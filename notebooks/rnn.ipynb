{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.ops\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax import optim\n",
    "from flax.linen.recurrent import RNNCellBase\n",
    "\n",
    "import optax\n",
    "\n",
    "import numpy as np  # convention: original numpy\n",
    "\n",
    "from typing import Any, Callable, Sequence, Optional, Tuple, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1701\n",
    "key = jax.random.PRNGKey(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_copies = 5\n",
    "rng, key2, key3, key4, key5 = jax.random.split(key, num=num_copies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(RNNCellBase):\n",
    "    @nn.compact()\n",
    "    def __call__(self, carry, input):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            W_xh = x_{t} @ W_{xh} - multiply the previous hidden state with\n",
    "            W_hh = H_{t-1} @ W_{hh} + b_{h} - this a linear layer\n",
    "\n",
    "            H_{t} = f_{w}(H_{t-1}, x)\n",
    "            H_{t} = tanh(H_{t-1} @ W_{hh}) + (x_{t} @ W_{xh})\n",
    "\n",
    "        Args:\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "\n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        \"\"\"\n",
    "        ht_1 = carry\n",
    "\n",
    "        h_t = self.rnn_update(input, ht_1)\n",
    "\n",
    "        return h_t, h_t\n",
    "\n",
    "    def rnn_update(self, input, ht_1):\n",
    "\n",
    "        W_hh = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        W_xh = nn.Dense(input.shape[0])(input)\n",
    "        h_t = jnp.tanh(W_hh + W_xh)  # H_{t} = tanh(H_{t-1} @ W_{hh}) + (x_{t} @ W_{xh})\n",
    "\n",
    "        return h_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(RNNCellBase):\n",
    "    @nn.compact()\n",
    "    def __call__(self, carry, input):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            i_{t} = sigmoid((W_{ii} @ x_{t} + b_{ii}) + (W_{hi} @ h_{t-1} + b_{hi}))\n",
    "            f_{t} = sigmoid((W_{if} @ x_{t} + b_{if}) + (W_{hf} @ h_{t-1} + b_{hf}))\n",
    "            g_{t} = tanh((W_{ig} @ x_{t} + b_{ig}) + (W_{hg} @ h_{t-1} + b_{hg}))\n",
    "            o_{t} = sigmoid((W_{io} @ x_{t} + b_{io}) + (W_{ho} @ h_{t-1} + b_{ho}))\n",
    "            c_{t} = f_{t} * c_{t-1} + i_{t} * g_{t}\n",
    "            h_{t} = o_{t} * tanh(c_{t})\n",
    "\n",
    "        Args:\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "\n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        \"\"\"\n",
    "        ht_1, ct_1 = carry\n",
    "\n",
    "        c_t, h_t = self.rnn_update(input, ht_1, ct_1)\n",
    "\n",
    "        return (h_t, c_t), h_t\n",
    "\n",
    "    def rnn_update(self, input, ht_1, ct_1):\n",
    "\n",
    "        i_ta = nn.Dense(input.shape[0])(input)\n",
    "        i_tb = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        i_t = jnp.sigmoid(i_ta + i_tb)  # input gate\n",
    "\n",
    "        o_ta = nn.Dense(input.shape[0])(input)\n",
    "        o_tb = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        o_t = jnp.sigmoid(o_ta + o_tb)  # output gate\n",
    "\n",
    "        f_ia = nn.Dense(input.shape[0])(\n",
    "            input\n",
    "        )  # b^{f}_{i} + \\sum\\limits_{j} U^{f}_{i, j} x^{t}_{j}\n",
    "        f_ib = nn.Dense(ht_1.shape[0])(\n",
    "            ht_1\n",
    "        )  # \\sum\\limits_{j} W^{f}_{i, j} h^{(t-1)}_{j}\n",
    "        f_i = jnp.sigmoid(f_ia + f_ib)  # forget gate\n",
    "\n",
    "        g_ia = nn.Dense(input.shape[0])(\n",
    "            input\n",
    "        )  # b^{g}_{i} + \\sum\\limits_{j} U^{g}_{i, j} x^{t}_{j}\n",
    "        g_ib = nn.Dense(ht_1.shape[0])(\n",
    "            ht_1\n",
    "        )  # \\sum\\limits_{j} W^{g}_{i, j} h^{(t-1)}_{j}\n",
    "        g_i = jnp.tanh(g_ia + g_ib)  # (external) input gate\n",
    "\n",
    "        c_t = (f_i * ct_1) + (i_t * g_i)  # internal cell state update\n",
    "\n",
    "        h_t = o_t * jnp.tanh(c_t)  # hidden state update\n",
    "\n",
    "        return h_t, c_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(RNNCellBase):\n",
    "    @nn.compact()\n",
    "    def __call__(self, carry, input):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            z_t = sigmoid((W_{iz} @ x_{t} + b_{iz}) + (W_{hz} @ h_{t-1} + b_{hz}))\n",
    "            r_t = sigmoid((W_{ir} @ x_{t} + b_{ir}) + (W_{hr} @ h_{t-1} + b_{hr}))\n",
    "            g_i = tanh(((W_{ig} @ x_{t} + b_{ig}) + r_t) * (W_{hg} @ h_{t-1} + b_{hg}))\n",
    "            h_t = (z_t * h_{t-1}) + ((1 - z_t) * g_i)\n",
    "\n",
    "        Args:\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "\n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        \"\"\"\n",
    "        ht_1 = carry\n",
    "\n",
    "        h_t = self.rnn_update(input, ht_1)\n",
    "\n",
    "        return h_t, h_t\n",
    "\n",
    "    def rnn_update(self, input, ht_1):\n",
    "\n",
    "        z_ta = nn.Dense(input.shape[0])(input)\n",
    "        z_tb = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        z_t = jnp.sigmoid(z_ta + z_tb)  # update gate\n",
    "\n",
    "        r_ta = nn.Dense(input.shape[0])(input)\n",
    "        r_tb = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        r_t = jnp.sigmoid(r_ta + r_tb)  # reset gate\n",
    "\n",
    "        g_ia = nn.Dense(input.shape[0])(input)\n",
    "        g_ib = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        g_i = jnp.tanh((g_ia + r_t) * g_ib)  # (external) input gate\n",
    "\n",
    "        h_t = (z_t * ht_1) + ((1 - z_t) * g_i)  # internal cell state update\n",
    "\n",
    "        return h_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPOCell(nn.module):\n",
    "    '''\n",
    "        Description:\n",
    "            RNN update function\n",
    "            τ(h, x) = (1 - g(h, x)) ◦ h + g(h, x) ◦ tanh(Lτ (h, x)) \n",
    "            g(h, x) = σ(Lg(h,x))\n",
    "\n",
    "        Args:\n",
    "            hippo (HiPPO): # hippo model object\n",
    "            cell (RNNCellBase): choice of RNN cell object\n",
    "                - RNNCell \n",
    "                - LSTMCell\n",
    "                - GRUCell\n",
    "    '''\n",
    "    hippo: HiPPO\n",
    "    cell: RNNCellBase\n",
    "        \n",
    "    @nn.compact() \n",
    "    def __call__(self, carry, input):\n",
    "        '''\n",
    "        Description:\n",
    "            RNN update function\n",
    "            τ(h, x) = (1 - g(h, x)) ◦ h + g(h, x) ◦ tanh(Lτ (h, x)) \n",
    "            g(h, x) = σ(Lg(h,x))\n",
    "            \n",
    "        Args:\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "            \n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        '''\n",
    "        \n",
    "        _, h_t = self.cell(carry, input)\n",
    "        \n",
    "        y_t = nn.Dense(input.shape[0])(h_t) # f_t in the paper\n",
    "        \n",
    "        c_t = self.hippo(y_t, init_state=None, kernel=False)\n",
    "        \n",
    "        return (h_t, c_t), h_t\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_o2m(nn.Module):\n",
    "    \"\"\"_summary_\n",
    "        An RNN with one-to-many connections.\n",
    "\n",
    "    Args:\n",
    "        cell (_type_): choice of RNN cell object\n",
    "        sequence_length (int): length of the input sequence\n",
    "        carry (Tuple[jnp.ndarray, jnp.ndarray]): A tuple with the new carry and the output.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cell: RNNCellBase\n",
    "    sequence_length: int\n",
    "    carry: Tuple[jnp.ndarray, jnp.ndarray]\n",
    "\n",
    "    @nn.compact()\n",
    "    def __call__(self, carry, x):\n",
    "        output = []\n",
    "\n",
    "        for i in range(self.sequence_length):\n",
    "            if i == 0:\n",
    "                carry, h_t = self.cell(self.carry, x)\n",
    "            else:\n",
    "                carry, h_t = self.cell(carry, output[i - 1])\n",
    "\n",
    "            y_t = nn.Dense(x.shape[0])(h_t)  # output\n",
    "            output.append(y_t)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one2one(init_carry, input, sequence_length, cell, tf_bool=True):\n",
    "\n",
    "    if not tf_bool:\n",
    "        output = []\n",
    "\n",
    "        for i in range(len(sequence_length)):\n",
    "            if i == 0:\n",
    "                carry, h_t = cell(init_carry, input)\n",
    "            else:\n",
    "                carry, h_t = cell(carry, output[i - 1])\n",
    "\n",
    "            y_t = nn.Dense(x.shape[0])(h_t)  # output\n",
    "            output.append(y_t)\n",
    "    else:\n",
    "        output = []\n",
    "\n",
    "        for i in range(sequence_length):\n",
    "            if i == 0:\n",
    "                carry, h_t = self.cell(init_carry, input)\n",
    "            else:\n",
    "                carry, h_t = self.cell(carry, output[i - 1])\n",
    "\n",
    "            y_t = nn.Dense(x.shape[0])(h_t)  # output\n",
    "            output.append(y_t)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_m2o(nn.Module):\n",
    "    \"\"\"_summary_\n",
    "        An RNN with many-to-one connections.\n",
    "\n",
    "    Args:\n",
    "        cell (_type_): choice of RNN cell object\n",
    "        sequence_length (int): length of the input sequence\n",
    "        carry (Tuple[jnp.ndarray, jnp.ndarray]): A tuple with the new carry and the output.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cell: RNNCellBase\n",
    "    sequence_length: int\n",
    "    carry: Tuple[jnp.ndarray, jnp.ndarray]\n",
    "\n",
    "    @nn.compact()\n",
    "    def __call__(self, x):\n",
    "        output = []\n",
    "\n",
    "        for i in range(self.sequence_length):\n",
    "            if i == 0:\n",
    "                carry, h_t = self.cell(self.carry, x)\n",
    "            else:\n",
    "                carry, h_t = self.cell(carry, output[i - 1])\n",
    "\n",
    "            y_t = nn.Dense(x.shape[0])(h_t)  # output\n",
    "            output.append(y_t)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "\n",
    "\n",
    "    Args:\n",
    "        lstm_size (int): number of units in one LSTM layer.\n",
    "        num_layers (int): number of stacked LSTM layers.\n",
    "        keep_prob (float): percentage of cell units to keep in the dropout operation.\n",
    "        init_learning_rate (float): the learning rate to start with.\n",
    "        learning_rate_decay (float): decay ratio in later training epochs.\n",
    "        init_epoch (int): number of epochs using the constant init_learning_rate.\n",
    "        max_epoch (int): total number of epochs in training\n",
    "        input_size (int): size of the sliding window / one training data point\n",
    "        batch_size (int): number of data points to use in one mini-batch.\n",
    "    \"\"\"\n",
    "\n",
    "    input_size = 1\n",
    "    num_steps = 30\n",
    "    lstm_size = 128\n",
    "    num_layers = 1\n",
    "    keep_prob = 0.8\n",
    "    batch_size = 64\n",
    "    init_learning_rate = 0.001\n",
    "    learning_rate_decay = 0.99\n",
    "    init_epoch = 5\n",
    "    max_epoch = 50\n",
    "\n",
    "    rnn_type: str\n",
    "    arch: Callable[jnp.ndarray, jnp.ndarray]\n",
    "\n",
    "    def setup(self):\n",
    "        self.choose_rnn_type()  # choose rnn type\n",
    "        cell = self.choose_cell(cell_type=\"lstm\")  # choose cell type\n",
    "\n",
    "        pass\n",
    "\n",
    "    def __call__(self, ht_1, input):\n",
    "\n",
    "        y_t = nn.Dense(input.shape[0])(h_t)  # output\n",
    "        return h_t, y_t\n",
    "\n",
    "    def choose_cell(self, cell_type=\"lstm\"):\n",
    "        cell = None\n",
    "        if cell_type == \"regular\":\n",
    "            cell = RNNCell\n",
    "\n",
    "        elif cell_type == \"hippo\":\n",
    "            cell = HiPPOCell\n",
    "\n",
    "        elif cell_type == \"lstm\":\n",
    "            cell = LSTMCell\n",
    "\n",
    "        elif cell_type == \"gru\":\n",
    "            cell = GRUCell\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid cell type\")\n",
    "\n",
    "        return cell\n",
    "\n",
    "    def choose_rnn_type(self):\n",
    "        if self.rnn_type == \"one2one\":\n",
    "            self.arch = self.one_to_one\n",
    "\n",
    "        elif self.rnn_type == \"one2many\":\n",
    "            self.arch = self.one_to_many\n",
    "\n",
    "        elif self.rnn_type == \"many2one\":\n",
    "            self.arch = self.many_to_one\n",
    "\n",
    "        elif self.rnn_type == \"many2many\":\n",
    "            self.arch = self.many_to_many\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid cell type\")\n",
    "\n",
    "    def one_to_one(self, ht_1, input, cell_init):\n",
    "        _, y_t = cell_init(ht_1, input)\n",
    "\n",
    "        return y_t\n",
    "\n",
    "    def one_to_many(self, ht_1, input, cell_init):\n",
    "        _, y_t = cell_init(ht_1, input)\n",
    "\n",
    "        return y_t\n",
    "\n",
    "    def many_to_one(self, ht_1, input, cell_init, output_bool=False):\n",
    "        output = None\n",
    "\n",
    "        if output_bool:\n",
    "            h_t, _ = cell_init(ht_1, input)\n",
    "            output = h_t.copy()\n",
    "        else:\n",
    "            _, y_t = cell_init(ht_1, input)\n",
    "            output = y_t.copy()\n",
    "\n",
    "        return output\n",
    "\n",
    "    def many_to_many(self, ht_1, input, cell_init):\n",
    "        h_t, y_t = cell_init(ht_1, input)\n",
    "\n",
    "        return h_t, y_t\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('S4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dc494a5daaced9550789c1f8ef2d8b520b83ed8d0bf2c0436ba61ad5b0d825e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
