{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.ops\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax import optim\n",
    "from flax.linen.recurrent import RNNCellBase\n",
    "\n",
    "import optax\n",
    "\n",
    "import numpy as np  # convention: original numpy\n",
    "\n",
    "from typing import Any, Callable, Sequence, Optional, Tuple, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1701\n",
    "key = jax.random.PRNGKey(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_copies = 5\n",
    "rng, key2, key3, key4, key5 = jax.random.split(key, num=num_copies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(RNNCellBase):\n",
    "    @nn.compact()\n",
    "    def __call__(self, carry, input):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            W_xh = x_{t} @ W_{xh} - multiply the previous hidden state with\n",
    "            W_hh = H_{t-1} @ W_{hh} + b_{h} - this a linear layer\n",
    "\n",
    "            H_{t} = f_{w}(H_{t-1}, x)\n",
    "            H_{t} = tanh(H_{t-1} @ W_{hh}) + (x_{t} @ W_{xh})\n",
    "\n",
    "        Args:\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "\n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        \"\"\"\n",
    "        ht_1 = carry\n",
    "\n",
    "        h_t = self.rnn_update(input, ht_1)\n",
    "\n",
    "        return h_t, h_t\n",
    "\n",
    "    def rnn_update(self, input, ht_1):\n",
    "\n",
    "        W_hh = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        W_xh = nn.Dense(input.shape[0])(input)\n",
    "        h_t = jnp.tanh(W_hh + W_xh)  # H_{t} = tanh(H_{t-1} @ W_{hh}) + (x_{t} @ W_{xh})\n",
    "\n",
    "        return h_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(RNNCellBase):\n",
    "    @nn.compact()\n",
    "    def __call__(self, carry, input):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            i_{t} = sigmoid((W_{ii} @ x_{t} + b_{ii}) + (W_{hi} @ h_{t-1} + b_{hi}))\n",
    "            f_{t} = sigmoid((W_{if} @ x_{t} + b_{if}) + (W_{hf} @ h_{t-1} + b_{hf}))\n",
    "            g_{t} = tanh((W_{ig} @ x_{t} + b_{ig}) + (W_{hg} @ h_{t-1} + b_{hg}))\n",
    "            o_{t} = sigmoid((W_{io} @ x_{t} + b_{io}) + (W_{ho} @ h_{t-1} + b_{ho}))\n",
    "            c_{t} = f_{t} * c_{t-1} + i_{t} * g_{t}\n",
    "            h_{t} = o_{t} * tanh(c_{t})\n",
    "\n",
    "        Args:\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "\n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        \"\"\"\n",
    "        ht_1, ct_1 = carry\n",
    "\n",
    "        c_t, h_t = self.rnn_update(input, ht_1, ct_1)\n",
    "\n",
    "        return (h_t, c_t), h_t\n",
    "\n",
    "    def rnn_update(self, input, ht_1, ct_1):\n",
    "\n",
    "        i_ta = nn.Dense(input.shape[0])(input)\n",
    "        i_tb = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        i_t = jnp.sigmoid(i_ta + i_tb)  # input gate\n",
    "\n",
    "        o_ta = nn.Dense(input.shape[0])(input)\n",
    "        o_tb = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        o_t = jnp.sigmoid(o_ta + o_tb)  # output gate\n",
    "\n",
    "        f_ia = nn.Dense(input.shape[0])(\n",
    "            input\n",
    "        )  # b^{f}_{i} + \\sum\\limits_{j} U^{f}_{i, j} x^{t}_{j}\n",
    "        f_ib = nn.Dense(ht_1.shape[0])(\n",
    "            ht_1\n",
    "        )  # \\sum\\limits_{j} W^{f}_{i, j} h^{(t-1)}_{j}\n",
    "        f_i = jnp.sigmoid(f_ia + f_ib)  # forget gate\n",
    "\n",
    "        g_ia = nn.Dense(input.shape[0])(\n",
    "            input\n",
    "        )  # b^{g}_{i} + \\sum\\limits_{j} U^{g}_{i, j} x^{t}_{j}\n",
    "        g_ib = nn.Dense(ht_1.shape[0])(\n",
    "            ht_1\n",
    "        )  # \\sum\\limits_{j} W^{g}_{i, j} h^{(t-1)}_{j}\n",
    "        g_i = jnp.tanh(g_ia + g_ib)  # (external) input gate\n",
    "\n",
    "        c_t = (f_i * ct_1) + (i_t * g_i)  # internal cell state update\n",
    "\n",
    "        h_t = o_t * jnp.tanh(c_t)  # hidden state update\n",
    "\n",
    "        return h_t, c_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(RNNCellBase):\n",
    "    @nn.compact()\n",
    "    def __call__(self, carry, input):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            z_t = sigmoid((W_{iz} @ x_{t} + b_{iz}) + (W_{hz} @ h_{t-1} + b_{hz}))\n",
    "            r_t = sigmoid((W_{ir} @ x_{t} + b_{ir}) + (W_{hr} @ h_{t-1} + b_{hr}))\n",
    "            g_i = tanh(((W_{ig} @ x_{t} + b_{ig}) + r_t) * (W_{hg} @ h_{t-1} + b_{hg}))\n",
    "            h_t = (z_t * h_{t-1}) + ((1 - z_t) * g_i)\n",
    "\n",
    "        Args:\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "\n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        \"\"\"\n",
    "        ht_1 = carry\n",
    "\n",
    "        h_t = self.rnn_update(input, ht_1)\n",
    "\n",
    "        return h_t, h_t\n",
    "\n",
    "    def rnn_update(self, input, ht_1):\n",
    "\n",
    "        z_ta = nn.Dense(input.shape[0])(input)\n",
    "        z_tb = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        z_t = jnp.sigmoid(z_ta + z_tb)  # update gate\n",
    "\n",
    "        r_ta = nn.Dense(input.shape[0])(input)\n",
    "        r_tb = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        r_t = jnp.sigmoid(r_ta + r_tb)  # reset gate\n",
    "\n",
    "        g_ia = nn.Dense(input.shape[0])(input)\n",
    "        g_ib = nn.Dense(ht_1.shape[0])(ht_1)\n",
    "        g_i = jnp.tanh((g_ia + r_t) * g_ib)  # (external) input gate\n",
    "\n",
    "        h_t = (z_t * ht_1) + ((1 - z_t) * g_i)  # internal cell state update\n",
    "\n",
    "        return h_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPOCell(nn.module):\n",
    "    '''\n",
    "        Description:\n",
    "            RNN update function\n",
    "            τ(h, x) = (1 - g(h, x)) ◦ h + g(h, x) ◦ tanh(Lτ (h, x)) \n",
    "            g(h, x) = σ(Lg(h,x))\n",
    "\n",
    "        Args:\n",
    "            hippo (HiPPO): # hippo model object\n",
    "            cell (RNNCellBase): choice of RNN cell object\n",
    "                - RNNCell \n",
    "                - LSTMCell\n",
    "                - GRUCell\n",
    "    '''\n",
    "    hippo: HiPPO\n",
    "    cell: RNNCellBase\n",
    "        \n",
    "    @nn.compact() \n",
    "    def __call__(self, carry, input):\n",
    "        '''\n",
    "        Description:\n",
    "            RNN update function\n",
    "            τ(h, x) = (1 - g(h, x)) ◦ h + g(h, x) ◦ tanh(Lτ (h, x)) \n",
    "            g(h, x) = σ(Lg(h,x))\n",
    "            \n",
    "        Args:\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "            \n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        '''\n",
    "        \n",
    "        _, h_t = self.cell(carry, input)\n",
    "        \n",
    "        y_t = nn.Dense(input.shape[0])(h_t) # f_t in the paper\n",
    "        \n",
    "        c_t = self.hippo(y_t, init_state=None, kernel=False)\n",
    "        \n",
    "        return (h_t, c_t), h_t\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Training Types\n",
    "refer to [this](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one2one(init_carry, input, sequence_length, cell):\n",
    "    _, h_t = cell(init_carry, input)\n",
    "    y_t = nn.Dense(input.shape[0])(h_t)  # output\n",
    "    return y_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one2many(init_carry, input, T_y, cell, tf_bool=True):\n",
    "    output = []\n",
    "    if not tf_bool:\n",
    "        for i in range(len(T_y)):\n",
    "            if i == 0:\n",
    "                carry, h_t = cell(init_carry, input[i])\n",
    "            else:\n",
    "                carry, h_t = cell(carry, output[i - 1])\n",
    "\n",
    "            y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
    "            output.append(y_t)\n",
    "    else:\n",
    "        for i in range(len(input)):\n",
    "            carry, h_t = cell(init_carry, input[i])\n",
    "            y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
    "            output.append(y_t)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many2one(init_carry, input, T_x, cell, tf_bool=True):\n",
    "    y_t = None\n",
    "    carry = init_carry\n",
    "    for i in range(len(T_x)):\n",
    "        carry, h_t = cell(carry, input[i])\n",
    "        if i == (len(T_x) - 1):\n",
    "            y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
    "\n",
    "    return y_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many2many(init_carry, input, T_xy, cell, tf_bool=True):\n",
    "    output = []\n",
    "    carry = init_carry\n",
    "    for i in range(len(T_xy)):\n",
    "        carry, h_t = cell(carry, input[i])\n",
    "        y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
    "        output.append(y_t)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many2many(init_carry, input, T_x, T_y, cell, tf_bool=True):\n",
    "    assert T_x != T_y, \"T_x and T_y must be different\"\n",
    "    output = []\n",
    "    carry = init_carry\n",
    "    for i in range(len(T_x)):\n",
    "        carry, h_t = cell(carry, input[i])\n",
    "        \n",
    "    for i in range(len(T_y)):\n",
    "        carry, h_t = cell(carry, input[i])\n",
    "        y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
    "        output.append(y_t)\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('S4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6dc494a5daaced9550789c1f8ef2d8b520b83ed8d0bf2c0436ba61ad5b0d825e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
