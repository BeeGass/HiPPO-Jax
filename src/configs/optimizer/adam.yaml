_target_: src.optimizer.adam.Adam
# _name_: adam
lr: 0.001 # Initial learning rate
# weight_decay: 0.0  # Weight decay for adam|lamb; should use AdamW instead if desired
beta: [0.9, 0.999]
