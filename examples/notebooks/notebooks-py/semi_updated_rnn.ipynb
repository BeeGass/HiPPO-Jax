{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade -q git+https://github.com/google/flax.git"
      ],
      "metadata": {
        "id": "M_rcOmX_RcbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "j4OATsG0RXah"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.ops\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import flax\n",
        "from flax import linen as nn\n",
        "from flax import optim\n",
        "from flax.linen.recurrent import RNNCellBase\n",
        "\n",
        "import optax\n",
        "\n",
        "import numpy as np  # convention: original numpy\n",
        "\n",
        "from typing import Any, Callable, Sequence, Optional, Tuple, Union\n",
        "from collections import defaultdict\n",
        "\n",
        "from hippo import HiPPO, HiPPOCel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebf2T7uoRXam",
        "outputId": "b8bd2a5a-056d-4157-c446-bdaf9d486374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "seed = 1701\n",
        "key = jax.random.PRNGKey(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK_ek114RXan"
      },
      "outputs": [],
      "source": [
        "num_copies = 5\n",
        "rng, key2, key3, key4, key5 = jax.random.split(key, num=num_copies)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VtwOh4URXan"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HZvmwt2BRXap"
      },
      "outputs": [],
      "source": [
        "def add_batch(nest, batch_size: Optional[int]):\n",
        "    \"\"\"Adds a batch dimension at axis 0 to the leaves of a nested structure.\"\"\"\n",
        "    broadcast = lambda x: jnp.broadcast_to(x, (batch_size,) + x.shape)\n",
        "\n",
        "    return jax.tree_map(broadcast, nest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2YGhKAzRXap"
      },
      "source": [
        "## RNN Cells"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yIMcZQg1adW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "zZdUIAFjRXaq"
      },
      "outputs": [],
      "source": [
        "class RNNCell(RNNCellBase):\n",
        "    hidden_size: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, carry, input):\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            W_xh = x_{t} @ W_{xh} - multiply the previous hidden state with\n",
        "            W_hh = H_{t-1} @ W_{hh} + b_{h} - this a linear layer\n",
        "\n",
        "            H_{t} = f_{w}(H_{t-1}, x)\n",
        "            H_{t} = tanh(H_{t-1} @ W_{hh}) + (x_{t} @ W_{xh})\n",
        "\n",
        "        Args:\n",
        "            hidden_size (int): hidden state size\n",
        "            carry (jnp.ndarray): hidden state from previous time step\n",
        "            input (jnp.ndarray): # input vector\n",
        "\n",
        "        Returns:\n",
        "            A tuple with the new carry and the output.\n",
        "        \"\"\"\n",
        "        ht_1, _ = carry\n",
        "\n",
        "        h_t = self.rnn_update(input, ht_1)\n",
        "\n",
        "        return (h_t, h_t), h_t\n",
        "\n",
        "    def rnn_update(self, input, ht_1):\n",
        "\n",
        "        W_hh = nn.Dense(self.hidden_size)(ht_1)\n",
        "        W_xh = nn.Dense(self.hidden_size)(input)\n",
        "        h_t = nn.relu(W_hh + W_xh)  # H_{t} = tanh(H_{t-1} @ W_{hh}) + (x_{t} @ W_{xh})\n",
        "\n",
        "        return h_t\n",
        "\n",
        "    def initial_state(self, batch_size: Optional[int]):\n",
        "        state = jnp.zeros([self.hidden_size])\n",
        "        if batch_size is not None:\n",
        "            state = add_batch(state, batch_size)\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "pcirm9GzRXar"
      },
      "outputs": [],
      "source": [
        "class LSTMCell(RNNCellBase):\n",
        "    hidden_size: int\n",
        "\n",
        "    # @nn.compact\n",
        "    @nn.compact\n",
        "    def __call__(self, carry, input):\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            i_{t} = sigmoid((W_{ii} @ x_{t} + b_{ii}) + (W_{hi} @ h_{t-1} + b_{hi}))\n",
        "            f_{t} = sigmoid((W_{if} @ x_{t} + b_{if}) + (W_{hf} @ h_{t-1} + b_{hf}))\n",
        "            g_{t} = tanh((W_{ig} @ x_{t} + b_{ig}) + (W_{hg} @ h_{t-1} + b_{hg}))\n",
        "            o_{t} = sigmoid((W_{io} @ x_{t} + b_{io}) + (W_{ho} @ h_{t-1} + b_{ho}))\n",
        "            c_{t} = f_{t} * c_{t-1} + i_{t} * g_{t}\n",
        "            h_{t} = o_{t} * tanh(c_{t})\n",
        "\n",
        "        Args:\n",
        "            hidden_size (int): hidden state size\n",
        "            carry (jnp.ndarray): hidden state from previous time step\n",
        "            input (jnp.ndarray): # input vector\n",
        "\n",
        "        Returns:\n",
        "            A tuple with the new carry and the output.\n",
        "        \"\"\"\n",
        "        ht_1, ct_1 = carry\n",
        "\n",
        "        c_t, h_t = self.rnn_update(input, ht_1, ct_1)\n",
        "\n",
        "        return (h_t, c_t), h_t\n",
        "\n",
        "    def rnn_update(self, input, ht_1, ct_1):\n",
        "\n",
        "        i_ta = nn.Dense(self.hidden_size)(input)\n",
        "        i_tb = nn.Dense(self.hidden_size)(ht_1)\n",
        "        i_t = nn.sigmoid(i_ta + i_tb)  # input gate\n",
        "\n",
        "        o_ta = nn.Dense(self.hidden_size)(input)\n",
        "        o_tb = nn.Dense(self.hidden_size)(ht_1)\n",
        "        o_t = nn.sigmoid(o_ta + o_tb)  # output gate\n",
        "\n",
        "        f_ia = nn.Dense(self.hidden_size)(\n",
        "            input\n",
        "        )  # b^{f}_{i} + \\sum\\limits_{j} U^{f}_{i, j} x^{t}_{j}\n",
        "        f_ib = nn.Dense(self.hidden_size)(\n",
        "            ht_1\n",
        "        )  # \\sum\\limits_{j} W^{f}_{i, j} h^{(t-1)}_{j}\n",
        "        f_i = nn.sigmoid(f_ia + f_ib)  # forget gate\n",
        "\n",
        "        g_ia = nn.Dense(self.hidden_size)(\n",
        "            input\n",
        "        )  # b^{g}_{i} + \\sum\\limits_{j} U^{g}_{i, j} x^{t}_{j}\n",
        "        g_ib = nn.Dense(self.hidden_size)(\n",
        "            ht_1\n",
        "        )  # \\sum\\limits_{j} W^{g}_{i, j} h^{(t-1)}_{j}\n",
        "        g_i = nn.tanh(g_ia + g_ib)  # (external) input gate\n",
        "\n",
        "        c_t = (f_i * ct_1) + (i_t * g_i)  # internal cell state update\n",
        "\n",
        "        h_t = o_t * nn.tanh(c_t)  # hidden state update\n",
        "\n",
        "        return h_t, c_t\n",
        "\n",
        "    def initial_state(self, batch_size: Optional[int]):\n",
        "        state = jnp.zeros([self.hidden_size])\n",
        "        if batch_size is not None:\n",
        "            state = add_batch(state, batch_size)\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6OnltMD_RXat"
      },
      "outputs": [],
      "source": [
        "class GRUCell(RNNCellBase):\n",
        "    hidden_size: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, carry, input):\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            z_t = sigmoid((W_{iz} @ x_{t} + b_{iz}) + (W_{hz} @ h_{t-1} + b_{hz}))\n",
        "            r_t = sigmoid((W_{ir} @ x_{t} + b_{ir}) + (W_{hr} @ h_{t-1} + b_{hr}))\n",
        "            g_t = tanh(((W_{ig} @ x_{t} + b_{ig}) + r_t) * (W_{hg} @ h_{t-1} + b_{hg}))\n",
        "            h_t = (z_t * h_{t-1}) + ((1 - z_t) * g_i)\n",
        "\n",
        "        Args:\n",
        "            hidden_size (int): hidden state size\n",
        "            carry (jnp.ndarray): hidden state from previous time step\n",
        "            input (jnp.ndarray): # input vector\n",
        "\n",
        "        Returns:\n",
        "            A tuple with the new carry and the output.\n",
        "        \"\"\"\n",
        "        ht_1 = carry\n",
        "\n",
        "        h_t = self.rnn_update(input, ht_1)\n",
        "\n",
        "        return (h_t, h_t), h_t\n",
        "\n",
        "    def rnn_update(self, input, ht_1):\n",
        "\n",
        "        z_ta = nn.Dense(self.hidden_size)(input)\n",
        "        z_tb = nn.Dense(self.hidden_size)(ht_1)\n",
        "        z_t = nn.sigmoid(z_ta + z_tb)  # reset gate\n",
        "\n",
        "        r_ta = nn.Dense(self.hidden_size)(input)\n",
        "        r_tb = nn.Dense(self.hidden_size)(ht_1)\n",
        "        r_t = nn.sigmoid(r_ta + r_tb)  # update gate\n",
        "\n",
        "        g_ta = nn.Dense(self.hidden_size)(input)\n",
        "        g_tb = nn.Dense(self.hidden_size)(ht_1)\n",
        "        g_t = nn.tanh((g_ta + r_t) * g_tb)  # (external) input gate\n",
        "\n",
        "        h_t = ((1 - z_t) * ht_1) + (z_t * g_t)  # internal cell state update\n",
        "\n",
        "        return h_t\n",
        "\n",
        "    def initial_state(self, batch_size: Optional[int]):\n",
        "        state = jnp.zeros([self.hidden_size])\n",
        "        if batch_size is not None:\n",
        "            state = add_batch(state, batch_size)\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "vGJevRqRRXau"
      },
      "outputs": [],
      "source": [
        "class HiPPOCell(nn.Module):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        RNN update function\n",
        "        τ(h, x) = (1 - g(h, x)) ◦ h + g(h, x) ◦ tanh(Lτ (h, x))\n",
        "        g(h, x) = σ(Lg(h,x))\n",
        "\n",
        "    Args:\n",
        "        hidden_size (int): hidden state size\n",
        "        output_size (int): output size\n",
        "        hippo (HiPPO): hippo model object\n",
        "        cell (RNNCellBase): choice of RNN cell object\n",
        "            - RNNCell\n",
        "            - LSTMCell\n",
        "            - GRUCell\n",
        "    \"\"\"\n",
        "\n",
        "    hidden_size: int\n",
        "    output_size: int\n",
        "    hippo: HiPPO\n",
        "    model: RNNCellBase\n",
        "    \n",
        "    def setup(self):\n",
        "        self.cell = self.model(self.hidden_size)\n",
        "\n",
        "    def __call__(self, carry, input):\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            RNN update function\n",
        "            τ(h, x) = (1 - g(h, x)) ◦ h + g(h, x) ◦ tanh(Lτ (h, x))\n",
        "            g(h, x) = σ(Lg(h,x))\n",
        "\n",
        "        Args:\n",
        "            carry (jnp.ndarray): hidden state from previous time step\n",
        "            input (jnp.ndarray): # input vector\n",
        "\n",
        "        Returns:\n",
        "            A tuple with the new carry and the output.\n",
        "        \"\"\"\n",
        "\n",
        "        _, h_t = self.cell(carry, input)\n",
        "\n",
        "        y_t = nn.Dense(self.output_size)(h_t)  # f_t in the paper\n",
        "\n",
        "        c_t = self.hippo(y_t, init_state=None, kernel=False)\n",
        "\n",
        "        return (h_t, c_t), h_t\n",
        "\n",
        "    def initial_state(self, batch_size: Optional[int]):\n",
        "        state = jnp.zeros([self.hidden_size])\n",
        "        if batch_size is not None:\n",
        "            state = add_batch(state, batch_size)\n",
        "        return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78QtlQ2dRXav"
      },
      "source": [
        "## Deep RNN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "OIgWSOESRXaw"
      },
      "outputs": [],
      "source": [
        "# TODO: refer to https://github.com/deepmind/dm-haiku/blob/main/haiku/_src/recurrent.py#L714-L762\n",
        "# also refer to https://dm-haiku.readthedocs.io/en/latest/api.html?highlight=DeepRNN#deeprnn\n",
        "class _DeepRNN(RNNCellBase):\n",
        "    layers: Sequence[Any]\n",
        "    skip_connections: bool\n",
        "    hidden_to_output_layer: bool\n",
        "    layer_name: Optional[str]\n",
        "\n",
        "    def setup(self):\n",
        "        if self.skip_connections:\n",
        "            for layer in self.layers:\n",
        "                if not (isinstance(layer, RNNCellBase) or isinstance(layer, HiPPOCell)):\n",
        "                    raise ValueError(\n",
        "                        f\"{self.layer_name} layer {layer} is not a RNNCellBase or HiPPOCell\"\n",
        "                    )\n",
        "\n",
        "    def __call__(self, carry, inputs):\n",
        "        current_carry = carry\n",
        "        next_states = []\n",
        "        h_t_outputs = []\n",
        "        c_t_outputs = []\n",
        "        state_idx = 0\n",
        "        h_t, c_t = current_carry  # c_t may actually be h_t in which case dont use it\n",
        "        (\n",
        "            h_t_copy,\n",
        "            c_t_copy,\n",
        "        ) = current_carry  # c_t may actually be h_t in which case dont use it\n",
        "        concat = lambda *args: jnp.concatenate(args, axis=-1)\n",
        "        for idx, layer in enumerate(self.layers):\n",
        "            if self.skip_connections and idx > 0:\n",
        "                skip_h_t = jax.tree_map(concat, h_t, h_t_copy)\n",
        "                skip_c_t = jax.tree_map(concat, c_t, c_t_copy)\n",
        "                current_carry = (skip_h_t, skip_c_t)\n",
        "\n",
        "            if isinstance(layer, RNNCellBase) or isinstance(layer, HiPPOCell):\n",
        "                current_carry, next_state = layer(current_carry, inputs[state_idx])\n",
        "                if self.hidden_to_output_layer:\n",
        "                    next_state = nn.Dense(next_state.shape[0])(next_state)\n",
        "\n",
        "                h_t, c_t = current_carry\n",
        "                h_t_outputs.append(h_t)\n",
        "                c_t_outputs.append(c_t)\n",
        "                next_states.append(next_state)\n",
        "                state_idx += 1\n",
        "\n",
        "            else:\n",
        "                current_carry = layer(current_carry)\n",
        "\n",
        "        if self.skip_connections:\n",
        "            skip_h_t_out = jax.tree_map(concat, *h_t_outputs)\n",
        "            skip_c_t_out = jax.tree_map(concat, *c_t_outputs)\n",
        "            out = (skip_h_t_out, skip_c_t_out)\n",
        "        else:\n",
        "            out = current_carry\n",
        "\n",
        "        return out, tuple(next_states)\n",
        "\n",
        "    def initial_state(self, batch_size: Optional[int]):\n",
        "        return tuple(\n",
        "            layer.initial_state_and_carry(batch_size)\n",
        "            for layer in self.layers\n",
        "            if isinstance(layer, RNNCellBase)\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "io_qC16aRXaw"
      },
      "outputs": [],
      "source": [
        "class DeepRNN(_DeepRNN):\n",
        "    r\"\"\"Wraps a sequence of cores and callables as a single core.\n",
        "        >>> deep_rnn = hk.DeepRNN([\n",
        "        ...     LSTMCell(hidden_size=4),\n",
        "        ...     jax.nn.relu,\n",
        "        ...     LSTMCell(hidden_size=2),\n",
        "        ... ])\n",
        "    The state of a :class:`DeepRNN` is a tuple with one element per\n",
        "    :class:`RNNCore`. If no layers are :class:`RNNCore`\\ s, the state is an empty\n",
        "    tuple.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers: Sequence[Any],\n",
        "        skip_connections: Optional[bool] = False,\n",
        "        hidden_to_output_layer: Optional[bool] = False,\n",
        "        name: Optional[str] = None,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            layers,\n",
        "            skip_connections=skip_connections,\n",
        "            hidden_to_output_layer=hidden_to_output_layer,\n",
        "            layer_name=name,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPoyXqF1RXax"
      },
      "source": [
        "## RNN Training Types\n",
        "refer to [this](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGEyUxM2RXax"
      },
      "outputs": [],
      "source": [
        "def train_one2one(params, init_carry, input, sequence_length, cell):\n",
        "    _, h_t = cell.apply(params, init_carry, input)\n",
        "    y_t = nn.Dense(input.shape[0])(h_t)  # output\n",
        "    return y_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOYHmSMQRXay"
      },
      "outputs": [],
      "source": [
        "def train_one2many(params, init_carry, input, T_y, cell, tf_bool=True):\n",
        "    output = []\n",
        "    if not tf_bool:\n",
        "        for i in range(len(T_y)):\n",
        "            if i == 0:\n",
        "                carry, h_t = cell.apply(params, init_carry, input[i])\n",
        "            else:\n",
        "                carry, h_t = cell.apply(params, carry, output[i - 1])\n",
        "\n",
        "            y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
        "            output.append(y_t)\n",
        "    else:\n",
        "        for i in range(len(input)):\n",
        "            carry, h_t = cell.apply(params, init_carry, input[i])\n",
        "            y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
        "            output.append(y_t)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kejILG-iRXay"
      },
      "outputs": [],
      "source": [
        "def train_many2one(params, init_carry, input, T_x, cell, tf_bool=True):\n",
        "    y_t = None\n",
        "    carry = init_carry\n",
        "    for i in range(len(T_x)):\n",
        "        carry, h_t = cell.apply(params, carry, input[i])\n",
        "        if i == (len(T_x) - 1):\n",
        "            y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
        "\n",
        "    return y_t\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyuM0mWURXay"
      },
      "outputs": [],
      "source": [
        "def train_many2many(params, init_carry, input, T_xy, cell, tf_bool=True):\n",
        "    output = []\n",
        "    carry = init_carry\n",
        "    for i in range(len(T_xy)):\n",
        "        carry, h_t = cell.apply(params, carry, input[i])\n",
        "        y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
        "        output.append(y_t)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u3-97TgRXaz"
      },
      "outputs": [],
      "source": [
        "def train_many2many(params, init_carry, input, T_x, T_y, cell, tf_bool=True):\n",
        "    assert T_x != T_y, \"T_x and T_y must be different\"\n",
        "    output = []\n",
        "    carry = init_carry\n",
        "    for i in range(len(T_x)):\n",
        "        carry, h_t = cell.apply(params, carry, input[i])\n",
        "\n",
        "    for i in range(len(T_y)):\n",
        "        carry, h_t = cell.apply(params, carry, input[i])\n",
        "        y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
        "        output.append(y_t)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxhyYDKzRXaz"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ptu3tWUfRXaz"
      },
      "outputs": [],
      "source": [
        "def map_data_2_id(iterable):\n",
        "    \"\"\"\n",
        "    provides mapping to and from ids\n",
        "    \"\"\"\n",
        "    \n",
        "    id_2_data = {}\n",
        "    data_2_id = {}\n",
        "\n",
        "    for id, elem in enumerate(iterable):\n",
        "        id_2_data[id] = elem\n",
        "\n",
        "    for id, elem in enumerate(iterable):\n",
        "        data_2_id[elem] = id\n",
        "\n",
        "    return (id_2_data, data_2_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "gLNIPHoRRXa0"
      },
      "outputs": [],
      "source": [
        "def one_hot(i, n):\n",
        "    \"\"\"\n",
        "    create vector of size n with 1 at index i\n",
        "    \"\"\"\n",
        "    print(i)\n",
        "    x = defaultdict(lambda: np.zeros(n))\n",
        "    x[i] = 1\n",
        "    return x\n",
        "\n",
        "    # x[i].at[i].set(1)\n",
        "    # return x\n",
        "    # return x.at[i].set(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "t7jtg-E2RXa0"
      },
      "outputs": [],
      "source": [
        "def encode(char):\n",
        "    return one_hot(data_2_id[char], len(data_2_id))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ks9UAl1KRXa0"
      },
      "outputs": [],
      "source": [
        "def decode(predictions, id_2_data):\n",
        "    return id_2_data[int(jnp.argmax(predictions))]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text(fname):\n",
        "  with open(fname, \"r\") as reader:\n",
        "    data = reader.read()\n",
        "  return data\n",
        "\n",
        "\n",
        "def prep_data(data):\n",
        "  chars = list(set(data))\n",
        "  vocab_size = len(chars)\n",
        "  char_to_id, id_to_char = map_data_2_id(chars)\n",
        "  char_to_id = {value:key for key, value in char_to_id.items()}\n",
        "  # data converted to ids\n",
        "  # data_id = [char_to_id[char] for char in data]\n",
        "  data_id = [char_to_id[char] for char in data]\n",
        "  return data_id, char_to_id, id_to_char\n",
        "\n",
        "\n",
        "data = \"abcd...abcd...\"\n",
        "data_id, char_to_id, id_to_char = prep_data(data)\n",
        "# print(data_id)\n",
        "data_id[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZHQ0tA0ViGU",
        "outputId": "7698900a-eaaa-4d53-d034-ab08f3ac603a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abcd...abcd...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 2, 4, 0, 0, 0, 1, 3, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sr01mRcJRXa1"
      },
      "source": [
        "## Optimizer Helpers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUTDZ0M3RXa1"
      },
      "source": [
        "check [this](https://github.com/deepmind/optax/blob/master/examples/quick_start.ipynb) out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qhn5yIrbRXa1"
      },
      "outputs": [],
      "source": [
        "def pick_optimizer_fn(starting_learning_rate, name=\"adam\"):\n",
        "    # refer to https://optax.readthedocs.io/en/latest/api.html#optimizer-schedules\n",
        "    optim = None\n",
        "\n",
        "    if name == \"sgd\":\n",
        "        optim = optax.sgd(starting_learning_rate)\n",
        "    elif name == \"adam\":\n",
        "        optim = optax.adam(starting_learning_rate, )\n",
        "    elif name == \"adagrad\":\n",
        "        optim = optax.adagrad(starting_learning_rate)\n",
        "    elif name == \"rmsprop\":\n",
        "        optim = optax.rmsprop(starting_learning_rate)\n",
        "    else:\n",
        "        raise ValueError(\"optimizer name not recognized\")\n",
        "\n",
        "    return optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQw5kexYRXa1"
      },
      "outputs": [],
      "source": [
        "def pick_scheduler_fn(\n",
        "    start_learning_rate, steps, decay_rate, init_value, end_val, name\n",
        "):\n",
        "    # refer to https://optax.readthedocs.io/en/latest/api.html#schedules\n",
        "    scheduler = None\n",
        "\n",
        "    if name == \"constant\":\n",
        "        scheduler = optax.constant_schedule(init_value)\n",
        "\n",
        "    elif name == \"exp_decay\":\n",
        "        scheduler = optax.exponential_decay(\n",
        "            init_value=start_learning_rate, transition_steps=1000, decay_rate=0.99\n",
        "        )\n",
        "    elif name == \"linear\":\n",
        "        scheduler = optax.linear_schedule(init_value=init_value, end_value=end_val)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"scheduler name not recognized\")\n",
        "\n",
        "    return scheduler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnncC_7VRXa1"
      },
      "outputs": [],
      "source": [
        "# TODO: add transformations\n",
        "# refer to https://optax.readthedocs.io/en/latest/api.html#optax-transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a53yRPQBRXa2"
      },
      "outputs": [],
      "source": [
        "#     # A simple update loop.\n",
        "#     for _ in range(1000):\n",
        "#     grads = jax.grad(compute_loss)(params, xs, ys)\n",
        "#     updates, opt_state = gradient_transform.update(grads, opt_state)\n",
        "#     params = optax.apply_updates(params, updates)\n",
        "\n",
        "#     assert jnp.allclose(params, target_params), \\\n",
        "#     'Optimization should retrieve the target params used to generate the data.'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJx2HxdGRXa2"
      },
      "outputs": [],
      "source": [
        "# def optimizer_fn(start_learning_rate, params, num_weights, x, y):\n",
        "#     optimizer = optax.adam(start_learning_rate)\n",
        "#     # Obtain the `opt_state` that contains statistics for the optimizer.\n",
        "#     params = {'w': jnp.ones((num_weights,))}\n",
        "#     opt_state = optimizer.init(params)\n",
        "\n",
        "#     compute_loss = lambda params, x, y: optax.l2_loss(params['w'].dot(x), y)\n",
        "#     grads = jax.grad(compute_loss)(params, xs, ys)\n",
        "\n",
        "#     updates, opt_state = optimizer.update(grads, opt_state)\n",
        "#     params = optax.apply_updates(params, updates)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQDJqnsbRXa2"
      },
      "source": [
        "## Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFrXEgtqRXa2"
      },
      "outputs": [],
      "source": [
        "class CharRNN(nn.Module):\n",
        "    state_size: int\n",
        "    vocab_size: int\n",
        "    hidden_size: int\n",
        "    hippo_order_N: int\n",
        "    batch_size: int\n",
        "\n",
        "    def setup(self):\n",
        "        L = self.vocab_size\n",
        "        N = self.state_size\n",
        "\n",
        "        hippo = HiPPO(N=N, max_length=L, measure=\"legs\", step=1.0 / L, GBT_alpha=0.5, seq_L=L,\n",
        "                      v=\"v\", lambda_n=1.0, fourier_type=\"fru\", alpha=0.0, beta=1.0)\n",
        "\n",
        "        cell1 = LSTMCell\n",
        "        cell2 = LSTMCell\n",
        "        \n",
        "        input_layers = [HiPPOCell(hippo=hippo, model=cell1, hidden_size=N, output_size=L),\n",
        "                        nn.relu,\n",
        "                        HiPPOCell(hippo=hippo, model=cell2, hidden_size=N, output_size=L)]\n",
        "\n",
        "        self.deep_cell = DeepRNN(layers=input_layers,\n",
        "                                 skip_connections=True,\n",
        "                                 hidden_to_output_layer=True,\n",
        "                                 name=\"CharRNN\")\n",
        "\n",
        "    def __call__(self, carry, i):\n",
        "        input = one_hot(i, self.vocab_size)\n",
        "        carries, next_states = self.deep_cell(carry, input)\n",
        "        predictions = nn.softmax(nn.Dense(self.vocab_size)(next_states[-1]))\n",
        "        return carries, next_states, predictions\n",
        "    \n",
        "    def initial_state(self, batch_size: Optional[int]):\n",
        "        state = jnp.zeros([self.hidden_size])\n",
        "        if batch_size is not None:\n",
        "            state = add_batch(state, batch_size)\n",
        "        return state\n",
        "    \n",
        "    def initial_carry(self, batch_size: Optional[int]):\n",
        "        state = jnp.zeros([self.hidden_size])\n",
        "        if batch_size is not None:\n",
        "            state = add_batch(state, batch_size)\n",
        "        return (state, state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1ywuewL2RXa3"
      },
      "outputs": [],
      "source": [
        "def sample(model, params, bridge, initial=\"\", max_length=100):\n",
        "    char_to_id, id_to_char = bridge\n",
        "    state = model.init_state()\n",
        "    output = initial\n",
        "    if len(initial) > 0:\n",
        "        for char in initial[:-1]:\n",
        "            _, state, _ = model.apply(params, char_to_id[char], state)\n",
        "\n",
        "    next_char = initial[-1]\n",
        "    for i in range(max_length):\n",
        "        state, predictions = model.apply(params, state, char_to_id[next_char], state)\n",
        "        next_char = decode(predictions, id_to_char)\n",
        "        output += next_char\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdASEbObXA-x",
        "outputId": "49b66e65-998b-41ba-d191-d7b1aa0d56ea"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CharRNN(\n",
            "    # attributes\n",
            "    state_size = 8\n",
            "    vocab_size = 5\n",
            "    hidden_size = 3\n",
            "    hippo_order_N = 2\n",
            "    batch_size = 20\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "NSsmNTgCRXa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "outputId": "7aac2988-2ce9-4f9a-cae6-b182272bd17f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnfilteredStackTrace\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-efa703337a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCharRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_to_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhippo_order_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_carry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   1269\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36minit_with_output\u001b[0;34m(self, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcapture_intermediates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     )(rngs, *args, **kwargs)\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/core/scope.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(rngs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0minit_flags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'initializing'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrngs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrngs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/core/scope.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(variables, rngs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrngs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrngs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmutable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mscope_fn\u001b[0;34m(scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1635\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/transforms.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1328\u001b[0m           or self._state.in_setup):  # pylint: disable=protected-access\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mprewrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m       \u001b[0mfn_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36mwrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapped_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/flax/linen/module.py\u001b[0m in \u001b[0;36m_call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture_stack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-8b726afddee2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, carry, i)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mcarries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-511cf3d3b023>\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(i, n)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnfilteredStackTrace\u001b[0m: TypeError: unhashable type: 'DeviceArray'\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-efa703337a88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# model = CharRNN(state_size, len(char_to_id))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCharRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_to_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhippo_order_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_carry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model state size: {model.state_size}, vocab size: {model.vocab_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-8b726afddee2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, carry, i)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcarry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mcarries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-77-511cf3d3b023>\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(i, n)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'DeviceArray'"
          ]
        }
      ],
      "source": [
        "state_size = 8\n",
        "\n",
        "# randomness is handled using explicit keys in Jax\n",
        "key, subkey = jax.random.split(key)\n",
        "\n",
        "hidden_size = 3\n",
        "hippo_order_N = 2\n",
        "batch_size = 20\n",
        "\n",
        "# model = CharRNN(state_size, len(char_to_id))\n",
        "model = CharRNN(state_size, len(char_to_id), hidden_size, hippo_order_N, batch_size)\n",
        "params = model.init(subkey, model.initial_carry(batch_size), model.initial_state(batch_size))\n",
        "\n",
        "print(f\"Model state size: {model.state_size}, vocab size: {model.vocab_size}\")\n",
        "# output: Model state size: 8, vocab size: 5\n",
        "\n",
        "# run a single example through the model to test that it works\n",
        "new_state, predictions = model.apply(params, model.initial_carry(), model.init_state())\n",
        "assert predictions.shape[0] == model.vocab_size\n",
        "\n",
        "# calling sample on random model leads to random output\n",
        "sample(model, params, (char_to_id, id_to_char), \"abc\", max_length=10)\n",
        "# output: 'abcadbaadbadd'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DHrf5W0_WwMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeJktgL0RXa3"
      },
      "outputs": [],
      "source": [
        "def chunker(seq, size):\n",
        "    \"\"\"\n",
        "    chunks a sequences into two subsequences\n",
        "    one for inputs, another for targets, by\n",
        "    shifting the input by 1\n",
        "    \"\"\"\n",
        "    n = len(seq)\n",
        "    p = 0\n",
        "    while p + 1 <= n:\n",
        "        # ensure the last chunk is of equal size\n",
        "        yield seq[p : min(n - 1, p + size)], seq[(p + 1) : (p + size + 1)]\n",
        "        p += size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi94Fu1dRXa4"
      },
      "outputs": [],
      "source": [
        "def rnn_loss(params, model, carries, inputs, targets):\n",
        "    # use lax.scan to efficiently generate a loop over the inputs\n",
        "    # this function returns the final state, and predictions for every step\n",
        "    # note: scan input array needs have shape [length, 1]\n",
        "    final_state, predictions = jax.lax.scan(\n",
        "        lambda carry, input: model.apply(params, carry, input), carries, np.array([inputs]).T\n",
        "    )\n",
        "    loss = np.mean(jax.vmap(optax.softmax_cross_entropy)(predictions, np.array([targets]).T))\n",
        "    return loss, final_state\n",
        "\n",
        "\n",
        "# we want both the loss an gradient, we set has_aux because rnn_loss also return final state\n",
        "# use static_argnums=1 to indicate that the model is static;\n",
        "# a different model input will require recomplication\n",
        "# finally, we jit the function to improve runtime\n",
        "rnn_loss_grad = jax.jit(jax.value_and_grad(rnn_loss, has_aux=True), static_argnums=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOlsbCBVRXa4"
      },
      "outputs": [],
      "source": [
        "def batch_step(model, optimizer, state, inputs, targets):\n",
        "    (loss, state), grad = rnn_loss_grad(optimizer.target, model, state, inputs, targets)\n",
        "    new_optimizer = optimizer.apply_gradient(grad)\n",
        "    return new_optimizer, loss, state\n",
        "\n",
        "\n",
        "def epoch_step(model, optimizer, data, batch_size):\n",
        "    state = model.init_state()\n",
        "    total_loss = 0\n",
        "    for n, (inputs, targets) in enumerate(chunker(data, batch_size)):\n",
        "        optimizer, loss, state = batch_step(model, optimizer, state, inputs, targets)\n",
        "\n",
        "        total_loss += loss\n",
        "    return optimizer, total_loss / (n + 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o30Mul0PRXa4"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    pass\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 ('jax-pytorch')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "dbeba54f39f0ad863615cd2814766ffd78084a8276e5c331aa23b4d5ff4f068c"
      }
    },
    "colab": {
      "name": "rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}