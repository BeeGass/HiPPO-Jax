{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiPPO Matrices\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Loading In Necessary Packages](#load-packages)\n",
    "    * [Instantiate The HiPPO Matrix](#instantiate-the-hippo-matrix)\n",
    "        * [Translated Legendre (LegT)](#translated-legendre-legt)\n",
    "            * [LegT](#legt)\n",
    "            * [LMU](#lmu)\n",
    "        * [Translated Laguerre (LagT)](#translated-laguerre-lagt)\n",
    "        * [Scaled Legendre (LegS)](#scaled-legendre-legs)\n",
    "        * [Fourier Basis](#fourier-basis)\n",
    "            * [Fourier Recurrent Unit (FRU)](#fourier-recurrent-unit-fru)\n",
    "            * [Truncated Fourier (FouT)](#truncated-fourier-fout)\n",
    "            * [Fourier With Decay (FourD)](#fourier-with-decay-fourd)\n",
    "    * [Utilities For Gu HiPPO Operator](#utilities-for-gu-hippo-operator)\n",
    "    * [Gu's HiPPO LegT Operator](#gus-hippo-legt-operator)\n",
    "    * [Gu's Scale invariant HiPPO LegS Operator](#gus-scale-invariant-hippo-legs-operator)\n",
    "    * [Implementation Of General HiPPO Operator](#implementation-of-general-hippo-operator)\n",
    "    * [Output](#output)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n",
      "The Device: gpu\n"
     ]
    }
   ],
   "source": [
    "## import packages\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from flax import linen as jnn\n",
    "\n",
    "from jax.nn.initializers import lecun_normal, uniform\n",
    "from jax.numpy.linalg import eig, inv, matrix_power\n",
    "from jax.scipy.signal import convolve\n",
    "\n",
    "# import modules \n",
    "from src.models.hippo.gu_transition import GuTransMatrix\n",
    "from src.data.process import moving_window, rolling_window\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "from scipy import linalg as la\n",
    "from scipy import signal\n",
    "from scipy import special as ss\n",
    "\n",
    "import math\n",
    "\n",
    "print(jax.devices())\n",
    "print(f\"The Device: {jax.lib.xla_bridge.get_backend().platform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS enabled: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"MPS enabled: {torch.backends.mps.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=150)\n",
    "np.set_printoptions(linewidth=150)\n",
    "jnp.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1701\n",
    "key = jax.random.PRNGKey(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_copies = 5\n",
    "rng, key2, key3, key4, key5 = jax.random.split(key, num=num_copies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate The HiPPO Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransMatrix:\n",
    "    def __init__(\n",
    "        self, N, measure=\"legs\", lambda_n=1, fourier_type=\"fru\", alpha=0, beta=1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Instantiates the HiPPO matrix of a given order using a particular measure.\n",
    "        Args:\n",
    "            N (int): Order of coefficients to describe the orthogonal polynomial that is the HiPPO projection.\n",
    "            v (str): choose between this repo's implementation or hazy research's implementation.\n",
    "            measure (str):\n",
    "                choose between\n",
    "                    - HiPPO w/ Translated Legendre (LegT) - legt\n",
    "                    - HiPPO w/ Translated Laguerre (LagT) - lagt\n",
    "                    - HiPPO w/ Scaled Legendre (LegS) - legs\n",
    "                    - HiPPO w/ Fourier basis - fourier\n",
    "                        - FRU: Fourier Recurrent Unit\n",
    "                        - FouT: Translated Fourier\n",
    "            lambda_n (int): The amount of tilt applied to the HiPPO-LegS basis, determines between LegS and LMU.\n",
    "            fourier_type (str): chooses between the following:\n",
    "                - FRU: Fourier Recurrent Unit - fru\n",
    "                - FouT: Translated Fourier - fout\n",
    "                - FourD: Fourier Decay - fourd\n",
    "            alpha (float): The order of the Laguerre basis.\n",
    "            beta (float): The scale of the Laguerre basis.\n",
    "\n",
    "        Returns:\n",
    "            A (jnp.ndarray): The HiPPO matrix multiplied by -1.\n",
    "            B (jnp.ndarray): The other corresponding state space matrix.\n",
    "\n",
    "        \"\"\"\n",
    "        A = None\n",
    "        B = None\n",
    "        if measure == \"legt\":\n",
    "            A, B = self.build_LegT(N=N, lambda_n=lambda_n)\n",
    "\n",
    "        elif measure == \"lagt\":\n",
    "            A, B = self.build_LagT(alpha=alpha, beta=beta, N=N)\n",
    "\n",
    "        elif measure == \"legs\":\n",
    "            A, B = self.build_LegS(N=N)\n",
    "\n",
    "        elif measure == \"fourier\":\n",
    "            A, B = self.build_Fourier(N=N, fourier_type=fourier_type)\n",
    "\n",
    "        elif measure == \"random\":\n",
    "            A = jnp.random.randn(N, N) / N\n",
    "            B = jnp.random.randn(N, 1)\n",
    "\n",
    "        elif measure == \"diagonal\":\n",
    "            A = -jnp.diag(jnp.exp(jnp.random.randn(N)))\n",
    "            B = jnp.random.randn(N, 1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid HiPPO type\")\n",
    "\n",
    "        self.A_matrix = (A.copy()).astype(jnp.float32)\n",
    "        self.B_matrix = (B.copy()).astype(jnp.float32)\n",
    "\n",
    "    # Translated Legendre (LegT) - vectorized\n",
    "    @staticmethod\n",
    "    def build_LegT(N, lambda_n=1):\n",
    "        \"\"\"\n",
    "        The, vectorized implementation of the, measure derived from the translated Legendre basis.\n",
    "\n",
    "        Args:\n",
    "            N (int): Order of coefficients to describe the orthogonal polynomial that is the HiPPO projection.\n",
    "            legt_type (str): Choice between the two different tilts of basis.\n",
    "                - legt: translated Legendre - 'legt'\n",
    "                - lmu: Legendre Memory Unit - 'lmu'\n",
    "\n",
    "        Returns:\n",
    "            A (jnp.ndarray): The A HiPPO matrix.\n",
    "            B (jnp.ndarray): The B HiPPO matrix.\n",
    "\n",
    "        \"\"\"\n",
    "        q = jnp.arange(N, dtype=jnp.float32)\n",
    "        k, n = jnp.meshgrid(q, q)\n",
    "        case = jnp.power(-1.0, (n - k))\n",
    "        A = None\n",
    "        B = None\n",
    "\n",
    "        if lambda_n == 1:\n",
    "            A_base = jnp.sqrt(2 * n + 1) * jnp.sqrt(2 * k + 1)\n",
    "            pre_D = jnp.sqrt(jnp.diag(2 * q + 1))\n",
    "            B = D = jnp.diag(pre_D)[:, None]\n",
    "            A = jnp.where(\n",
    "                k <= n, A_base, A_base * case\n",
    "            )  # if n >= k, then case_2 * A_base is used, otherwise A_base\n",
    "\n",
    "        elif lambda_n == 2:  # (jnp.sqrt(2*n+1) * jnp.power(-1, n)):\n",
    "            A_base = 2 * n + 1\n",
    "            B = jnp.diag((2 * q + 1) * jnp.power(-1, n))[:, None]\n",
    "            A = jnp.where(\n",
    "                k <= n, A_base * case, A_base\n",
    "            )  # if n >= k, then case_2 * A_base is used, otherwise A_base\n",
    "\n",
    "        return -A, B\n",
    "\n",
    "    # Translated Laguerre (LagT) - non-vectorized\n",
    "    @staticmethod\n",
    "    def build_LagT(alpha, beta, N):\n",
    "        \"\"\"\n",
    "        The, vectorized implementation of the, measure derived from the translated Laguerre basis.\n",
    "\n",
    "        Args:\n",
    "            alpha (float): The order of the Laguerre basis.\n",
    "            beta (float): The scale of the Laguerre basis.\n",
    "            N (int): Order of coefficients to describe the orthogonal polynomial that is the HiPPO projection.\n",
    "\n",
    "        Returns:\n",
    "            A (jnp.ndarray): The A HiPPO matrix.\n",
    "            B (jnp.ndarray): The B HiPPO matrix.\n",
    "\n",
    "        \"\"\"\n",
    "        L = jnp.exp(\n",
    "            0.5\n",
    "            * (ss.gammaln(jnp.arange(N) + alpha + 1) - ss.gammaln(jnp.arange(N) + 1))\n",
    "        )\n",
    "        inv_L = 1.0 / L[:, None]\n",
    "        pre_A = (jnp.eye(N) * ((1 + beta) / 2)) + jnp.tril(jnp.ones((N, N)), -1)\n",
    "        pre_B = ss.binom(alpha + jnp.arange(N), jnp.arange(N))[:, None]\n",
    "\n",
    "        A = -inv_L * pre_A * L[None, :]\n",
    "        B = (\n",
    "            jnp.exp(-0.5 * ss.gammaln(1 - alpha))\n",
    "            * jnp.power(beta, (1 - alpha) / 2)\n",
    "            * inv_L\n",
    "            * pre_B\n",
    "        )\n",
    "\n",
    "        return A, B\n",
    "\n",
    "    # Scaled Legendre (LegS) vectorized\n",
    "    @staticmethod\n",
    "    def build_LegS(N):\n",
    "        \"\"\"\n",
    "        The, vectorized implementation of the, measure derived from the Scaled Legendre basis.\n",
    "\n",
    "        Args:\n",
    "            N (int): Order of coefficients to describe the orthogonal polynomial that is the HiPPO projection.\n",
    "\n",
    "        Returns:\n",
    "            A (jnp.ndarray): The A HiPPO matrix.\n",
    "            B (jnp.ndarray): The B HiPPO matrix.\n",
    "\n",
    "        \"\"\"\n",
    "        q = jnp.arange(N, dtype=jnp.float32)\n",
    "        k, n = jnp.meshgrid(q, q)\n",
    "        pre_D = jnp.sqrt(jnp.diag(2 * q + 1))\n",
    "        B = D = jnp.diag(pre_D)[:, None]\n",
    "\n",
    "        A_base = jnp.sqrt(2 * n + 1) * jnp.sqrt(2 * k + 1)\n",
    "\n",
    "        A = jnp.where(n > k, A_base, jnp.where(n == k, n + 1, 0.0))\n",
    "\n",
    "        return -A.astype(jnp.float32), B.astype(jnp.float32)\n",
    "\n",
    "    # Fourier Basis OPs and functions - vectorized\n",
    "    @staticmethod\n",
    "    def build_Fourier(N, fourier_type=\"fru\"):\n",
    "        \"\"\"\n",
    "        Vectorized measure implementations derived from fourier basis.\n",
    "\n",
    "        Args:\n",
    "            N (int): Order of coefficients to describe the orthogonal polynomial that is the HiPPO projection.\n",
    "            fourier_type (str): The type of Fourier measure.\n",
    "                - FRU: Fourier Recurrent Unit - fru\n",
    "                - FouT: truncated Fourier - fout\n",
    "                - fouD: decayed Fourier - foud\n",
    "\n",
    "        Returns:\n",
    "            A (jnp.ndarray): The A HiPPO matrix.\n",
    "            B (jnp.ndarray): The B HiPPO matrix.\n",
    "\n",
    "        \"\"\"\n",
    "        A = jnp.diag(\n",
    "            jnp.stack([jnp.zeros(N // 2), jnp.zeros(N // 2)], axis=-1).reshape(-1)[1:],\n",
    "            1,\n",
    "        )\n",
    "        B = jnp.zeros(A.shape[1], dtype=jnp.float32)\n",
    "\n",
    "        B = B.at[0::2].set(jnp.sqrt(2))\n",
    "        B = B.at[0].set(1)\n",
    "\n",
    "        q = jnp.arange(A.shape[1], dtype=jnp.float32)\n",
    "        k, n = jnp.meshgrid(q, q)\n",
    "\n",
    "        n_odd = n % 2 == 0\n",
    "        k_odd = k % 2 == 0\n",
    "\n",
    "        case_1 = (n == k) & (n == 0)\n",
    "        case_2_3 = ((k == 0) & (n_odd)) | ((n == 0) & (k_odd))\n",
    "        case_4 = (n_odd) & (k_odd)\n",
    "        case_5 = (n - k == 1) & (k_odd)\n",
    "        case_6 = (k - n == 1) & (n_odd)\n",
    "\n",
    "        if fourier_type == \"fru\":  # Fourier Recurrent Unit (FRU) - vectorized\n",
    "            A = jnp.where(\n",
    "                case_1,\n",
    "                -1.0,\n",
    "                jnp.where(\n",
    "                    case_2_3,\n",
    "                    -jnp.sqrt(2),\n",
    "                    jnp.where(\n",
    "                        case_4,\n",
    "                        -2,\n",
    "                        jnp.where(\n",
    "                            case_5,\n",
    "                            jnp.pi * (n // 2),\n",
    "                            jnp.where(case_6, -jnp.pi * (k // 2), 0.0),\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        elif fourier_type == \"fout\":  # truncated Fourier (FouT) - vectorized\n",
    "            A = jnp.where(\n",
    "                case_1,\n",
    "                -1.0,\n",
    "                jnp.where(\n",
    "                    case_2_3,\n",
    "                    -jnp.sqrt(2),\n",
    "                    jnp.where(\n",
    "                        case_4,\n",
    "                        -2,\n",
    "                        jnp.where(\n",
    "                            case_5,\n",
    "                            jnp.pi * (n // 2),\n",
    "                            jnp.where(case_6, -jnp.pi * (k // 2), 0.0),\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            A = 2 * A\n",
    "            B = 2 * B\n",
    "\n",
    "        elif fourier_type == \"foud\":\n",
    "            A = jnp.where(\n",
    "                case_1,\n",
    "                -1.0,\n",
    "                jnp.where(\n",
    "                    case_2_3,\n",
    "                    -jnp.sqrt(2),\n",
    "                    jnp.where(\n",
    "                        case_4,\n",
    "                        -2,\n",
    "                        jnp.where(\n",
    "                            case_5,\n",
    "                            2 * jnp.pi * (n // 2),\n",
    "                            jnp.where(case_6, 2 * -jnp.pi * (k // 2), 0.0),\n",
    "                        ),\n",
    "                    ),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            A = 0.5 * A\n",
    "            B = 0.5 * B\n",
    "\n",
    "        B = B[:, None]\n",
    "\n",
    "        return A.astype(jnp.float32), B.astype(jnp.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translated Legendre (LegT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LegT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LegT():\n",
    "    legt_matrices = TransMatrix(N=8, measure=\"legt\", lambda_n=1.0)\n",
    "    A, B = legt_matrices.A_matrix, legt_matrices.B_matrix\n",
    "    gu_legt_matrices = GuTransMatrix(N=8, measure=\"legt\", lambda_n=1.0)\n",
    "    gu_A, gu_B = gu_legt_matrices.A_matrix, gu_legt_matrices.B_matrix\n",
    "    print(f\"A:\\n\", A)\n",
    "    print(f\"Gu's A:\\n\", gu_A)\n",
    "    print(f\"B:\\n\", B)\n",
    "    print(f\"Gu's B:\\n\", gu_B)\n",
    "    assert jnp.allclose(A, gu_A)\n",
    "    assert jnp.allclose(B, gu_B)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[ -1.          1.7320508  -2.2360678   2.6457512  -3.          3.3166246  -3.6055512   3.8729832]\n",
      " [ -1.7320508  -3.          3.872983   -4.5825753   5.196152   -5.744562    6.244998   -6.708204 ]\n",
      " [ -2.2360678  -3.872983   -4.999999    5.916079   -6.7082033   7.4161973  -8.062257    8.660253 ]\n",
      " [ -2.6457512  -4.5825753  -5.916079   -6.9999995   7.937254   -8.774963    9.5393915 -10.24695  ]\n",
      " [ -3.         -5.196152   -6.7082033  -7.937254   -9.          9.949874  -10.816654   11.61895  ]\n",
      " [ -3.3166246  -5.744562   -7.4161973  -8.774963   -9.949874  -10.999999   11.958261  -12.845232 ]\n",
      " [ -3.6055512  -6.244998   -8.062257   -9.5393915 -10.816654  -11.958261  -13.         13.964239 ]\n",
      " [ -3.8729832  -6.708204   -8.660253  -10.24695   -11.61895   -12.845232  -13.964239  -14.999999 ]]\n",
      "Gu's A:\n",
      " [[ -1.          1.7320508  -2.2360678   2.6457512  -3.          3.3166246  -3.6055512   3.8729832]\n",
      " [ -1.7320508  -3.          3.872983   -4.5825753   5.196152   -5.744562    6.244998   -6.708204 ]\n",
      " [ -2.2360678  -3.872983   -4.999999    5.916079   -6.7082033   7.4161973  -8.062257    8.660253 ]\n",
      " [ -2.6457512  -4.5825753  -5.916079   -6.9999995   7.937254   -8.774963    9.5393915 -10.24695  ]\n",
      " [ -3.         -5.196152   -6.7082033  -7.937254   -9.          9.949874  -10.816654   11.61895  ]\n",
      " [ -3.3166246  -5.744562   -7.4161973  -8.774963   -9.949874  -10.999999   11.958261  -12.845232 ]\n",
      " [ -3.6055512  -6.244998   -8.062257   -9.5393915 -10.816654  -11.958261  -13.         13.964239 ]\n",
      " [ -3.8729832  -6.708204   -8.660253  -10.24695   -11.61895   -12.845232  -13.964239  -14.999999 ]]\n",
      "B:\n",
      " [[1.       ]\n",
      " [1.7320508]\n",
      " [2.2360678]\n",
      " [2.6457512]\n",
      " [3.       ]\n",
      " [3.3166246]\n",
      " [3.6055512]\n",
      " [3.8729832]]\n",
      "Gu's B:\n",
      " [[1.       ]\n",
      " [1.7320508]\n",
      " [2.2360678]\n",
      " [2.6457512]\n",
      " [3.       ]\n",
      " [3.3166246]\n",
      " [3.6055512]\n",
      " [3.8729832]]\n"
     ]
    }
   ],
   "source": [
    "test_LegT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LMU():\n",
    "    lmu_matrices = TransMatrix(\n",
    "        N=8, measure=\"legt\", lambda_n=2.0\n",
    "    )  # change lambda so resulting matrix is in the form of LMU\n",
    "    A, B = lmu_matrices.A_matrix, lmu_matrices.B_matrix\n",
    "    gu_lmu_matrices = GuTransMatrix(\n",
    "        N=8, measure=\"legt\", lambda_n=2.0\n",
    "    )  # change lambda so resulting matrix is in the form of LMU\n",
    "    gu_A, gu_B = gu_lmu_matrices.A_matrix, gu_lmu_matrices.B_matrix\n",
    "    print(f\"A:\\n\", A)\n",
    "    print(f\"Gu's A:\\n\", gu_A)\n",
    "    print(f\"B:\\n\", B)\n",
    "    print(f\"Gu's B:\\n\", gu_B)\n",
    "    assert jnp.allclose(A, gu_A)\n",
    "    assert jnp.allclose(B, gu_B)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[ -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -3.  -3.  -3.  -3.  -3.  -3.  -3.]\n",
      " [ -5.   5.  -5.  -5.  -5.  -5.  -5.  -5.]\n",
      " [  7.  -7.   7.  -7.  -7.  -7.  -7.  -7.]\n",
      " [ -9.   9.  -9.   9.  -9.  -9.  -9.  -9.]\n",
      " [ 11. -11.  11. -11.  11. -11. -11. -11.]\n",
      " [-13.  13. -13.  13. -13.  13. -13. -13.]\n",
      " [ 15. -15.  15. -15.  15. -15.  15. -15.]]\n",
      "Gu's A:\n",
      " [[ -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -3.  -3.  -3.  -3.  -3.  -3.  -3.]\n",
      " [ -5.   5.  -5.  -5.  -5.  -5.  -5.  -5.]\n",
      " [  7.  -7.   7.  -7.  -7.  -7.  -7.  -7.]\n",
      " [ -9.   9.  -9.   9.  -9.  -9.  -9.  -9.]\n",
      " [ 11. -11.  11. -11.  11. -11. -11. -11.]\n",
      " [-13.  13. -13.  13. -13.  13. -13. -13.]\n",
      " [ 15. -15.  15. -15.  15. -15.  15. -15.]]\n",
      "B:\n",
      " [[  1.]\n",
      " [ -3.]\n",
      " [  5.]\n",
      " [ -7.]\n",
      " [  9.]\n",
      " [-11.]\n",
      " [ 13.]\n",
      " [-15.]]\n",
      "Gu's B:\n",
      " [[  1.]\n",
      " [ -3.]\n",
      " [  5.]\n",
      " [ -7.]\n",
      " [  9.]\n",
      " [-11.]\n",
      " [ 13.]\n",
      " [-15.]]\n"
     ]
    }
   ],
   "source": [
    "test_LMU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translated Laguerre (LagT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LagT():\n",
    "    lagt_matrices = TransMatrix(\n",
    "        N=8,\n",
    "        measure=\"lagt\",\n",
    "        alpha=0.0,  # change resulting tilt through alpha and beta\n",
    "        beta=1.0,\n",
    "    )  # change resulting tilt through alpha and beta\n",
    "    A, B = lagt_matrices.A_matrix, lagt_matrices.B_matrix\n",
    "    gu_lagt_matrices = GuTransMatrix(\n",
    "        N=8,\n",
    "        measure=\"lagt\",\n",
    "        alpha=0.0,  # change resulting tilt through alpha and beta\n",
    "        beta=1.0,\n",
    "    )  # change resulting tilt through alpha and beta\n",
    "    gu_A, gu_B = gu_lagt_matrices.A_matrix, gu_lagt_matrices.B_matrix\n",
    "    print(f\"A:\\n\", A)\n",
    "    print(f\"Gu's A:\\n\", gu_A)\n",
    "    print(f\"B:\\n\", B)\n",
    "    print(f\"Gu's B:\\n\", gu_B)\n",
    "    assert jnp.allclose(A, gu_A)\n",
    "    assert jnp.allclose(B, gu_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[-1.         -0.         -0.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -0.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.         -0.        ]\n",
      " [-0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -1.        ]]\n",
      "Gu's A:\n",
      " [[-1.         -0.         -0.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -0.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.         -0.        ]\n",
      " [-0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -1.        ]]\n",
      "B:\n",
      " [[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999976]]\n",
      "Gu's B:\n",
      " [[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999976]]\n"
     ]
    }
   ],
   "source": [
    "test_LagT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Legendre (LegS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_LegS():\n",
    "    legs_matrices = TransMatrix(N=8, measure=\"legs\")\n",
    "    A, B = legs_matrices.A_matrix, legs_matrices.B_matrix\n",
    "    gu_legs_matrices = GuTransMatrix(N=8, measure=\"legs\")\n",
    "    gu_A, gu_B = gu_legs_matrices.A_matrix, gu_legs_matrices.B_matrix\n",
    "    print(f\"A:\\n\", A)\n",
    "    print(f\"Gu's A:\\n\", gu_A)\n",
    "    print(f\"B:\\n\", B)\n",
    "    print(f\"Gu's B:\\n\", gu_B)\n",
    "    assert jnp.allclose(A, gu_A)\n",
    "    assert jnp.allclose(B, gu_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[ -1.         -0.         -0.         -0.         -0.         -0.         -0.         -0.       ]\n",
      " [ -1.7320508  -2.         -0.         -0.         -0.         -0.         -0.         -0.       ]\n",
      " [ -2.2360678  -3.872983   -3.         -0.         -0.         -0.         -0.         -0.       ]\n",
      " [ -2.6457512  -4.5825753  -5.916079   -4.         -0.         -0.         -0.         -0.       ]\n",
      " [ -3.         -5.196152   -6.7082033  -7.937254   -5.         -0.         -0.         -0.       ]\n",
      " [ -3.3166246  -5.744562   -7.4161973  -8.774963   -9.949874   -6.         -0.         -0.       ]\n",
      " [ -3.6055512  -6.244998   -8.062257   -9.5393915 -10.816654  -11.958261   -7.         -0.       ]\n",
      " [ -3.8729832  -6.708204   -8.660253  -10.24695   -11.61895   -12.845232  -13.964239   -8.       ]]\n",
      "Gu's A:\n",
      " [[ -1.          0.          0.          0.          0.          0.          0.          0.       ]\n",
      " [ -1.7320508  -1.9999999   0.          0.          0.          0.          0.          0.       ]\n",
      " [ -2.2360678  -3.872983   -3.          0.          0.          0.          0.          0.       ]\n",
      " [ -2.6457512  -4.582576   -5.91608    -4.          0.          0.          0.          0.       ]\n",
      " [ -3.         -5.196152   -6.7082047  -7.9372544  -5.          0.          0.          0.       ]\n",
      " [ -3.3166246  -5.744562   -7.4161987  -8.774965   -9.949874   -6.          0.          0.       ]\n",
      " [ -3.6055512  -6.244998   -8.062259   -9.539392  -10.816654  -11.958261   -7.          0.       ]\n",
      " [ -3.8729832  -6.708204   -8.6602545 -10.246951  -11.61895   -12.845232  -13.964239   -7.9999995]]\n",
      "B:\n",
      " [[1.       ]\n",
      " [1.7320508]\n",
      " [2.2360678]\n",
      " [2.6457512]\n",
      " [3.       ]\n",
      " [3.3166246]\n",
      " [3.6055512]\n",
      " [3.8729832]]\n",
      "Gu's B:\n",
      " [[1.       ]\n",
      " [1.7320508]\n",
      " [2.2360678]\n",
      " [2.6457512]\n",
      " [3.       ]\n",
      " [3.3166246]\n",
      " [3.6055512]\n",
      " [3.8729832]]\n"
     ]
    }
   ],
   "source": [
    "test_LegS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Recurrent Unit (FRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_FRU():\n",
    "    fru_matrices = TransMatrix(N=8, measure=\"fourier\", fourier_type=\"fru\")\n",
    "    A, B = fru_matrices.A_matrix, fru_matrices.B_matrix\n",
    "    gu_fru_matrices = GuTransMatrix(N=8, measure=\"fourier\", fourier_type=\"fru\")\n",
    "    gu_A, gu_B = gu_fru_matrices.A_matrix, gu_fru_matrices.B_matrix\n",
    "    print(f\"A:\\n\", A)\n",
    "    print(f\"Gu's A:\\n\", gu_A)\n",
    "    print(f\"B:\\n\", B)\n",
    "    print(f\"Gu's B:\\n\", gu_B)\n",
    "    assert jnp.allclose(A, gu_A)\n",
    "    assert jnp.allclose(B, gu_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[-1.        -0.        -1.4142135  0.        -1.4142135  0.        -1.4142135  0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.       ]\n",
      " [-1.4142135  0.        -2.        -3.1415927 -2.         0.        -2.         0.       ]\n",
      " [ 0.         0.         3.1415927  0.         0.         0.         0.         0.       ]\n",
      " [-1.4142135  0.        -2.         0.        -2.        -6.2831855 -2.         0.       ]\n",
      " [ 0.         0.         0.         0.         6.2831855  0.         0.         0.       ]\n",
      " [-1.4142135  0.        -2.         0.        -2.         0.        -2.        -9.424778 ]\n",
      " [ 0.         0.         0.         0.         0.         0.         9.424778   0.       ]]\n",
      "Gu's A:\n",
      " [[-1.         0.        -1.4142135  0.        -1.4142135  0.        -1.4142135  0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.       ]\n",
      " [-1.4142135  0.        -1.9999999 -3.1415927 -1.9999999  0.        -1.9999999  0.       ]\n",
      " [ 0.         0.         3.1415927  0.         0.         0.         0.         0.       ]\n",
      " [-1.4142135  0.        -1.9999999  0.        -1.9999999 -6.2831855 -1.9999999  0.       ]\n",
      " [ 0.         0.         0.         0.         6.2831855  0.         0.         0.       ]\n",
      " [-1.4142135  0.        -1.9999999  0.        -1.9999999  0.        -1.9999999 -9.424778 ]\n",
      " [ 0.         0.         0.         0.         0.         0.         9.424778   0.       ]]\n",
      "B:\n",
      " [[1.       ]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]]\n",
      "Gu's B:\n",
      " [[1.       ]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]]\n"
     ]
    }
   ],
   "source": [
    "test_FRU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated Fourier (FouT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_FouT():\n",
    "    fout_matrices = TransMatrix(N=8, measure=\"fourier\", fourier_type=\"fout\")\n",
    "    A, B = fout_matrices.A_matrix, fout_matrices.B_matrix\n",
    "    gu_fout_matrices = GuTransMatrix(N=8, measure=\"fourier\", fourier_type=\"fout\")\n",
    "    gu_A, gu_B = gu_fout_matrices.A_matrix, gu_fout_matrices.B_matrix\n",
    "    print(f\"A:\\n\", A)\n",
    "    print(f\"Gu's A:\\n\", gu_A)\n",
    "    print(f\"B:\\n\", B)\n",
    "    print(f\"Gu's B:\\n\", gu_B)\n",
    "    assert jnp.allclose(A, gu_A)\n",
    "    assert jnp.allclose(B, gu_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[ -2.         -0.         -2.828427    0.         -2.828427    0.         -2.828427    0.       ]\n",
      " [  0.          0.          0.          0.          0.          0.          0.          0.       ]\n",
      " [ -2.828427    0.         -4.         -6.2831855  -4.          0.         -4.          0.       ]\n",
      " [  0.          0.          6.2831855   0.          0.          0.          0.          0.       ]\n",
      " [ -2.828427    0.         -4.          0.         -4.        -12.566371   -4.          0.       ]\n",
      " [  0.          0.          0.          0.         12.566371    0.          0.          0.       ]\n",
      " [ -2.828427    0.         -4.          0.         -4.          0.         -4.        -18.849556 ]\n",
      " [  0.          0.          0.          0.          0.          0.         18.849556    0.       ]]\n",
      "Gu's A:\n",
      " [[ -2.          0.         -2.828427    0.         -2.828427    0.         -2.828427    0.       ]\n",
      " [  0.          0.          0.          0.          0.          0.          0.          0.       ]\n",
      " [ -2.828427    0.         -3.9999998  -6.2831855  -3.9999998   0.         -3.9999998   0.       ]\n",
      " [  0.          0.          6.2831855   0.          0.          0.          0.          0.       ]\n",
      " [ -2.828427    0.         -3.9999998   0.         -3.9999998 -12.566371   -3.9999998   0.       ]\n",
      " [  0.          0.          0.          0.         12.566371    0.          0.          0.       ]\n",
      " [ -2.828427    0.         -3.9999998   0.         -3.9999998   0.         -3.9999998 -18.849556 ]\n",
      " [  0.          0.          0.          0.          0.          0.         18.849556    0.       ]]\n",
      "B:\n",
      " [[2.      ]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]]\n",
      "Gu's B:\n",
      " [[2.      ]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]]\n"
     ]
    }
   ],
   "source": [
    "test_FouT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier With Decay (FourD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_FouD():\n",
    "    the_measure = \"fourier\"\n",
    "    fourier_type = \"foud\"\n",
    "    foud_matrices = TransMatrix(N=8, measure=the_measure, fourier_type=fourier_type)\n",
    "    A, B = foud_matrices.A_matrix, foud_matrices.B_matrix\n",
    "    gu_foud_matrices = GuTransMatrix(N=8, measure=\"fourier\", fourier_type=\"foud\")\n",
    "    gu_A, gu_B = gu_foud_matrices.A_matrix, gu_foud_matrices.B_matrix\n",
    "    print(f\"A:\\n\", A)\n",
    "    print(f\"Gu's A:\\n\", gu_A)\n",
    "    print(f\"B:\\n\", B)\n",
    "    print(f\"Gu's B:\\n\", gu_B)\n",
    "    assert jnp.allclose(A, gu_A)\n",
    "    assert jnp.allclose(B, gu_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[-0.5        -0.         -0.70710677  0.         -0.70710677  0.         -0.70710677  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [-0.70710677  0.         -1.         -3.1415927  -1.          0.         -1.          0.        ]\n",
      " [ 0.          0.          3.1415927   0.          0.          0.          0.          0.        ]\n",
      " [-0.70710677  0.         -1.          0.         -1.         -6.2831855  -1.          0.        ]\n",
      " [ 0.          0.          0.          0.          6.2831855   0.          0.          0.        ]\n",
      " [-0.70710677  0.         -1.          0.         -1.          0.         -1.         -9.424778  ]\n",
      " [ 0.          0.          0.          0.          0.          0.          9.424778    0.        ]]\n",
      "Gu's A:\n",
      " [[-0.5         0.         -0.70710677  0.         -0.70710677  0.         -0.70710677  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [-0.70710677  0.         -0.99999994 -3.1415927  -0.99999994  0.         -0.99999994  0.        ]\n",
      " [ 0.          0.          3.1415927   0.          0.          0.          0.          0.        ]\n",
      " [-0.70710677  0.         -0.99999994  0.         -0.99999994 -6.2831855  -0.99999994  0.        ]\n",
      " [ 0.          0.          0.          0.          6.2831855   0.          0.          0.        ]\n",
      " [-0.70710677  0.         -0.99999994  0.         -0.99999994  0.         -0.99999994 -9.424778  ]\n",
      " [ 0.          0.          0.          0.          0.          0.          9.424778    0.        ]]\n",
      "B:\n",
      " [[0.5       ]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]]\n",
      "Gu's B:\n",
      " [[0.5       ]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "test_FouD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities For Gu HiPPO Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_up(a, s=None, drop=True, dim=0):\n",
    "    assert dim == 0\n",
    "    if s is None:\n",
    "        s = torch.zeros_like(a[0, ...])\n",
    "    s = s.unsqueeze(dim)\n",
    "    if drop:\n",
    "        a = a[:-1, ...]\n",
    "    return torch.cat((s, a), dim=dim)\n",
    "\n",
    "def interleave(a, b, uneven=False, dim=0):\n",
    "    \"\"\" Interleave two tensors of same shape \"\"\"\n",
    "    # assert(a.shape == b.shape)\n",
    "    assert dim == 0 # TODO temporary to make handling uneven case easier\n",
    "    if dim < 0:\n",
    "        dim = N + dim\n",
    "    if uneven:\n",
    "        a_ = a[-1:, ...]\n",
    "        a = a[:-1, ...]\n",
    "    c = torch.stack((a, b), dim+1)\n",
    "    out_shape = list(a.shape)\n",
    "    out_shape[dim] *= 2\n",
    "    c = c.view(out_shape)\n",
    "    if uneven:\n",
    "        c = torch.cat((c, a_), dim=dim)\n",
    "    return c\n",
    "\n",
    "def batch_mult(A, u, has_batch=None):\n",
    "    \"\"\" Matrix mult A @ u with special case to save memory if u has additional batch dim\n",
    "\n",
    "    The batch dimension is assumed to be the second dimension\n",
    "    A : (L, ..., N, N)\n",
    "    u : (L, [B], ..., N)\n",
    "    has_batch: True, False, or None. If None, determined automatically\n",
    "\n",
    "    Output:\n",
    "    x : (L, [B], ..., N)\n",
    "      A @ u broadcasted appropriately\n",
    "    \"\"\"\n",
    "\n",
    "    if has_batch is None:\n",
    "        has_batch = len(u.shape) >= len(A.shape)\n",
    "\n",
    "    if has_batch:\n",
    "        u = u.permute([0] + list(range(2, len(u.shape))) + [1])\n",
    "    else:\n",
    "        u = u.unsqueeze(-1)\n",
    "    v = (A @ u)\n",
    "    if has_batch:\n",
    "        v = v.permute([0] + [len(u.shape)-1] + list(range(1, len(u.shape)-1)))\n",
    "    else:\n",
    "        v = v[..., 0]\n",
    "    return v\n",
    "\n",
    "\n",
    "\n",
    "### Main unrolling functions\n",
    "\n",
    "def unroll(A, u):\n",
    "    \"\"\"\n",
    "    A : (..., N, N) # TODO I think this can't take batch dimension?\n",
    "    u : (L, ..., N)\n",
    "    output : x (..., N) # TODO a lot of these shapes are wrong\n",
    "    x[i, ...] = A^{i} @ u[0, ...] + ... + A @ u[i-1, ...] + u[i, ...]\n",
    "    \"\"\"\n",
    "\n",
    "    m = u.new_zeros(u.shape[1:])\n",
    "    outputs = []\n",
    "    for u_ in torch.unbind(u, dim=0):\n",
    "        m = F.linear(m, A) + u_\n",
    "        outputs.append(m)\n",
    "\n",
    "    output = torch.stack(outputs, dim=0)\n",
    "    return output\n",
    "\n",
    "\n",
    "def parallel_unroll_recursive(A, u):\n",
    "    \"\"\" Bottom-up divide-and-conquer version of unroll. \"\"\"\n",
    "\n",
    "    # Main recursive function\n",
    "    def parallel_unroll_recursive_(A, u):\n",
    "        if u.shape[0] == 1:\n",
    "            return u\n",
    "\n",
    "        u_evens = u[0::2, ...]\n",
    "        u_odds = u[1::2, ...]\n",
    "\n",
    "        # u2 = F.linear(u_evens, A) + u_odds\n",
    "        u2 = (A @ u_evens.unsqueeze(-1)).squeeze(-1) + u_odds\n",
    "        A2 = A @ A\n",
    "\n",
    "        x_odds = parallel_unroll_recursive_(A2, u2)\n",
    "        # x_evens = F.linear(shift_up(x_odds), A) + u_evens\n",
    "        x_evens = (A @ shift_up(x_odds).unsqueeze(-1)).squeeze(-1) + u_evens\n",
    "\n",
    "        x = interleave(x_evens, x_odds, dim=0)\n",
    "        return x\n",
    "\n",
    "    # Pad u to power of 2\n",
    "    n = u.shape[0]\n",
    "    m = int(math.ceil(math.log(n)/math.log(2)))\n",
    "    N = 1 << m\n",
    "    u = torch.cat((u, u.new_zeros((N-u.shape[0],) + u.shape[1:] )), dim=0)\n",
    "\n",
    "    return parallel_unroll_recursive_(A, u)[:n, ...]\n",
    "\n",
    "\n",
    "\n",
    "def parallel_unroll_recursive_br(A, u):\n",
    "    \"\"\" Same as parallel_unroll_recursive but uses bit reversal for locality. \"\"\"\n",
    "\n",
    "    # Main recursive function\n",
    "    def parallel_unroll_recursive_br_(A, u):\n",
    "        n = u.shape[0]\n",
    "        if n == 1:\n",
    "            return u\n",
    "\n",
    "        m = n//2\n",
    "        u_0 = u[:m, ...]\n",
    "        u_1 = u[m:, ...]\n",
    "\n",
    "        u2 = F.linear(u_0, A) + u_1\n",
    "        A2 = A @ A\n",
    "\n",
    "        x_1 = parallel_unroll_recursive_br_(A2, u2)\n",
    "        x_0 = F.linear(shift_up(x_1), A) + u_0\n",
    "\n",
    "        # x = torch.cat((x_0, x_1), dim=0) # is there a way to do this with cat?\n",
    "        x = interleave(x_0, x_1, dim=0)\n",
    "        return x\n",
    "\n",
    "    # Pad u to power of 2\n",
    "    n = u.shape[0]\n",
    "    m = int(math.ceil(math.log(n)/math.log(2)))\n",
    "    N = 1 << m\n",
    "    u = torch.cat((u, u.new_zeros((N-u.shape[0],) + u.shape[1:] )), dim=0)\n",
    "\n",
    "    # Apply bit reversal\n",
    "    br = bitreversal_po2(N)\n",
    "    u = u[br, ...]\n",
    "\n",
    "    x = parallel_unroll_recursive_br_(A, u)\n",
    "    return x[:n, ...]\n",
    "\n",
    "def parallel_unroll_iterative(A, u):\n",
    "    \"\"\" Bottom-up divide-and-conquer version of unroll, implemented iteratively \"\"\"\n",
    "\n",
    "    # Pad u to power of 2\n",
    "    n = u.shape[0]\n",
    "    m = int(math.ceil(math.log(n)/math.log(2)))\n",
    "    N = 1 << m\n",
    "    u = torch.cat((u, u.new_zeros((N-u.shape[0],) + u.shape[1:] )), dim=0)\n",
    "\n",
    "    # Apply bit reversal\n",
    "    br = bitreversal_po2(N)\n",
    "    u = u[br, ...]\n",
    "\n",
    "    # Main recursive loop, flattened\n",
    "    us = [] # stores the u_0 terms in the recursive version\n",
    "    N_ = N\n",
    "    As = [] # stores the A matrices\n",
    "    for l in range(m):\n",
    "        N_ = N_ // 2\n",
    "        As.append(A)\n",
    "        u_0 = u[:N_, ...]\n",
    "        us.append(u_0)\n",
    "        u = F.linear(u_0, A) + u[N_:, ...]\n",
    "        A = A @ A\n",
    "    x_0 = []\n",
    "    x = u # x_1\n",
    "    for l in range(m-1, -1, -1):\n",
    "        x_0 = F.linear(shift_up(x), As[l]) + us[l]\n",
    "        x = interleave(x_0, x, dim=0)\n",
    "\n",
    "    return x[:n, ...]\n",
    "\n",
    "\n",
    "def variable_unroll_sequential(A, u, s=None, variable=True):\n",
    "    \"\"\" Unroll with variable (in time/length) transitions A.\n",
    "\n",
    "    A : ([L], ..., N, N) dimension L should exist iff variable is True\n",
    "    u : (L, [B], ..., N) updates\n",
    "    s : ([B], ..., N) start state\n",
    "    output : x (..., N)\n",
    "    x[i, ...] = A[i]..A[0] @ s + A[i..1] @ u[0] + ... + A[i] @ u[i-1] + u[i]\n",
    "    \"\"\"\n",
    "\n",
    "    if s is None:\n",
    "        s = torch.zeros_like(u[0])\n",
    "\n",
    "    if not variable:\n",
    "        A = A.expand((u.shape[0],) + A.shape)\n",
    "    has_batch = len(u.shape) >= len(A.shape)\n",
    "\n",
    "    outputs = []\n",
    "    for (A_, u_) in zip(torch.unbind(A, dim=0), torch.unbind(u, dim=0)):\n",
    "        # s = F.linear(s, A_) + u_\n",
    "        s = batch_mult(A_.unsqueeze(0), s.unsqueeze(0), has_batch)[0]\n",
    "        s = s + u_\n",
    "        outputs.append(s)\n",
    "\n",
    "    output = torch.stack(outputs, dim=0)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def variable_unroll(A, u, s=None, variable=True, recurse_limit=16):\n",
    "    \"\"\" Bottom-up divide-and-conquer version of variable_unroll. \"\"\"\n",
    "\n",
    "    if u.shape[0] <= recurse_limit:\n",
    "        return variable_unroll_sequential(A, u, s, variable)\n",
    "\n",
    "    if s is None:\n",
    "        s = torch.zeros_like(u[0])\n",
    "\n",
    "    uneven = u.shape[0] % 2 == 1\n",
    "    has_batch = len(u.shape) >= len(A.shape)\n",
    "\n",
    "    u_0 = u[0::2, ...]\n",
    "    u_1  = u[1::2, ...]\n",
    "\n",
    "    if variable:\n",
    "        A_0 = A[0::2, ...]\n",
    "        A_1  = A[1::2, ...]\n",
    "    else:\n",
    "        A_0 = A\n",
    "        A_1 = A\n",
    "\n",
    "    u_0_ = u_0\n",
    "    A_0_ = A_0\n",
    "    if uneven:\n",
    "        u_0_ = u_0[:-1, ...]\n",
    "        if variable:\n",
    "            A_0_ = A_0[:-1, ...]\n",
    "\n",
    "    u_10 = batch_mult(A_1, u_0_, has_batch)\n",
    "    u_10 = u_10 + u_1\n",
    "    A_10 = A_1 @ A_0_\n",
    "\n",
    "    # Recursive call\n",
    "    x_1 = variable_unroll(A_10, u_10, s, variable, recurse_limit)\n",
    "\n",
    "    x_0 = shift_up(x_1, s, drop=not uneven)\n",
    "    x_0 = batch_mult(A_0, x_0, has_batch)\n",
    "    x_0 = x_0 + u_0\n",
    "\n",
    "\n",
    "    x = interleave(x_0, x_1, uneven, dim=0) # For some reason this interleave is slower than in the (non-multi) unroll_recursive\n",
    "    return x\n",
    "\n",
    "def variable_unroll_general_sequential(A, u, s, op, variable=True):\n",
    "    \"\"\" Unroll with variable (in time/length) transitions A with general associative operation\n",
    "\n",
    "    A : ([L], ..., N, N) dimension L should exist iff variable is True\n",
    "    u : (L, [B], ..., N) updates\n",
    "    s : ([B], ..., N) start state\n",
    "    output : x (..., N)\n",
    "    x[i, ...] = A[i]..A[0] s + A[i..1] u[0] + ... + A[i] u[i-1] + u[i]\n",
    "    \"\"\"\n",
    "\n",
    "    if not variable:\n",
    "        A = A.expand((u.shape[0],) + A.shape)\n",
    "\n",
    "    outputs = []\n",
    "    for (A_, u_) in zip(torch.unbind(A, dim=0), torch.unbind(u, dim=0)):\n",
    "        s = op(A_, s)\n",
    "        s = s + u_\n",
    "        outputs.append(s)\n",
    "\n",
    "    output = torch.stack(outputs, dim=0)\n",
    "    return output\n",
    "\n",
    "def variable_unroll_matrix_sequential(A, u, s=None, variable=True):\n",
    "    if s is None:\n",
    "        s = torch.zeros_like(u[0])\n",
    "\n",
    "    if not variable:\n",
    "        A = A.expand((u.shape[0],) + A.shape)\n",
    "    # has_batch = len(u.shape) >= len(A.shape)\n",
    "\n",
    "    # op = lambda x, y: batch_mult(x.unsqueeze(0), y.unsqueeze(0), has_batch)[0]\n",
    "    op = lambda x, y: batch_mult(x.unsqueeze(0), y.unsqueeze(0))[0]\n",
    "\n",
    "    return variable_unroll_general_sequential(A, u, s, op, variable=True)\n",
    "\n",
    "def variable_unroll_toeplitz_sequential(A, u, s=None, variable=True, pad=False):\n",
    "    if s is None:\n",
    "        s = torch.zeros_like(u[0])\n",
    "\n",
    "    if not variable:\n",
    "        A = A.expand((u.shape[0],) + A.shape)\n",
    "    # has_batch = len(u.shape) >= len(A.shape)\n",
    "\n",
    "    # op = lambda x, y: batch_mult(x.unsqueeze(0), y.unsqueeze(0), has_batch)[0]\n",
    "    # op = lambda x, y: batch_mult(x.unsqueeze(0), y.unsqueeze(0))[0]\n",
    "\n",
    "    if pad:\n",
    "        n = A.shape[-1]\n",
    "        A = F.pad(A, (0, n))\n",
    "        u = F.pad(u, (0, n))\n",
    "        s = F.pad(s, (0, n))\n",
    "        ret = variable_unroll_general_sequential(A, u, s, triangular_toeplitz_multiply_padded, variable=True)\n",
    "        ret = ret[..., :n]\n",
    "        return ret\n",
    "\n",
    "    return variable_unroll_general_sequential(A, u, s, triangular_toeplitz_multiply, variable=True)\n",
    "\n",
    "\n",
    "\n",
    "### General parallel scan functions with generic binary composition operators\n",
    "\n",
    "def variable_unroll_general(A, u, s, op, compose_op=None, sequential_op=None, variable=True, recurse_limit=16):\n",
    "    \"\"\" Bottom-up divide-and-conquer version of variable_unroll.\n",
    "\n",
    "    compose is an optional function that defines how to compose A without multiplying by a leaf u\n",
    "    \"\"\"\n",
    "    print(f\"u shape: {u.shape}\")\n",
    "    if u.shape[0] <= recurse_limit:\n",
    "        if sequential_op is None:\n",
    "            sequential_op = op\n",
    "        return variable_unroll_general_sequential(A, u, s, sequential_op, variable)\n",
    "\n",
    "    if compose_op is None:\n",
    "        compose_op = op\n",
    "\n",
    "    uneven = u.shape[0] % 2 == 1\n",
    "    # has_batch = len(u.shape) >= len(A.shape)\n",
    "\n",
    "    u_0 = u[0::2, ...]\n",
    "    u_1 = u[1::2, ...]\n",
    "\n",
    "    if variable:\n",
    "        A_0 = A[0::2, ...]\n",
    "        A_1 = A[1::2, ...]\n",
    "    else:\n",
    "        A_0 = A\n",
    "        A_1 = A\n",
    "\n",
    "    u_0_ = u_0\n",
    "    A_0_ = A_0\n",
    "    if uneven:\n",
    "        u_0_ = u_0[:-1, ...]\n",
    "        if variable:\n",
    "            A_0_ = A_0[:-1, ...]\n",
    "\n",
    "    u_10 = op(A_1, u_0_) # batch_mult(A_1, u_0_, has_batch)\n",
    "    u_10 = u_10 + u_1\n",
    "    A_10 = compose_op(A_1, A_0_)\n",
    "\n",
    "    # Recursive call\n",
    "    x_1 = variable_unroll_general(A_10, u_10, s, op, compose_op, sequential_op, variable=variable, recurse_limit=recurse_limit)\n",
    "\n",
    "    x_0 = shift_up(x_1, s, drop=not uneven)\n",
    "    x_0 = op(A_0, x_0) # batch_mult(A_0, x_0, has_batch)\n",
    "    x_0 = x_0 + u_0\n",
    "\n",
    "\n",
    "    x = interleave(x_0, x_1, uneven, dim=0) # For some reason this interleave is slower than in the (non-multi) unroll_recursive\n",
    "    return x\n",
    "\n",
    "def variable_unroll_matrix(A, u, s=None, variable=True, recurse_limit=16):\n",
    "    print(f\"variable_unroll_matrix u shape: {u.shape}\")\n",
    "    if s is None:\n",
    "        s = torch.zeros_like(u[0])\n",
    "    has_batch = len(u.shape) >= len(A.shape)\n",
    "    print(f\"has_batch: {has_batch}\")\n",
    "    op = lambda x, y: batch_mult(x, y, has_batch)\n",
    "    sequential_op = lambda x, y: batch_mult(x.unsqueeze(0), y.unsqueeze(0), has_batch)[0]\n",
    "    matmul = lambda x, y: x @ y\n",
    "    return variable_unroll_general(A, u, s, op, compose_op=matmul, sequential_op=sequential_op, variable=variable, recurse_limit=recurse_limit)\n",
    "\n",
    "def variable_unroll_toeplitz(A, u, s=None, variable=True, recurse_limit=8, pad=False):\n",
    "    \"\"\" Unroll with variable (in time/length) transitions A with general associative operation\n",
    "\n",
    "    A : ([L], ..., N) dimension L should exist iff variable is True\n",
    "    u : (L, [B], ..., N) updates\n",
    "    s : ([B], ..., N) start state\n",
    "    output : x (L, [B], ..., N) same shape as u\n",
    "    x[i, ...] = A[i]..A[0] s + A[i..1] u[0] + ... + A[i] u[i-1] + u[i]\n",
    "    \"\"\"\n",
    "    # Add the batch dimension to A if necessary\n",
    "    A_batch_dims = len(A.shape) - int(variable)\n",
    "    u_batch_dims = len(u.shape)-1\n",
    "    if u_batch_dims > A_batch_dims:\n",
    "        # assert u_batch_dims == A_batch_dims + 1\n",
    "        if variable:\n",
    "            while len(A.shape) < len(u.shape):\n",
    "                A = A.unsqueeze(1)\n",
    "        # else:\n",
    "        #     A = A.unsqueeze(0)\n",
    "\n",
    "    if s is None:\n",
    "        s = torch.zeros_like(u[0])\n",
    "\n",
    "    if pad:\n",
    "        n = A.shape[-1]\n",
    "        A = F.pad(A, (0, n))\n",
    "        u = F.pad(u, (0, n))\n",
    "        s = F.pad(s, (0, n))\n",
    "        op = triangular_toeplitz_multiply_padded\n",
    "        ret = variable_unroll_general(A, u, s, op, compose_op=op, variable=variable, recurse_limit=recurse_limit)\n",
    "        ret = ret[..., :n]\n",
    "        return ret\n",
    "\n",
    "    op = triangular_toeplitz_multiply\n",
    "    ret = variable_unroll_general(A, u, s, op, compose_op=op, variable=variable, recurse_limit=recurse_limit)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gu's HiPPO LegT Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPO_LegT(nn.Module):\n",
    "    def __init__(self, N, dt=1.0, discretization=\"bilinear\", lambda_n=1.0):\n",
    "        \"\"\"\n",
    "        N: the order of the HiPPO projection\n",
    "        dt: discretization step size - should be roughly inverse to the length of the sequence\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        # A, B = transition('lmu', N)\n",
    "        legt_matrices = GuTransMatrix(N=N, measure=\"legt\", lambda_n=lambda_n)\n",
    "        A = legt_matrices.A_matrix\n",
    "        B = legt_matrices.B_matrix\n",
    "        C = np.ones((1, N))\n",
    "        D = np.zeros((1,))\n",
    "        # dt, discretization options\n",
    "        A, B, _, _, _ = signal.cont2discrete((A, B, C, D), dt=dt, method=discretization)\n",
    "\n",
    "        B = B.squeeze(-1)\n",
    "\n",
    "        self.register_buffer(\"A\", torch.Tensor(A))  # (N, N)\n",
    "        self.register_buffer(\"B\", torch.Tensor(B))  # (N,)\n",
    "\n",
    "        # vals = np.linspace(0.0, 1.0, 1./dt)\n",
    "        vals = np.arange(0.0, 1.0, dt)\n",
    "        self.eval_matrix = torch.Tensor(\n",
    "            ss.eval_legendre(np.arange(N)[:, None], 1 - 2 * vals).T\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs : (length, ...)\n",
    "        output : (length, ..., N) where N is the order of the HiPPO projection\n",
    "        \"\"\"\n",
    "\n",
    "        inputs = inputs.unsqueeze(-1)\n",
    "        u = inputs * self.B  # (length, ..., N)\n",
    "\n",
    "        c = torch.zeros(u.shape[1:])\n",
    "        cs = []\n",
    "        for f in inputs:\n",
    "            c = F.linear(c, self.A) + self.B * f\n",
    "            # print(f\"f:\\n{f}\")\n",
    "            cs.append(c)\n",
    "        return torch.stack(cs, dim=0)\n",
    "\n",
    "    def reconstruct(self, c):\n",
    "        return (self.eval_matrix @ c.unsqueeze(-1)).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gu's Scale invariant HiPPO LegS Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPO_LegS(nn.Module):\n",
    "    \"\"\"Vanilla HiPPO-LegS model (scale invariant instead of time invariant)\"\"\"\n",
    "\n",
    "    def __init__(self, N, max_length=1024, measure=\"legs\", discretization=\"bilinear\"):\n",
    "        \"\"\"\n",
    "        max_length: maximum sequence length\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        legs_matrices = GuTransMatrix(N=self.N, measure=measure)\n",
    "        A = legs_matrices.A_matrix\n",
    "        B = legs_matrices.B_matrix\n",
    "        # A, B = transition(measure, N)\n",
    "        B = B.squeeze(-1)\n",
    "        A_stacked = np.empty((max_length, N, N), dtype=A.dtype)\n",
    "        B_stacked = np.empty((max_length, N), dtype=B.dtype)\n",
    "        for t in range(1, max_length + 1):\n",
    "            At = A / t\n",
    "            Bt = B / t\n",
    "            if discretization == \"forward\":\n",
    "                A_stacked[t - 1] = np.eye(N) + At\n",
    "                B_stacked[t - 1] = Bt\n",
    "            elif discretization == \"backward\":\n",
    "                A_stacked[t - 1] = la.solve_triangular(\n",
    "                    np.eye(N) - At, np.eye(N), lower=True\n",
    "                )\n",
    "                B_stacked[t - 1] = la.solve_triangular(np.eye(N) - At, Bt, lower=True)\n",
    "            elif discretization == \"bilinear\":\n",
    "                alpha = 0.5\n",
    "                A_stacked[t - 1] = np.linalg.lstsq(\n",
    "                    np.eye(N) - (At * alpha), np.eye(N) + (At * alpha), rcond=None\n",
    "                )[\n",
    "                    0\n",
    "                ]  # TODO: Referencing this: https://stackoverflow.com/questions/64527098/numpy-linalg-linalgerror-singular-matrix-error-when-trying-to-solve\n",
    "                B_stacked[t - 1] = np.linalg.lstsq(\n",
    "                    np.eye(N) - (At * alpha), Bt, rcond=None\n",
    "                )[0]\n",
    "            else:  # ZOH\n",
    "                A_stacked[t - 1] = la.expm(A * (math.log(t + 1) - math.log(t)))\n",
    "                B_stacked[t - 1] = la.solve_triangular(\n",
    "                    A, A_stacked[t - 1] @ B - B, lower=True\n",
    "                )\n",
    "        self.A_stacked = torch.Tensor(A_stacked.copy())  # (max_length, N, N)\n",
    "        self.B_stacked = torch.Tensor(B_stacked.copy())  # (max_length, N)\n",
    "        vals = np.linspace(0.0, 1.0, max_length)\n",
    "        self.eval_matrix = torch.from_numpy(\n",
    "            np.asarray(\n",
    "                ((B[:, None] * ss.eval_legendre(np.arange(N)[:, None], 2 * vals - 1)).T)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, fast=False):\n",
    "        \"\"\"\n",
    "        inputs : (length, ...)\n",
    "        output : (length, ..., N) where N is the order of the HiPPO projection\n",
    "        \"\"\"\n",
    "        result = None\n",
    "\n",
    "        L = inputs.shape[0]\n",
    "\n",
    "        u = inputs.unsqueeze(-1)\n",
    "        u = torch.transpose(u, 0, -2)\n",
    "        u = u * self.B_stacked[:L]  # c_k = A @ c_{k-1} + B @ f_k\n",
    "        # print(f\"u - Gu: {u}\")\n",
    "        my_b = torch.Tensor(\n",
    "            [\n",
    "                [6.6666657e-01],\n",
    "                [5.7735050e-01],\n",
    "                [1.4907140e-01],\n",
    "                [-2.3096800e-07],\n",
    "                [-2.7939677e-09],\n",
    "                [2.9616058e-07],\n",
    "                [-2.2817403e-08],\n",
    "                [-8.1490725e-08],\n",
    "            ]\n",
    "        )\n",
    "        u = torch.transpose(u, 0, -2)  # (length, ..., N)\n",
    "\n",
    "        # print(f\"A_stacked: {self.A_stacked[:L]}\")\n",
    "        # print(f\"B_stacked: {self.B_stacked[:L]}\")\n",
    "\n",
    "        if fast:\n",
    "            result = variable_unroll_matrix(self.A_stacked[:L], u)\n",
    "\n",
    "        else:\n",
    "            result = variable_unroll_matrix_sequential(self.A_stacked[:L], u)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def reconstruct(self, c):\n",
    "        a = self.eval_matrix @ c.unsqueeze(-1)\n",
    "        return a.squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Of General HiPPO Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nb_HiPPO(jnn.Module):\n",
    "    \"\"\"\n",
    "    class that constructs HiPPO model using the defined measure.\n",
    "\n",
    "    Args:\n",
    "        N (int): order of the HiPPO projection, aka the number of coefficients to describe the matrix\n",
    "        max_length (int): maximum sequence length to be input\n",
    "        measure (str): the measure used to define which way to instantiate the HiPPO matrix\n",
    "        step (float): step size used for descretization\n",
    "        GBT_alpha (float): represents which descretization transformation to use based off the alpha value\n",
    "        seq_L (int): length of the sequence to be used for training\n",
    "        v (str): choice of vectorized or non-vectorized function instantiation\n",
    "            - 'v': vectorized\n",
    "            - 'nv': non-vectorized\n",
    "        lambda_n (float): value associated with the tilt of legt\n",
    "            - 1: tilt on legt\n",
    "            - \\sqrt(2n+1)(-1)^{N}: tilt associated with the legendre memory unit (LMU)\n",
    "        fourier_type (str): choice of fourier measures\n",
    "            - fru: fourier recurrent unit measure (FRU) - 'fru'\n",
    "            - fout: truncated Fourier (FouT) - 'fout'\n",
    "            - fourd: decaying fourier transform - 'fourd'\n",
    "        alpha (float): The order of the Laguerre basis.\n",
    "        beta (float): The scale of the Laguerre basis.\n",
    "    \"\"\"\n",
    "\n",
    "    N: int\n",
    "    max_length: int\n",
    "    step: float\n",
    "    GBT_alpha: float\n",
    "    seq_L: int\n",
    "    A: jnp.ndarray\n",
    "    B: jnp.ndarray\n",
    "    measure: str\n",
    "\n",
    "    def setup(self):\n",
    "        A = self.A\n",
    "        B = self.B\n",
    "        self.C = jnp.ones((self.N,))\n",
    "        self.D = jnp.zeros((1,))\n",
    "\n",
    "        if self.measure == \"legt\":\n",
    "            L = self.seq_L\n",
    "            vals = jnp.arange(0.0, 1.0, L)\n",
    "            # n = jnp.arange(self.N)[:, None]\n",
    "            zero_N = self.N - 1\n",
    "            x = 1 - 2 * vals\n",
    "            self.eval_matrix = jax.scipy.special.lpmn_values(\n",
    "                m=zero_N, n=zero_N, z=x, is_normalized=False\n",
    "            ).T  # ss.eval_legendre(n, x).T\n",
    "\n",
    "        elif self.measure == \"legs\":\n",
    "            L = self.max_length\n",
    "            vals = jnp.linspace(0.0, 1.0, L)\n",
    "            # n = jnp.arange(self.N)[:, None]\n",
    "            zero_N = self.N - 1\n",
    "            x = 2 * vals - 1\n",
    "            self.eval_matrix = (\n",
    "                B[:, None]\n",
    "                * jax.scipy.special.lpmn_values(\n",
    "                    m=zero_N, n=zero_N, z=x, is_normalized=False\n",
    "                )\n",
    "            ).T  # ss.eval_legendre(n, x)).T\n",
    "\n",
    "        elif self.measure == \"lagt\":\n",
    "            raise NotImplementedError(\"Translated Laguerre measure not implemented yet\")\n",
    "\n",
    "        elif self.measure == \"fourier\":\n",
    "            raise NotImplementedError(\"Fourier measures are not implemented yet\")\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"invalid measure\")\n",
    "\n",
    "    def __call__(self, f, init_state=None, t_step=0, kernel=False):\n",
    "        # print(f\"u shape:\\n{f.shape}\")\n",
    "        # print(f\"u:\\n{f}\")\n",
    "        if not kernel:\n",
    "            if init_state is None:\n",
    "                init_state = jnp.zeros((self.N, 1))\n",
    "\n",
    "            # Ab, Bb, Cb, Db = self.collect_SSM_vars(\n",
    "            #     self.A, self.B, self.C, self.D, f, t_step=t_step, alpha=self.GBT_alpha\n",
    "            # )\n",
    "            c_k, y_k, GBT_A, GBT_B = self.loop_SSM(\n",
    "                A=self.A,\n",
    "                B=self.B,\n",
    "                C=self.C,\n",
    "                D=self.D,\n",
    "                c_0=init_state,\n",
    "                f=f,\n",
    "                alpha=self.GBT_alpha,\n",
    "            )\n",
    "            # c_k, y_k = self.scan_SSM(Ab=Ab, Bb=Bb, Cb=Cb, Db=Db, c_0=init_state, f=f)\n",
    "\n",
    "        else:\n",
    "            Ab, Bb, Cb, Db = self.discretize(\n",
    "                self.A, self.B, self.C, self.D, step=self.step, alpha=self.GBT_alpha\n",
    "            )\n",
    "            c_k, y_k = self.causal_convolution(\n",
    "                f, self.K_conv(Ab, Bb, Cb, Db, L=self.max_length)\n",
    "            )\n",
    "\n",
    "        return c_k, y_k, GBT_A, GBT_B\n",
    "\n",
    "    def reconstruct(self, c):\n",
    "        \"\"\"\n",
    "        Uses coeffecients to reconstruct the signal\n",
    "\n",
    "        Args:\n",
    "            c (jnp.ndarray): coefficients of the HiPPO projection\n",
    "\n",
    "        Returns:\n",
    "            reconstructed signal\n",
    "        \"\"\"\n",
    "        return (self.eval_matrix @ jnp.expand_dims(c, -1)).squeeze(-1)\n",
    "\n",
    "    def discretize(self, A, B, C, D, step, alpha=0.5):\n",
    "        \"\"\"\n",
    "        function used for discretizing the HiPPO matrix\n",
    "\n",
    "        Args:\n",
    "            A (jnp.ndarray): matrix to be discretized\n",
    "            B (jnp.ndarray): matrix to be discretized\n",
    "            C (jnp.ndarray): matrix to be discretized\n",
    "            D (jnp.ndarray): matrix to be discretized\n",
    "            step (float): step size used for discretization\n",
    "            alpha (float, optional): used for determining which generalized bilinear transformation to use\n",
    "                - forward Euler corresponds to α = 0,\n",
    "                - backward Euler corresponds to α = 1,\n",
    "                - bilinear corresponds to α = 0.5,\n",
    "                - Zero-order Hold corresponds to α > 1\n",
    "        \"\"\"\n",
    "        I = jnp.eye(A.shape[0])\n",
    "        step_size = 1 / step\n",
    "        part1 = I - (step_size * alpha * A)\n",
    "        part2 = I + (step_size * (1 - alpha) * A)\n",
    "\n",
    "        GBT_A = jnp.linalg.lstsq(part1, part2, rcond=None)[0]\n",
    "\n",
    "        base_GBT_B = jnp.linalg.lstsq(part1, B, rcond=None)[0]\n",
    "        GBT_B = step_size * base_GBT_B\n",
    "\n",
    "        if alpha > 1:  # Zero-order Hold\n",
    "            GBT_A = jax.scipy.linalg.expm(step_size * A)\n",
    "            GBT_B = (jnp.linalg.inv(A) @ (jax.scipy.linalg.expm(step_size * A) - I)) @ B\n",
    "\n",
    "        return (\n",
    "            GBT_A.astype(jnp.float32),\n",
    "            GBT_B.astype(jnp.float32),\n",
    "            C.astype(jnp.float32),\n",
    "            D.astype(jnp.float32),\n",
    "        )\n",
    "\n",
    "    def collect_SSM_vars(self, A, B, C, D, f, t_step=0, alpha=0.5):\n",
    "        \"\"\"\n",
    "        turns the continuos HiPPO matrix components into discrete ones\n",
    "\n",
    "        Args:\n",
    "            A (jnp.ndarray): matrix to be discretized\n",
    "            B (jnp.ndarray): matrix to be discretized\n",
    "            C (jnp.ndarray): matrix to be discretized\n",
    "            D (jnp.ndarray): matrix to be discretized\n",
    "            f (jnp.ndarray): input signal\n",
    "            alpha (float, optional): used for determining which generalized bilinear transformation to use\n",
    "\n",
    "        Returns:\n",
    "            Ab (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "            Bb (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "            Cb (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "            Db (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "        \"\"\"\n",
    "        N = A.shape[0]\n",
    "\n",
    "        if t_step == 0:\n",
    "            L = f.shape[0]  # seq_L, 1\n",
    "            assert (\n",
    "                L == self.seq_L\n",
    "            ), f\"sequence length must match, currently {L} != {self.seq_L}\"\n",
    "            assert N == self.N, f\"Order number must match, currently {N} != {self.N}\"\n",
    "        else:\n",
    "            L = t_step\n",
    "            assert t_step >= 1, f\"time step must be greater than 0, currently {t_step}\"\n",
    "            assert N == self.N, f\"Order number must match, currently {N} != {self.N}\"\n",
    "\n",
    "        Ab, Bb, Cb, Db = self.discretize(A, B, C, D, step=L, alpha=alpha)\n",
    "\n",
    "        return (\n",
    "            Ab.astype(jnp.float32),\n",
    "            Bb.astype(jnp.float32),\n",
    "            Cb.astype(jnp.float32),\n",
    "            Db.astype(jnp.float32),\n",
    "        )\n",
    "\n",
    "    def scan_SSM(self, Ad, Bd, Cd, Dd, c_0, f):\n",
    "        \"\"\"\n",
    "        This is for returning the discretized hidden state often needed for an RNN.\n",
    "        Args:\n",
    "            Ab (jnp.ndarray): the discretized A matrix\n",
    "            Bb (jnp.ndarray): the discretized B matrix\n",
    "            Cb (jnp.ndarray): the discretized C matrix\n",
    "            f (jnp.ndarray): the input sequence\n",
    "            c_0 (jnp.ndarray): the initial hidden state\n",
    "        Returns:\n",
    "            the next hidden state (aka coefficients representing the function, f(t))\n",
    "        \"\"\"\n",
    "\n",
    "        def step(c_k_1, f_k):\n",
    "            \"\"\"\n",
    "            Get descretized coefficients of the hidden state by applying HiPPO matrix to input sequence, u_k, and previous hidden state, x_k_1.\n",
    "            Args:\n",
    "                c_k_1: previous hidden state\n",
    "                f_k: output from function f at, descritized, time step, k.\n",
    "                t:\n",
    "\n",
    "            Returns:\n",
    "                c_k: current hidden state\n",
    "                y_k: current output of hidden state applied to Cb (sorry for being vague, I just dont know yet)\n",
    "            \"\"\"\n",
    "            part1 = Ad @ c_k_1\n",
    "            part2 = jnp.expand_dims((Bd @ f_k), -1)\n",
    "\n",
    "            c_k = part1 + part2\n",
    "            y_k = Cd @ c_k  # + (Db.T @ f_k)\n",
    "\n",
    "            return c_k, y_k\n",
    "\n",
    "        return jax.lax.scan(step, c_0, f)\n",
    "\n",
    "    def loop_SSM(self, A, B, C, D, c_0, f, alpha=0.5):\n",
    "        \"\"\"\n",
    "        This is for returning the discretized hidden state often needed for an RNN.\n",
    "        Args:\n",
    "            Ab (jnp.ndarray): the discretized A matrix\n",
    "            Bb (jnp.ndarray): the discretized B matrix\n",
    "            Cb (jnp.ndarray): the discretized C matrix\n",
    "            f (jnp.ndarray): the input sequence\n",
    "            c_0 (jnp.ndarray): the initial hidden state\n",
    "        Returns:\n",
    "            the next hidden state (aka coefficients representing the function, f(t))\n",
    "        \"\"\"\n",
    "        GBT_A_lst = []\n",
    "        GBT_B_lst = []\n",
    "        c_k_list = []\n",
    "        y_k_list = []\n",
    "\n",
    "        c_k = c_0.copy()\n",
    "        print(f\"no batch f shape: {f.shape}\")\n",
    "        print(f\"no batch c_k shape: {c_k.shape}\")\n",
    "        for i in range(1, f.shape[0] + 1):\n",
    "            Ad_i, Bd_i, Cd_i, Dd_i = self.collect_SSM_vars(\n",
    "                A=A, B=B, C=C, D=D, f=f, t_step=i, alpha=alpha\n",
    "            )\n",
    "            c_k, y_k = self.loop_step(\n",
    "                Ad=Ad_i, Bd=Bd_i, Cd=Cd_i, Dd=Dd_i, c_k_i=c_k, f_k=f[i - 1][0]\n",
    "            )\n",
    "            c_k_list.append(c_k.copy())\n",
    "            y_k_list.append(y_k.copy())\n",
    "            GBT_A_lst.append(Ad_i.copy())\n",
    "            GBT_B_lst.append(Bd_i.copy())\n",
    "\n",
    "        return c_k_list, y_k_list, GBT_A_lst, GBT_B_lst\n",
    "\n",
    "    def loop_step(self, Ad, Bd, Cd, Dd, c_k_i, f_k):\n",
    "        \"\"\"\n",
    "        Get descretized coefficients of the hidden state by applying HiPPO matrix to input sequence, u_k, and previous hidden state, x_k_1.\n",
    "        Args:\n",
    "            c_k_i: previous hidden state\n",
    "            f_k: output from function f at, descritized, time step, k.\n",
    "\n",
    "        Returns:\n",
    "            c_k: current hidden state\n",
    "            y_k: current output of hidden state applied to Cb (sorry for being vague, I just dont know yet)\n",
    "        \"\"\"\n",
    "        # print(f\"c_k_i:\\n{c_k_i}\")\n",
    "        # print(f\"f_k:\\n{f_k}\")\n",
    "\n",
    "        part1 = Ad @ c_k_i\n",
    "        part2 = Bd * f_k\n",
    "        c_k = part1 + part2\n",
    "        y_k = Cd @ c_k  # + (Db.T @ f_k)\n",
    "\n",
    "        return c_k.astype(jnp.float32), y_k.astype(jnp.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class b_HiPPO(jnn.Module):\n",
    "    \"\"\"\n",
    "    class that constructs HiPPO model using the defined measure.\n",
    "\n",
    "    Args:\n",
    "        N (int): order of the HiPPO projection, aka the number of coefficients to describe the matrix\n",
    "        max_length (int): maximum sequence length to be input\n",
    "        measure (str): the measure used to define which way to instantiate the HiPPO matrix\n",
    "        step (float): step size used for descretization\n",
    "        GBT_alpha (float): represents which descretization transformation to use based off the alpha value\n",
    "        seq_L (int): length of the sequence to be used for training\n",
    "        v (str): choice of vectorized or non-vectorized function instantiation\n",
    "            - 'v': vectorized\n",
    "            - 'nv': non-vectorized\n",
    "        lambda_n (float): value associated with the tilt of legt\n",
    "            - 1: tilt on legt\n",
    "            - \\sqrt(2n+1)(-1)^{N}: tilt associated with the legendre memory unit (LMU)\n",
    "        fourier_type (str): choice of fourier measures\n",
    "            - fru: fourier recurrent unit measure (FRU) - 'fru'\n",
    "            - fout: truncated Fourier (FouT) - 'fout'\n",
    "            - fourd: decaying fourier transform - 'fourd'\n",
    "        alpha (float): The order of the Laguerre basis.\n",
    "        beta (float): The scale of the Laguerre basis.\n",
    "    \"\"\"\n",
    "\n",
    "    N: int\n",
    "    max_length: int\n",
    "    step: float\n",
    "    GBT_alpha: float\n",
    "    seq_L: int\n",
    "    A: jnp.ndarray\n",
    "    B: jnp.ndarray\n",
    "    measure: str\n",
    "\n",
    "    def setup(self):\n",
    "        A = self.A\n",
    "        B = self.B\n",
    "        self.C = jnp.ones((self.N,))\n",
    "        self.D = jnp.zeros((1,))\n",
    "\n",
    "        if self.measure == \"legt\":\n",
    "            L = self.seq_L\n",
    "            vals = jnp.arange(0.0, 1.0, L)\n",
    "            # n = jnp.arange(self.N)[:, None]\n",
    "            zero_N = self.N - 1\n",
    "            x = 1 - 2 * vals\n",
    "            self.eval_matrix = jax.scipy.special.lpmn_values(\n",
    "                m=zero_N, n=zero_N, z=x, is_normalized=False\n",
    "            ).T  # ss.eval_legendre(n, x).T\n",
    "\n",
    "        elif self.measure == \"legs\":\n",
    "            L = self.max_length\n",
    "            vals = jnp.linspace(0.0, 1.0, L)\n",
    "            # n = jnp.arange(self.N)[:, None]\n",
    "            zero_N = self.N - 1\n",
    "            x = 2 * vals - 1\n",
    "            self.eval_matrix = (\n",
    "                B[:, None]\n",
    "                * jax.scipy.special.lpmn_values(\n",
    "                    m=zero_N, n=zero_N, z=x, is_normalized=False\n",
    "                )\n",
    "            ).T  # ss.eval_legendre(n, x)).T\n",
    "\n",
    "        elif self.measure == \"lagt\":\n",
    "            raise NotImplementedError(\"Translated Laguerre measure not implemented yet\")\n",
    "\n",
    "        elif self.measure == \"fourier\":\n",
    "            raise NotImplementedError(\"Fourier measures are not implemented yet\")\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"invalid measure\")\n",
    "\n",
    "    def __call__(self, f, init_state=None, t_step=0, kernel=False):\n",
    "        # print(f\"u shape:\\n{f.shape}\")\n",
    "        # print(f\"u:\\n{f}\")\n",
    "        if not kernel:\n",
    "            if init_state is None:\n",
    "                init_state = jnp.zeros((f.shape[0], self.N, 1))\n",
    "\n",
    "            # Ab, Bb, Cb, Db = self.collect_SSM_vars(\n",
    "            #     self.A, self.B, self.C, self.D, f, t_step=t_step, alpha=self.GBT_alpha\n",
    "            # )\n",
    "            c_k, y_k, GBT_A, GBT_B = self.loop_SSM(\n",
    "                A=self.A,\n",
    "                B=self.B,\n",
    "                C=self.C,\n",
    "                D=self.D,\n",
    "                c_0=init_state,\n",
    "                f=f,\n",
    "                alpha=self.GBT_alpha,\n",
    "            )\n",
    "            # c_k, y_k = self.scan_SSM(Ab=Ab, Bb=Bb, Cb=Cb, Db=Db, c_0=init_state, f=f)\n",
    "\n",
    "        else:\n",
    "            Ab, Bb, Cb, Db = self.discretize(\n",
    "                self.A, self.B, self.C, self.D, step=self.step, alpha=self.GBT_alpha\n",
    "            )\n",
    "            c_k, y_k = self.causal_convolution(\n",
    "                f, self.K_conv(Ab, Bb, Cb, Db, L=self.max_length)\n",
    "            )\n",
    "\n",
    "        return c_k, y_k, GBT_A, GBT_B\n",
    "\n",
    "    def reconstruct(self, c):\n",
    "        \"\"\"\n",
    "        Uses coeffecients to reconstruct the signal\n",
    "\n",
    "        Args:\n",
    "            c (jnp.ndarray): coefficients of the HiPPO projection\n",
    "\n",
    "        Returns:\n",
    "            reconstructed signal\n",
    "        \"\"\"\n",
    "        return (self.eval_matrix @ jnp.expand_dims(c, -1)).squeeze(-1)\n",
    "\n",
    "    def discretize(self, A, B, C, D, step, alpha=0.5):\n",
    "        \"\"\"\n",
    "        function used for discretizing the HiPPO matrix\n",
    "\n",
    "        Args:\n",
    "            A (jnp.ndarray): matrix to be discretized\n",
    "            B (jnp.ndarray): matrix to be discretized\n",
    "            C (jnp.ndarray): matrix to be discretized\n",
    "            D (jnp.ndarray): matrix to be discretized\n",
    "            step (float): step size used for discretization\n",
    "            alpha (float, optional): used for determining which generalized bilinear transformation to use\n",
    "                - forward Euler corresponds to α = 0,\n",
    "                - backward Euler corresponds to α = 1,\n",
    "                - bilinear corresponds to α = 0.5,\n",
    "                - Zero-order Hold corresponds to α > 1\n",
    "        \"\"\"\n",
    "        I = jnp.eye(A.shape[0])\n",
    "        step_size = 1 / step\n",
    "        part1 = I - (step_size * alpha * A)\n",
    "        part2 = I + (step_size * (1 - alpha) * A)\n",
    "\n",
    "        GBT_A = jnp.linalg.lstsq(part1, part2, rcond=None)[0]\n",
    "\n",
    "        base_GBT_B = jnp.linalg.lstsq(part1, B, rcond=None)[0]\n",
    "        GBT_B = step_size * base_GBT_B\n",
    "\n",
    "        if alpha > 1:  # Zero-order Hold\n",
    "            GBT_A = jax.scipy.linalg.expm(step_size * A)\n",
    "            GBT_B = (jnp.linalg.inv(A) @ (jax.scipy.linalg.expm(step_size * A) - I)) @ B\n",
    "\n",
    "        return (\n",
    "            GBT_A.astype(jnp.float32),\n",
    "            GBT_B.astype(jnp.float32),\n",
    "            C.astype(jnp.float32),\n",
    "            D.astype(jnp.float32),\n",
    "        )\n",
    "\n",
    "    def collect_SSM_vars(self, A, B, C, D, f, t_step=0, alpha=0.5):\n",
    "        \"\"\"\n",
    "        turns the continuos HiPPO matrix components into discrete ones\n",
    "\n",
    "        Args:\n",
    "            A (jnp.ndarray): matrix to be discretized\n",
    "            B (jnp.ndarray): matrix to be discretized\n",
    "            C (jnp.ndarray): matrix to be discretized\n",
    "            D (jnp.ndarray): matrix to be discretized\n",
    "            f (jnp.ndarray): input signal\n",
    "            alpha (float, optional): used for determining which generalized bilinear transformation to use\n",
    "\n",
    "        Returns:\n",
    "            Ab (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "            Bb (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "            Cb (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "            Db (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "        \"\"\"\n",
    "        N = A.shape[0]\n",
    "\n",
    "        if t_step == 0:\n",
    "            L = f.shape[1]  # seq_L, 1\n",
    "            assert (\n",
    "                L == self.seq_L\n",
    "            ), f\"sequence length must match, currently {L} != {self.seq_L}\"\n",
    "            assert N == self.N, f\"Order number must match, currently {N} != {self.N}\"\n",
    "        else:\n",
    "            L = t_step\n",
    "            assert t_step >= 1, f\"time step must be greater than 0, currently {t_step}\"\n",
    "            assert N == self.N, f\"Order number must match, currently {N} != {self.N}\"\n",
    "\n",
    "        Ab, Bb, Cb, Db = self.discretize(A, B, C, D, step=L, alpha=alpha)\n",
    "\n",
    "        return (\n",
    "            Ab.astype(jnp.float32),\n",
    "            Bb.astype(jnp.float32),\n",
    "            Cb.astype(jnp.float32),\n",
    "            Db.astype(jnp.float32),\n",
    "        )\n",
    "\n",
    "    def scan_SSM(self, Ad, Bd, Cd, Dd, c_0, f):\n",
    "        \"\"\"\n",
    "        This is for returning the discretized hidden state often needed for an RNN.\n",
    "        Args:\n",
    "            Ab (jnp.ndarray): the discretized A matrix\n",
    "            Bb (jnp.ndarray): the discretized B matrix\n",
    "            Cb (jnp.ndarray): the discretized C matrix\n",
    "            f (jnp.ndarray): the input sequence\n",
    "            c_0 (jnp.ndarray): the initial hidden state\n",
    "        Returns:\n",
    "            the next hidden state (aka coefficients representing the function, f(t))\n",
    "        \"\"\"\n",
    "\n",
    "        def step(c_k_1, f_k):\n",
    "            \"\"\"\n",
    "            Get descretized coefficients of the hidden state by applying HiPPO matrix to input sequence, u_k, and previous hidden state, x_k_1.\n",
    "            Args:\n",
    "                c_k_1: previous hidden state\n",
    "                f_k: output from function f at, descritized, time step, k.\n",
    "                t:\n",
    "\n",
    "            Returns:\n",
    "                c_k: current hidden state\n",
    "                y_k: current output of hidden state applied to Cb (sorry for being vague, I just dont know yet)\n",
    "            \"\"\"\n",
    "            part1 = Ad @ c_k_1\n",
    "            part2 = jnp.expand_dims((Bd @ f_k), -1)\n",
    "\n",
    "            c_k = part1 + part2\n",
    "            y_k = Cd @ c_k  # + (Db.T @ f_k)\n",
    "\n",
    "            return c_k, y_k\n",
    "\n",
    "        return jax.lax.scan(step, c_0, f)\n",
    "\n",
    "    def loop_SSM(self, A, B, C, D, c_0, f, alpha=0.5):\n",
    "        \"\"\"\n",
    "        This is for returning the discretized hidden state often needed for an RNN.\n",
    "        Args:\n",
    "            Ab (jnp.ndarray): the discretized A matrix\n",
    "            Bb (jnp.ndarray): the discretized B matrix\n",
    "            Cb (jnp.ndarray): the discretized C matrix\n",
    "            f (jnp.ndarray): the input sequence\n",
    "            c_0 (jnp.ndarray): the initial hidden state\n",
    "        Returns:\n",
    "            the next hidden state (aka coefficients representing the function, f(t))\n",
    "        \"\"\"\n",
    "        GBT_A_lst = []\n",
    "        GBT_B_lst = []\n",
    "        c_k_list = []\n",
    "        y_k_list = []\n",
    "\n",
    "        c_k = c_0.copy()\n",
    "        print(f\"f shape:{f.shape}\")\n",
    "        print(f\"c_k shape:{c_k.shape}\")\n",
    "        # jax.debug.print(f\"f:\\n{f}\")\n",
    "        for i in range(1, f.shape[1] + 1):\n",
    "            Ad_i, Bd_i, Cd_i, Dd_i = self.collect_SSM_vars(\n",
    "                A=A, B=B, C=C, D=D, f=f, t_step=i, alpha=alpha\n",
    "            )\n",
    "            # jax.debug.print(f\"f[:,i-1,:] shape: {f[:,i-1,:].shape}\")\n",
    "            # jax.debug.print(f\"f[:,i-1,:]: {f[:,i-1,:]}\")\n",
    "            # print(f\"f[i - 1][0] shape: {f[i - 1].shape}\")\n",
    "            # print(f\"f[i - 1][0]: {f[i - 1]}\")\n",
    "            # print(f\"c_k shape: {c_k.shape}\")\n",
    "            # c_k, y_k = self.loop_step(\n",
    "            #     Ad=Ad_i, Bd=Bd_i, Cd=Cd_i, Dd=Dd_i, c_k_i=c_k, f_k=f[i-1,:][0]\n",
    "            # )\n",
    "            c_k, y_k = jax.vmap(self.loop_step, in_axes=(None, None, None, None, 0, 0))(\n",
    "                Ad_i, Bd_i, Cd_i, Dd_i, c_k, f[:,i-1,:]\n",
    "            )\n",
    "            c_k_list.append(c_k.copy())\n",
    "            y_k_list.append(y_k.copy())\n",
    "            GBT_A_lst.append(Ad_i.copy())\n",
    "            GBT_B_lst.append(Bd_i.copy())\n",
    "\n",
    "        return c_k_list, y_k_list, GBT_A_lst, GBT_B_lst\n",
    "\n",
    "    def loop_step(self, Ad, Bd, Cd, Dd, c_k_i, f_k):\n",
    "        \"\"\"\n",
    "        Get descretized coefficients of the hidden state by applying HiPPO matrix to input sequence, u_k, and previous hidden state, x_k_1.\n",
    "        Args:\n",
    "            c_k_i: previous hidden state\n",
    "            f_k: output from function f at, descritized, time step, k.\n",
    "\n",
    "        Returns:\n",
    "            c_k: current hidden state\n",
    "            y_k: current output of hidden state applied to Cb (sorry for being vague, I just dont know yet)\n",
    "        \"\"\"\n",
    "        # jax.debug.print(f\"c_k_i:\\n{c_k_i}\")\n",
    "        # jax.debug.print(f\"f_k:\\n{f_k}\")\n",
    "        \n",
    "        part1 = Ad @ c_k_i\n",
    "        part2 = Bd * f_k\n",
    "        c_k = part1 + part2\n",
    "        y_k = Cd @ c_k  # + (Db.T @ f_k)\n",
    "\n",
    "        return c_k.astype(jnp.float32), y_k.astype(jnp.float32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPO(jnn.Module):\n",
    "    \"\"\"\n",
    "    class that constructs HiPPO model using the defined measure.\n",
    "\n",
    "    Args:\n",
    "        N (int): order of the HiPPO projection, aka the number of coefficients to describe the matrix\n",
    "        max_length (int): maximum sequence length to be input\n",
    "        measure (str): the measure used to define which way to instantiate the HiPPO matrix\n",
    "        step (float): step size used for descretization\n",
    "        GBT_alpha (float): represents which descretization transformation to use based off the alpha value\n",
    "        seq_L (int): length of the sequence to be used for training\n",
    "        v (str): choice of vectorized or non-vectorized function instantiation\n",
    "            - 'v': vectorized\n",
    "            - 'nv': non-vectorized\n",
    "        lambda_n (float): value associated with the tilt of legt\n",
    "            - 1: tilt on legt\n",
    "            - \\sqrt(2n+1)(-1)^{N}: tilt associated with the legendre memory unit (LMU)\n",
    "        fourier_type (str): choice of fourier measures\n",
    "            - fru: fourier recurrent unit measure (FRU) - 'fru'\n",
    "            - fout: truncated Fourier (FouT) - 'fout'\n",
    "            - fourd: decaying fourier transform - 'fourd'\n",
    "        alpha (float): The order of the Laguerre basis.\n",
    "        beta (float): The scale of the Laguerre basis.\n",
    "    \"\"\"\n",
    "\n",
    "    N: int\n",
    "    max_length: int\n",
    "    step: float\n",
    "    GBT_alpha: float\n",
    "    seq_L: int\n",
    "    A: jnp.ndarray\n",
    "    B: jnp.ndarray\n",
    "    measure: str\n",
    "\n",
    "    def setup(self):\n",
    "        A = self.A\n",
    "        B = self.B\n",
    "        self.C = jnp.ones((self.N,))\n",
    "        self.D = jnp.zeros((1,))\n",
    "\n",
    "        GBT_a_list = []\n",
    "        GBT_b_list = []\n",
    "        for i in range(1, self.seq_L + 1):\n",
    "            # TODO: make this scale invariant optional\n",
    "            GBT_A, GBT_B = self.discretion(\n",
    "                A, B, step=i, alpha=self.GBT_alpha, dtype=jnp.float32\n",
    "            )\n",
    "            GBT_a_list.append(GBT_A)\n",
    "            GBT_b_list.append(GBT_B)\n",
    "\n",
    "        self.GBT_A_list = GBT_a_list\n",
    "        self.GBT_B_list = GBT_b_list\n",
    "\n",
    "        if self.measure == \"legt\":\n",
    "            L = self.seq_L\n",
    "            vals = jnp.arange(0.0, 1.0, L)\n",
    "            # n = jnp.arange(self.N)[:, None]\n",
    "            zero_N = self.N - 1\n",
    "            x = 1 - 2 * vals\n",
    "            self.eval_matrix = jax.scipy.special.lpmn_values(\n",
    "                m=zero_N, n=zero_N, z=x, is_normalized=False\n",
    "            ).T  # ss.eval_legendre(n, x).T\n",
    "\n",
    "        elif self.measure == \"legs\":\n",
    "            L = self.max_length\n",
    "            vals = jnp.linspace(0.0, 1.0, L)\n",
    "            # n = jnp.arange(self.N)[:, None]\n",
    "            zero_N = self.N - 1\n",
    "            x = 2 * vals - 1\n",
    "            self.eval_matrix = (\n",
    "                B[:, None]\n",
    "                * jax.scipy.special.lpmn_values(\n",
    "                    m=zero_N, n=zero_N, z=x, is_normalized=False\n",
    "                )\n",
    "            ).T  # ss.eval_legendre(n, x)).T\n",
    "\n",
    "        elif self.measure == \"lagt\":\n",
    "            raise NotImplementedError(\"Translated Laguerre measure not implemented yet\")\n",
    "\n",
    "        elif self.measure == \"fourier\":\n",
    "            raise NotImplementedError(\"Fourier measures are not implemented yet\")\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"invalid measure\")\n",
    "\n",
    "    def __call__(self, f, init_state=None, t_step=0, kernel=False):\n",
    "        if not kernel:\n",
    "            if init_state is None:\n",
    "                init_state = jnp.zeros((f.shape[0], self.N, 1))\n",
    "\n",
    "            Ab, Bb, Cb, Db = self.collect_SSM_vars(\n",
    "                self.A, self.B, self.C, self.D, f, t_step=t_step, alpha=self.GBT_alpha\n",
    "            )\n",
    "            c_k, y_k, GBT_A, GBT_B = self.loop_SSM(\n",
    "                A=self.A,\n",
    "                B=self.B,\n",
    "                C=self.C,\n",
    "                D=self.D,\n",
    "                c_0=init_state,\n",
    "                f=f,\n",
    "                alpha=self.GBT_alpha,\n",
    "            )\n",
    "            # c_k, y_k = jax.vmap(\n",
    "            #     self.scan_SSM, in_axes=(None, None, None, None, 0, 0)\n",
    "            #     )(Ab=Ab, Bb=Bb, Cb=Cb, Db=Db, c_0=init_state, f=f)\n",
    "\n",
    "        else:\n",
    "            Ab, Bb, Cb, Db = self.discretize(\n",
    "                self.A, self.B, self.C, self.D, step=self.step, alpha=self.GBT_alpha\n",
    "            )\n",
    "            c_k, y_k = self.causal_convolution(\n",
    "                f, self.K_conv(Ab, Bb, Cb, Db, L=self.max_length)\n",
    "            )\n",
    "\n",
    "        return c_k, y_k, GBT_A, GBT_B\n",
    "\n",
    "    def reconstruct(self, c):\n",
    "        \"\"\"\n",
    "        Uses coefficients to reconstruct the signal\n",
    "\n",
    "        Args:\n",
    "            c (jnp.ndarray): coefficients of the HiPPO projection\n",
    "\n",
    "        Returns:\n",
    "            reconstructed signal\n",
    "        \"\"\"\n",
    "        return (self.eval_matrix @ jnp.expand_dims(c, -1)).squeeze(-1)\n",
    "\n",
    "    # @staticmethod\n",
    "    def discretion(self, A, B, step, alpha=0.5, dtype=jnp.float32):\n",
    "        \"\"\"\n",
    "        function used for discretizing the HiPPO matrix\n",
    "\n",
    "        Args:\n",
    "            A (jnp.ndarray): matrix to be discretized\n",
    "            B (jnp.ndarray): matrix to be discretized\n",
    "            C (jnp.ndarray): matrix to be discretized\n",
    "            D (jnp.ndarray): matrix to be discretized\n",
    "            step (float): step size used for discretization\n",
    "            alpha (float, optional): used for determining which generalized bilinear transformation to use\n",
    "                - forward Euler corresponds to α = 0,\n",
    "                - backward Euler corresponds to α = 1,\n",
    "                - bilinear corresponds to α = 0.5,\n",
    "                - Zero-order Hold corresponds to α > 1\n",
    "        \"\"\"\n",
    "        I = jnp.eye(A.shape[0])\n",
    "        step_size = 1 / step\n",
    "        part1 = I - (step_size * alpha * A)\n",
    "        part2 = I + (step_size * (1 - alpha) * A)\n",
    "\n",
    "        GBT_A = jnp.linalg.lstsq(part1, part2, rcond=None)[0]\n",
    "\n",
    "        base_GBT_B = jnp.linalg.lstsq(part1, B, rcond=None)[0]\n",
    "        GBT_B = step_size * base_GBT_B\n",
    "\n",
    "        if alpha > 1:  # Zero-order Hold\n",
    "            GBT_A = jax.scipy.linalg.expm(step_size * A)\n",
    "            GBT_B = (jnp.linalg.inv(A) @ (jax.scipy.linalg.expm(step_size * A) - I)) @ B\n",
    "\n",
    "        return GBT_A.astype(dtype), GBT_B.astype(dtype)\n",
    "\n",
    "    # def discretize(self, A, B, C, D, step, alpha=0.5):\n",
    "    #     \"\"\"\n",
    "    #     function used for discretizing the HiPPO matrix\n",
    "\n",
    "    #     Args:\n",
    "    #         A (jnp.ndarray): matrix to be discretized\n",
    "    #         B (jnp.ndarray): matrix to be discretized\n",
    "    #         C (jnp.ndarray): matrix to be discretized\n",
    "    #         D (jnp.ndarray): matrix to be discretized\n",
    "    #         step (float): step size used for discretization\n",
    "    #         alpha (float, optional): used for determining which generalized bilinear transformation to use\n",
    "    #             - forward Euler corresponds to α = 0,\n",
    "    #             - backward Euler corresponds to α = 1,\n",
    "    #             - bilinear corresponds to α = 0.5,\n",
    "    #             - Zero-order Hold corresponds to α > 1\n",
    "    #     \"\"\"\n",
    "    #     I = jnp.eye(A.shape[0])\n",
    "    #     step_size = 1 / step\n",
    "    #     part1 = I - (step_size * alpha * A)\n",
    "    #     part2 = I + (step_size * (1 - alpha) * A)\n",
    "\n",
    "    #     GBT_A = jnp.linalg.lstsq(part1, part2, rcond=None)[0]\n",
    "\n",
    "    #     base_GBT_B = jnp.linalg.lstsq(part1, B, rcond=None)[0]\n",
    "    #     GBT_B = step_size * base_GBT_B\n",
    "\n",
    "    #     if alpha > 1:  # Zero-order Hold\n",
    "    #         GBT_A = jax.scipy.linalg.expm(step_size * A)\n",
    "    #         GBT_B = (jnp.linalg.inv(A) @ (jax.scipy.linalg.expm(step_size * A) - I)) @ B\n",
    "\n",
    "    #     return (\n",
    "    #         GBT_A.astype(jnp.float32),\n",
    "    #         GBT_B.astype(jnp.float32),\n",
    "    #         C.astype(jnp.float32),\n",
    "    #         D.astype(jnp.float32),\n",
    "    #     )\n",
    "\n",
    "    def collect_SSM_vars(self, A, B, C, D, f, t_step=0, alpha=0.5):\n",
    "        \"\"\"\n",
    "        turns the continuos HiPPO matrix components into discrete ones\n",
    "\n",
    "        Args:\n",
    "            A (jnp.ndarray): matrix to be discretized\n",
    "            B (jnp.ndarray): matrix to be discretized\n",
    "            C (jnp.ndarray): matrix to be discretized\n",
    "            D (jnp.ndarray): matrix to be discretized\n",
    "            f (jnp.ndarray): input signal\n",
    "            alpha (float, optional): used for determining which generalized bilinear transformation to use\n",
    "\n",
    "        Returns:\n",
    "            Ab (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "            Bb (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "            Cb (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "            Db (jnp.ndarray): discrete form of the HiPPO matrix\n",
    "        \"\"\"\n",
    "        N = A.shape[0]\n",
    "\n",
    "        if t_step == 0:\n",
    "            L = f.shape[1]  # seq_L, 1\n",
    "            assert (\n",
    "                L == self.seq_L\n",
    "            ), f\"sequence length must match, currently {L} != {self.seq_L}\"\n",
    "            assert N == self.N, f\"Order number must match, currently {N} != {self.N}\"\n",
    "        else:\n",
    "            L = t_step\n",
    "            assert t_step >= 1, f\"time step must be greater than 0, currently {t_step}\"\n",
    "            assert N == self.N, f\"Order number must match, currently {N} != {self.N}\"\n",
    "\n",
    "        Ab, Bb, Cb, Db = self.discretize(A, B, C, D, step=L, alpha=alpha)\n",
    "\n",
    "        return (\n",
    "            Ab.astype(jnp.float32),\n",
    "            Bb.astype(jnp.float32),\n",
    "            Cb.astype(jnp.float32),\n",
    "            Db.astype(jnp.float32),\n",
    "        )\n",
    "\n",
    "    def scan_SSM(self, Ad, Bd, Cd, Dd, c_0, f):\n",
    "        \"\"\"\n",
    "        This is for returning the discretized hidden state often needed for an RNN.\n",
    "        Args:\n",
    "            Ab (jnp.ndarray): the discretized A matrix\n",
    "            Bb (jnp.ndarray): the discretized B matrix\n",
    "            Cb (jnp.ndarray): the discretized C matrix\n",
    "            f (jnp.ndarray): the input sequence\n",
    "            c_0 (jnp.ndarray): the initial hidden state\n",
    "        Returns:\n",
    "            the next hidden state (aka coefficients representing the function, f(t))\n",
    "        \"\"\"\n",
    "\n",
    "        def step(c_k_1, f_k):\n",
    "            \"\"\"\n",
    "            Get descretized coefficients of the hidden state by applying HiPPO matrix to input sequence, u_k, and previous hidden state, x_k_1.\n",
    "            Args:\n",
    "                c_k_1: previous hidden state\n",
    "                f_k: output from function f at, descritized, time step, k.\n",
    "                t:\n",
    "\n",
    "            Returns:\n",
    "                c_k: current hidden state\n",
    "                y_k: current output of hidden state applied to Cb (sorry for being vague, I just dont know yet)\n",
    "            \"\"\"\n",
    "            part1 = Ad @ c_k_1\n",
    "            # part2 = jnp.expand_dims((Bd @ f_k), -1)\n",
    "            part2 = Bd * f_k\n",
    "\n",
    "            c_k = part1 + part2\n",
    "            y_k = Cd @ c_k  # + (Db.T @ f_k)\n",
    "\n",
    "            return c_k, y_k\n",
    "\n",
    "        return jax.lax.scan(step, c_0, f)\n",
    "\n",
    "    def loop_SSM(self, A, B, C, D, c_0, f, alpha=0.5):\n",
    "        \"\"\"\n",
    "        This is for returning the discretized hidden state often needed for an RNN.\n",
    "        Args:\n",
    "            Ab (jnp.ndarray): the discretized A matrix\n",
    "            Bb (jnp.ndarray): the discretized B matrix\n",
    "            Cb (jnp.ndarray): the discretized C matrix\n",
    "            f (jnp.ndarray): the input sequence\n",
    "            c_0 (jnp.ndarray): the initial hidden state\n",
    "        Returns:\n",
    "            the next hidden state (aka coefficients representing the function, f(t))\n",
    "        \"\"\"\n",
    "        GBT_A_lst = []\n",
    "        GBT_B_lst = []\n",
    "        c_k_list = []\n",
    "        y_k_list = []\n",
    "\n",
    "        c_k = c_0.copy()\n",
    "        print(f\"f:\\n{f}\")\n",
    "        for i in range(f.shape[1]):\n",
    "            c_k, y_k = jax.vmap(self.loop_step, in_axes=(None, None, None, None, 0, 0))(\n",
    "                self.GBT_A_list[i], self.GBT_B_list[i], C, D, c_k, f[:, i, :]\n",
    "            )\n",
    "            c_k_list.append(c_k.copy())\n",
    "            y_k_list.append(y_k.copy())\n",
    "\n",
    "        return c_k_list, y_k_list, self.GBT_A_list, self.GBT_B_list\n",
    "\n",
    "    def loop_step(self, Ad, Bd, Cd, Dd, c_k_i, f_k):\n",
    "        \"\"\"\n",
    "        Get descretized coefficients of the hidden state by applying HiPPO matrix to input sequence, u_k, and previous hidden state, x_k_1.\n",
    "        Args:\n",
    "            c_k_i: previous hidden state\n",
    "            f_k: output from function f at, descritized, time step, k.\n",
    "\n",
    "        Returns:\n",
    "            c_k: current hidden state\n",
    "            y_k: current output of hidden state applied to Cb (sorry for being vague, I just dont know yet)\n",
    "        \"\"\"\n",
    "        jax.debug.print(f\"c_k_i:\\n{c_k_i}\")\n",
    "        jax.debug.print(f\"c_k_i shape:\\n{c_k_i.shape}\\n\")\n",
    "        jax.debug.print(f\"f_k:\\n{f_k}\")\n",
    "        jax.debug.print(f\"f_k shape:\\n{f_k.shape}\\n\")\n",
    "\n",
    "        part1 = Ad @ c_k_i\n",
    "        part2 = Bd * f_k\n",
    "        c_k = part1 + part2\n",
    "        y_k = Cd @ c_k  # + (Db.T @ f_k)\n",
    "\n",
    "        return c_k.astype(jnp.float32), y_k.astype(jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vmap_compare(gu_c, c_k):\n",
    "    # jax.debug.print(f\"c_k shape: {c_k.shape}\")\n",
    "    # jax.debug.print(f\"gu_c shape: {gu_c.shape}\")\n",
    "    for i in range(c_k.shape[0]):\n",
    "        # jax.debug.print(f\"c_k[i,:,:] shape: {c_k[i,:,:].shape}\")\n",
    "        # jax.debug.print(f\"gu_c[i,:,:] shape: {gu_c[i,:,:].shape}\")\n",
    "        # jax.debug.print(f\"c_k[{i},:,:]:\\n{c_k[i,:,:]}\\n\")\n",
    "        # jax.debug.print(f\"gu_c[{i},:,:]:\\n{gu_c[i,:,:]}\\n\")\n",
    "        \n",
    "        jax.debug.print(f\"HiPPO LegS Test: {jnp.allclose(c_k[i,:,:], gu_c[i,:,:], rtol=1e-03, atol=1e-03)}\")\n",
    "        #print(f\"c_k:\\n{c_k}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hippo_legs_operator(hippo_legs, nb_hippo_legs, gu_hippo_legs, nb_gu_hippo_legs, random_input, legs_key, nb_legs_key):\n",
    "    i = 0\n",
    "    print(f\"inputted data shape: {random_input.shape}\")\n",
    "    x_tensor = torch.tensor(random_input, dtype=torch.float32)\n",
    "    #nb_x_tensor = torch.squeeze(torch.tensor(random_input, dtype=torch.float32), dim=0)\n",
    "    x_jnp = jnp.asarray(x_tensor, dtype=jnp.float64)  # convert torch array to jax array\n",
    "    #nb_x_jnp = jnp.squeeze(x_jnp, axis=0)\n",
    "    # print(f\"Data jnp shape, no batch: {nb_x_jnp.shape}\")\n",
    "    # print(f\"Data tensor shape, no batch: {nb_x_tensor.shape}\")\n",
    "    print(f\"Data jnp shape: {x_jnp.shape}\")\n",
    "    print(f\"Data tensor shape: {x_tensor.shape}\")\n",
    "    \n",
    "    #NOT BATCHED\n",
    "    # nb_params = nb_hippo_legs.init(nb_legs_key, f=nb_x_jnp, t_step=(nb_x_jnp.shape[0]))\n",
    "    # nb_c_k_list, nb_y_k_list, nb_GBT_A_list, nb_GBT_B_list = nb_hippo_legs.apply(\n",
    "    #     nb_params, f=nb_x_jnp, t_step=(nb_x_jnp.shape[1])\n",
    "    # )\n",
    "    # nb_c_k = jnp.stack(nb_c_k_list, axis=0)\n",
    "    # print(f\"nb_c_k shape: {nb_c_k.shape}\")\n",
    "    \n",
    "    # BATCHED\n",
    "    params = hippo_legs.init(legs_key, f=x_jnp, t_step=(x_jnp.shape[1]))\n",
    "    c_k_list, y_k_list, GBT_A_list, GBT_B_list = hippo_legs.apply(\n",
    "        params, f=x_jnp, t_step=(x_jnp.shape[1])\n",
    "    )\n",
    "    c_k = jnp.stack(c_k_list, axis=0)\n",
    "    c_k = jnp.moveaxis(c_k, 0, 1)\n",
    "    print(f\"c_k shape: {c_k.shape}\")\n",
    "    \n",
    "    # Gu's HiPPO LegS\n",
    "    GU_c_k = gu_hippo_legs(x_tensor)\n",
    "    gu_c = jnp.asarray(GU_c_k, dtype=jnp.float64)  # convert torch array to jax array\n",
    "    gu_c = jnp.moveaxis(gu_c, -1, -2)\n",
    "    print(f\"gu_c shape: {gu_c.shape}\")\n",
    "    \n",
    "    # NOT BATCHED Gu's HiPPO LegS\n",
    "    # nb_GU_c_k = nb_gu_hippo_legs(nb_x_tensor, fast=True)\n",
    "    # nb_gu_c = jnp.asarray(nb_GU_c_k, dtype=jnp.float64)  # convert torch array to jax array\n",
    "    # nb_gu_c = jnp.moveaxis(nb_gu_c, -1, -2)\n",
    "    # print(f\"nb_gu_c shape: {nb_gu_c.shape}\")\n",
    "    \n",
    "    \n",
    "    # print(f\"c_k shape before vmap: {c_k.shape}\")\n",
    "    # print(f\"gu_c shape before vmap: {gu_c.shape}\")\n",
    "    \n",
    "    # print(f\"c_k before vmap:\\n{c_k}\")\n",
    "    # print(f\"nb_c_k before vmap:\\n{nb_c_k}\")\n",
    "    # print(f\"gu_c before vmap:\\n{gu_c}\")\n",
    "    for i in range(c_k.shape[0]):\n",
    "        for j in range(c_k.shape[1]):\n",
    "            jax.debug.print(f\"c_k @ b{i} t{j} - before vmap:\\n{c_k[i,j,:,:]}\\n\")\n",
    "            # jax.debug.print(f\"nb_c_k @ t{j} - before vmap:\\n{nb_c_k[j,:,:]}\\n\")\n",
    "            jax.debug.print(f\"gu_c @ b{i} t{j} - before vmap:\\n{gu_c[i,j,:,:]}\\n\")\n",
    "            # jax.debug.print(f\"nb_gu_c @ t{j} - before vmap:\\n{nb_gu_c[j,:,:]}\\n\")\n",
    "            jax.debug.print(f\"batch {i} on trajectory {j} compare : {jnp.allclose(c_k[i,j,:,:], gu_c[i,j,:,:], rtol=1e-03, atol=1e-03)}\")\n",
    "            # jax.debug.print(f\"no batch on trajectory {j} compare : {jnp.allclose(nb_c_k[j,:,:], gu_c[i,j,:,:], rtol=1e-03, atol=1e-03)}\")\n",
    "            # jax.debug.print(f\"no batch on trajectory {j} compare : {jnp.allclose(nb_c_k[j,:,:], nb_gu_c[j,:,:], rtol=1e-03, atol=1e-03)}\")\n",
    "            jax.debug.print(f\"no batch on trajectory {j} compare : {jnp.allclose(c_k[i,j,:,:], nb_gu_c[j,:,:], rtol=1e-03, atol=1e-03)}\")\n",
    "            # jax.debug.print(f\"no batch on trajectory {j} compare : {jnp.allclose(nb_gu_c[j,:,:], gu_c[i,j,:,:], rtol=1e-03, atol=1e-03)}\\n\")\n",
    "        \n",
    "    \n",
    "    #jax.vmap(vmap_compare, in_axes=(1, 1))(gu_c, c_k)\n",
    "    # print(f\"GU_c_k shape: {GU_c_k.shape}\")\n",
    "    # for i, c_k in enumerate(c_k_list):\n",
    "    #     g_c_k = GU_c_k[i,:,:,:]\n",
    "    #     # g_c_k = GU_c_k[i,:,:]\n",
    "    #     gu = torch.unsqueeze(g_c_k, -1)\n",
    "    #     gu_c = jnp.asarray(gu, dtype=jnp.float64)  # convert torch array to jax array\n",
    "    #     print(f\"HiPPO LegS Test: {jnp.allclose(c_k, gu_c, rtol=1e-04, atol=1e-06)}\")\n",
    "    #     #print(f\"c_k:\\n{c_k}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_16_input(key_generator, batch_size=16, data_size=784, input_size=28):\n",
    "    # x = jax.random.randint(key_generator, (batch_size, data_size), 0, 255)\n",
    "    x = jax.random.uniform(key_generator, (batch_size, data_size))\n",
    "    return jax.vmap(moving_window, in_axes=(0, None))(x, input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_GBT(hippo, gu_hippo, A, B, random_input):\n",
    "    L = random_input.shape[1]\n",
    "    for i in range(1, L+1):\n",
    "        GBT_A, GBT_B = hippo.discretion(A, B, step=i, alpha=0.5, dtype=jnp.float32)\n",
    "        gu_GBT_A, gu_GBT_B = (\n",
    "            jnp.asarray(gu_hippo.A_stacked[i-1], dtype=jnp.float32),\n",
    "            jnp.expand_dims(jnp.asarray(gu_hippo.B_stacked[i-1], dtype=jnp.float32), axis=1),\n",
    "        )\n",
    "        # print(f\"gu_GBT_A shape:{gu_GBT_A.shape}\\n\")\n",
    "        # print(f\"GBT_A shape: {GBT_A.shape}\\n\")\n",
    "        # print(f\"gu_GBT_B shape: {gu_GBT_B.shape}\\n\")\n",
    "        # print(f\"GBT_B shape: {GBT_B.shape}\")\n",
    "        \n",
    "        # print(f\"gu_GBT_A:\\n{gu_GBT_A}\\n\")\n",
    "        # print(f\"GBT_A:\\n{GBT_A}\\n\")\n",
    "        # print(f\"gu_GBT_B:\\n{gu_GBT_B}\\n\")\n",
    "        # print(f\"GBT_B:\\n{GBT_B}\")\n",
    "        \n",
    "        # print(f\"GBT_A: {jnp.allclose(GBT_A, gu_GBT_A, rtol=1e-04, atol=1e-04)}\")\n",
    "        # print(f\"GBT_B: {jnp.allclose(GBT_B, gu_GBT_B, rtol=1e-04, atol=1e-04)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # N = 256\n",
    "    # L = 128\n",
    "    \n",
    "    batch_size = 2\n",
    "    data_size = 16\n",
    "    input_size = 1\n",
    "    \n",
    "    N = 32\n",
    "    L = data_size\n",
    "    \n",
    "    x_jnp = random_16_input(\n",
    "        key_generator=key3, \n",
    "        batch_size=batch_size, \n",
    "        data_size=data_size, \n",
    "        input_size=input_size\n",
    "    )\n",
    "    x_np = np.asarray(x_jnp)\n",
    "    \n",
    "    # N = 16\n",
    "    # L = 8\n",
    "    \n",
    "    # x_np = np.array(\n",
    "    #     [\n",
    "    #         [0.3527],\n",
    "    #         [0.6617],\n",
    "    #         [0.2434],\n",
    "    #         [0.6674],\n",
    "    #         [1.2293],\n",
    "    #         [0.0964],\n",
    "    #         [-2.2756],\n",
    "    #         [0.5618],\n",
    "    #     ],\n",
    "    #     dtype=np.float32,\n",
    "    # )\n",
    "\n",
    "    # x = torch.randn(L, 1)\n",
    "    x = torch.tensor(x_np, dtype=torch.float32)\n",
    "\n",
    "    print(f\"X shape: {x.shape}\")\n",
    "    # print(f\"X:\\n{x}\")\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    loss = nn.MSELoss()\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ------------------------------ Test HiPPO LegT model -----------------------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    print(\"\\nTesting HiPPO LegT model\")\n",
    "    hippo_legt = HiPPO_LegT(N, dt=1.0 / L)\n",
    "\n",
    "    c_k = hippo_legt(x)\n",
    "\n",
    "    # print(f\"Gu's Coeffiecients for LegT:\\n{c_k}\")\n",
    "    # print(f\"Gu's Coeffiecient shapes for LegT:\\n{c_k.shape}\")\n",
    "\n",
    "    # z = hippo_legt.reconstruct(c_k)\n",
    "    # print(f\"Gu's Reconstruction for LegT:\\n{z}\")\n",
    "    # print(f\"Gu's Reconstruction shape for LegT:\\n{z.shape}\")\n",
    "\n",
    "    # mse = loss(z[-1, 0, :L], x.squeeze(-1))\n",
    "    # print(f\"h-MSE shape:\\n{mse}\")\n",
    "    # print(f\"end of test for HiPPO LegT model\")\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ------------------------------ Test HiPPO LegS model -----------------------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    print(\"\\nTesting HiPPO LegS model\")\n",
    "    gu_hippo_legs = HiPPO_LegS(N, max_length=L)  # The Gu's\n",
    "    \n",
    "    print(f\"gu_hippo_legs A_stacked: {gu_hippo_legs.A_stacked}\")\n",
    "    c_k = gu_hippo_legs(x, fast=True)\n",
    "\n",
    "    print(f\"Gu's Coeffiecients  for LegS:\\n{c_k}\")\n",
    "    print(f\"Gu's Coeffiecient shapes for LegS:\\n{c_k.shape}\")\n",
    "\n",
    "    # z = hippo_legs.reconstruct(c_k)\n",
    "\n",
    "    # print(f\"Gu's Reconstruction for LegS:\\n{z}\")\n",
    "    # print(f\"Gu's Reconstruction shape for LegS:\\n{z.shape}\")\n",
    "\n",
    "    # print(y-z)\n",
    "    print(f\"end of test for HiPPO LegS model\")\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ------------------------------ Test Generic HiPPO model --------------------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    the_measure = \"legs\"\n",
    "    print(f\"\\nTesting BRYANS HiPPO-{the_measure} model\")\n",
    "    legs_matrices = TransMatrix(N=N, measure=the_measure)\n",
    "    A = legs_matrices.A_matrix\n",
    "    B = legs_matrices.B_matrix\n",
    "    nb_hippo_LegS_B = nb_HiPPO(\n",
    "        N=N,\n",
    "        max_length=L,\n",
    "        step=1.0 / L,\n",
    "        GBT_alpha=0.5,\n",
    "        seq_L=L,\n",
    "        A=A,\n",
    "        B=B,\n",
    "        measure=the_measure,\n",
    "    )  # Bryan's\n",
    "    \n",
    "    hippo_LegS_B = HiPPO(\n",
    "        N=N,\n",
    "        max_length=L,\n",
    "        step=1.0 / L,\n",
    "        GBT_alpha=0.5,\n",
    "        seq_L=L,\n",
    "        A=A,\n",
    "        B=B,\n",
    "        measure=the_measure,\n",
    "    )  # Bryan's\n",
    "    \n",
    "    test_GBT(\n",
    "        hippo=hippo_LegS_B, \n",
    "        gu_hippo=gu_hippo_legs, \n",
    "        A=A, \n",
    "        B=B, \n",
    "        random_input=x_np\n",
    "    )    \n",
    "    # GBT_a_list = []\n",
    "    # GBT_b_list = []\n",
    "    # for i in range(L):\n",
    "    #     # TODO: make this scale invariant optional\n",
    "    #     GBT_A, GBT_B = hippo_LegS_B.discretion(A, B, step=L, alpha=0.5, dtype=jnp.float32)\n",
    "    #     GBT_a_list.append(GBT_A)\n",
    "    #     GBT_b_list.append(GBT_B)\n",
    "    # print(f\"GBT_a_list:\\n{GBT_a_list}\\n\")\n",
    "    # print(f\"GBT_b_list:\\n{GBT_b_list}\")\n",
    "    \n",
    "    print(f\"Bryan's Coeffiecients for HiPPO-{the_measure}\")\n",
    "    nb_gu_hippo_legs = HiPPO_LegS(N, max_length=L)  # The Gu's\n",
    "    test_hippo_legs_operator(hippo_legs=hippo_LegS_B, \n",
    "                             nb_hippo_legs=nb_hippo_LegS_B,\n",
    "                             gu_hippo_legs=gu_hippo_legs, \n",
    "                             nb_gu_hippo_legs=nb_gu_hippo_legs,\n",
    "                             random_input=x_np, \n",
    "                             legs_key=key2,\n",
    "                             nb_legs_key=key4)\n",
    "    \n",
    "    # y_legs = hippo_LegS_B.apply(\n",
    "    #     {\"params\": params}, c_k, method=hippo_LegS_B.reconstruct\n",
    "    # )\n",
    "\n",
    "    # print(f\"Bryan's Reconstruction for HiPPO-{the_measure}:\\n{y_legs}\")\n",
    "    # print(f\"Bryan's Reconstruction shape for HiPPO-{the_measure}:\\n{y_legs.shape}\")\n",
    "\n",
    "    print(f\"end of test for HiPPO-{the_measure} model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([2, 16, 1])\n",
      "\n",
      "Testing HiPPO LegT model\n",
      "\n",
      "Testing HiPPO LegS model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60022/1524178920.py:46: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "  self.eval_matrix = torch.from_numpy(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gu_hippo_legs A_stacked: tensor([[[ 3.3333e-01, -2.2230e-15,  3.7705e-15,  ...,  1.1191e-15,  1.7628e-15,  2.2591e-16],\n",
      "         [-5.7735e-01,  2.9802e-08,  1.0686e-15,  ..., -2.4980e-16, -7.3552e-16, -6.9389e-17],\n",
      "         [-1.4907e-01, -7.7460e-01, -2.0000e-01,  ..., -3.6316e-17,  4.0979e-16,  4.7384e-17],\n",
      "         ...,\n",
      "         [ 5.2325e-08, -1.9174e-07, -2.5004e-06,  ..., -8.7500e-01, -1.7738e-16,  4.7271e-17],\n",
      "         [-6.5608e-08,  2.0566e-07,  2.0668e-06,  ..., -2.2724e-01, -8.7879e-01, -3.1420e-16],\n",
      "         [ 6.0608e-08, -1.2849e-07, -1.8105e-06,  ...,  1.9018e-01, -2.2101e-01, -8.8235e-01]],\n",
      "\n",
      "        [[ 6.0000e-01, -3.5127e-15,  3.7322e-15,  ...,  1.9720e-15,  1.3421e-15,  8.8373e-17],\n",
      "         [-4.6188e-01,  3.3333e-01,  2.6368e-16,  ..., -5.5511e-16,  1.8041e-16,  2.5153e-16],\n",
      "         [-2.5555e-01, -7.3771e-01,  1.4286e-01,  ...,  1.8802e-15,  1.4118e-15,  3.1912e-16],\n",
      "         ...,\n",
      "         [ 2.0668e-08, -1.9147e-07,  7.6689e-08,  ..., -7.6471e-01, -5.0134e-16,  1.2924e-16],\n",
      "         [-3.2209e-08,  1.9052e-07, -8.1039e-08,  ..., -4.0331e-01, -7.7143e-01, -3.2943e-16],\n",
      "         [ 3.2505e-08, -1.0543e-07, -2.0006e-08,  ...,  2.9601e-01, -3.9360e-01, -7.7778e-01]],\n",
      "\n",
      "        [[ 7.1429e-01, -1.8542e-15,  7.2268e-16,  ...,  1.1697e-15,  7.5636e-16,  1.0982e-16],\n",
      "         [-3.7115e-01,  5.0000e-01, -1.0270e-15,  ...,  4.5103e-16,  3.4001e-16,  3.2092e-16],\n",
      "         [-2.6620e-01, -6.4550e-01,  3.3333e-01,  ..., -1.6867e-15, -5.0003e-16, -2.2208e-16],\n",
      "         ...,\n",
      "         [ 4.4030e-08, -1.3145e-07,  1.2056e-07,  ..., -6.6667e-01,  1.5266e-16,  1.3856e-16],\n",
      "         [-4.4793e-08,  9.7626e-08, -1.0966e-07,  ..., -5.4047e-01, -6.7568e-01, -1.8941e-16],\n",
      "         [ 2.3566e-08, -1.4568e-08, -3.3478e-08,  ...,  3.4690e-01, -5.2909e-01, -6.8421e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 9.3103e-01,  1.2296e-15, -6.4598e-16,  ..., -3.0784e-16,  1.7807e-16,  2.9290e-18],\n",
      "         [-1.1149e-01,  8.6667e-01,  6.8001e-16,  ...,  5.5511e-17, -5.5511e-17, -1.0842e-18],\n",
      "         [-1.2536e-01, -2.3321e-01,  8.0645e-01,  ...,  5.8536e-17, -3.0021e-16, -2.6025e-17],\n",
      "         ...,\n",
      "         [ 7.1434e-09, -6.1724e-08, -1.2370e-09,  ..., -3.4483e-02,  3.0206e-16,  2.3107e-17],\n",
      "         [-1.3861e-09,  4.3375e-08, -2.5738e-08,  ..., -9.8175e-01, -5.0847e-02, -1.8702e-18],\n",
      "         [ 2.2513e-09,  1.3873e-08, -1.0669e-08,  ...,  3.3257e-02, -9.8066e-01, -6.6667e-02]],\n",
      "\n",
      "        [[ 9.3548e-01, -2.1261e-16, -4.7086e-16,  ..., -4.7739e-16,  6.3820e-18, -4.7741e-18],\n",
      "         [-1.0476e-01,  8.7500e-01, -3.3307e-16,  ..., -6.7307e-16, -2.7409e-16, -1.3444e-17],\n",
      "         [-1.1885e-01, -2.2006e-01,  8.1818e-01,  ..., -7.6363e-17, -1.6592e-16, -5.2952e-18],\n",
      "         ...,\n",
      "         [ 1.2843e-08, -5.0748e-08, -4.8908e-09,  ...,  1.3704e-16,  1.9711e-16,  9.0599e-18],\n",
      "         [-2.1802e-10,  3.3529e-08,  1.1977e-08,  ..., -9.8347e-01, -1.6393e-02,  6.9321e-18],\n",
      "         [-1.5571e-08,  1.5271e-09, -9.3653e-08,  ..., -5.0075e-08, -9.8348e-01, -3.2258e-02]],\n",
      "\n",
      "        [[ 9.3939e-01,  1.2600e-15, -3.0211e-16,  ...,  7.7618e-17,  3.8933e-17,  0.0000e+00],\n",
      "         [-9.8798e-02,  8.8235e-01,  7.9103e-16,  ..., -1.5266e-16, -4.8919e-16,  0.0000e+00],\n",
      "         [-1.1297e-01, -2.0829e-01,  8.2857e-01,  ...,  1.0285e-16, -1.8650e-16,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 3.5383e-09, -5.3209e-08,  7.0965e-09,  ...,  3.2258e-02,  1.6870e-16,  0.0000e+00],\n",
      "         [-2.7888e-09,  3.5455e-08, -1.0577e-08,  ..., -9.8297e-01,  1.5873e-02,  0.0000e+00],\n",
      "         [ 3.3018e-09,  1.1219e-08, -4.9395e-08,  ..., -3.1217e-02, -9.8400e-01,  0.0000e+00]]])\n",
      "variable_unroll_matrix u shape: torch.Size([2, 16, 1, 32])\n",
      "has_batch: True\n",
      "u shape: torch.Size([2, 16, 1, 32])\n",
      "Gu's Coeffiecients  for LegS:\n",
      "tensor([[[[ 3.2127e-01,  2.7823e-01,  7.1838e-02,  ..., -2.5215e-08,  3.1617e-08, -2.9207e-08]],\n",
      "\n",
      "         [[ 1.3184e-01,  1.1418e-01,  2.9481e-02,  ..., -1.0348e-08,  1.2975e-08, -1.1986e-08]],\n",
      "\n",
      "         [[ 6.7515e-02,  5.8469e-02,  1.5097e-02,  ..., -5.2990e-09,  6.6443e-09, -6.1379e-09]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2723e-02,  1.9679e-02,  5.0811e-03,  ..., -1.7835e-09,  2.2362e-09, -2.0658e-09]],\n",
      "\n",
      "         [[ 4.5488e-01,  3.9394e-01,  1.0171e-01,  ..., -3.5702e-08,  4.4766e-08, -4.1354e-08]],\n",
      "\n",
      "         [[ 2.0649e-01,  1.7883e-01,  4.6173e-02,  ..., -1.6207e-08,  2.0321e-08, -1.8773e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7085e-01,  1.5000e-01, -1.6331e-01,  ..., -4.5009e-08,  4.7104e-08, -3.9437e-08]],\n",
      "\n",
      "         [[ 3.9553e-01,  3.4254e-01,  8.8443e-02,  ..., -3.1044e-08,  3.8925e-08, -3.5958e-08]],\n",
      "\n",
      "         [[ 2.8808e-01,  2.7417e-01,  9.9936e-02,  ..., -2.0317e-08,  2.6820e-08, -2.5364e-08]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9893e-01,  2.1002e-01,  9.8780e-02,  ..., -1.2106e-08,  1.7238e-08, -1.6823e-08]],\n",
      "\n",
      "         [[ 5.7833e-01,  2.7386e-01, -1.9721e-01,  ..., -6.6478e-08,  7.0980e-08, -6.0164e-08]],\n",
      "\n",
      "         [[ 3.1223e-01,  1.8170e-01, -5.7776e-02,  ..., -3.2746e-08,  3.6223e-08, -3.1350e-08]]]])\n",
      "Gu's Coeffiecient shapes for LegS:\n",
      "torch.Size([2, 16, 1, 32])\n",
      "end of test for HiPPO LegS model\n",
      "\n",
      "Testing BRYANS HiPPO-legs model\n",
      "Bryan's Coeffiecients for HiPPO-legs\n",
      "inputted data shape: (2, 16, 1)\n",
      "Data jnp shape: (2, 16, 1)\n",
      "Data tensor shape: torch.Size([2, 16, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60022/3587711683.py:6: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  x_jnp = jnp.asarray(x_tensor, dtype=jnp.float64)  # convert torch array to jax array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\n",
      "[[[0.48190224]\n",
      "  [0.19776285]\n",
      "  [0.10127199]\n",
      "  [0.00995553]\n",
      "  [0.29279542]\n",
      "  [0.99540186]\n",
      "  [0.58847713]\n",
      "  [0.0353756 ]\n",
      "  [0.7706082 ]\n",
      "  [0.08752763]\n",
      "  [0.27107787]\n",
      "  [0.41544926]\n",
      "  [0.97598505]\n",
      "  [0.0340848 ]\n",
      "  [0.6823162 ]\n",
      "  [0.30973995]]\n",
      "\n",
      " [[0.44523168]\n",
      "  [0.7910527 ]\n",
      "  [0.61892366]\n",
      "  [0.7225524 ]\n",
      "  [0.12798858]\n",
      "  [0.57040155]\n",
      "  [0.22614598]\n",
      "  [0.6732223 ]\n",
      "  [0.87575054]\n",
      "  [0.4019662 ]\n",
      "  [0.5075493 ]\n",
      "  [0.8612207 ]\n",
      "  [0.67529714]\n",
      "  [0.46322787]\n",
      "  [0.76350224]\n",
      "  [0.470829  ]]]\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.]],\n",
      "\n",
      "             [[0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.48190224],\n",
      "             [0.44523168]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.2126796e-01],\n",
      "              [ 2.7822685e-01],\n",
      "              [ 7.1837269e-02],\n",
      "              [-7.1809026e-08],\n",
      "              [ 7.1809026e-08],\n",
      "              [-7.3604255e-08],\n",
      "              [-2.1183664e-07],\n",
      "              [ 2.1542709e-07],\n",
      "              [-2.1542709e-08],\n",
      "              [ 8.7966065e-08],\n",
      "              [ 6.4628125e-08],\n",
      "              [-3.1595974e-07],\n",
      "              [ 4.3085419e-07],\n",
      "              [-5.4754383e-07],\n",
      "              [ 4.7034914e-07],\n",
      "              [-3.3391200e-07],\n",
      "              [ 2.2440322e-07],\n",
      "              [-3.2314063e-08],\n",
      "              [ 5.8344838e-08],\n",
      "              [-6.1037674e-08],\n",
      "              [-1.6875121e-07],\n",
      "              [ 2.9441702e-07],\n",
      "              [-1.4002761e-07],\n",
      "              [ 8.0785156e-09],\n",
      "              [ 2.0645096e-08],\n",
      "              [-1.2207535e-07],\n",
      "              [ 1.1040638e-07],\n",
      "              [ 7.1809030e-09],\n",
      "              [ 1.6157031e-08],\n",
      "              [ 5.7447224e-08],\n",
      "              [-1.5438941e-07],\n",
      "              [-5.7447224e-08]],\n",
      "\n",
      "             [[ 2.9682094e-01],\n",
      "              [ 2.5705504e-01],\n",
      "              [ 6.6370778e-02],\n",
      "              [-6.6344690e-08],\n",
      "              [ 6.6344690e-08],\n",
      "              [-6.8003310e-08],\n",
      "              [-1.9571684e-07],\n",
      "              [ 1.9903408e-07],\n",
      "              [-1.9903407e-08],\n",
      "              [ 8.1272248e-08],\n",
      "              [ 5.9710217e-08],\n",
      "              [-2.9191665e-07],\n",
      "              [ 3.9806815e-07],\n",
      "              [-5.0587823e-07],\n",
      "              [ 4.3455771e-07],\n",
      "              [-3.0850282e-07],\n",
      "              [ 2.0732716e-07],\n",
      "              [-2.9855109e-08],\n",
      "              [ 5.3905062e-08],\n",
      "              [-5.6392985e-08],\n",
      "              [-1.5591002e-07],\n",
      "              [ 2.7201324e-07],\n",
      "              [-1.2937214e-07],\n",
      "              [ 7.4637772e-09],\n",
      "              [ 1.9074099e-08],\n",
      "              [-1.1278597e-07],\n",
      "              [ 1.0200496e-07],\n",
      "              [ 6.6344690e-09],\n",
      "              [ 1.4927554e-08],\n",
      "              [ 5.3075752e-08],\n",
      "              [-1.4264108e-07],\n",
      "              [-5.3075752e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.19776285],\n",
      "             [0.7910527 ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 2.71866649e-01],\n",
      "              [ 3.56980935e-02],\n",
      "              [-2.26551116e-01],\n",
      "              [-1.30763426e-01],\n",
      "              [-1.64747015e-02],\n",
      "              [-2.99394003e-08],\n",
      "              [ 1.64629114e-07],\n",
      "              [ 7.32500638e-08],\n",
      "              [-3.34665799e-07],\n",
      "              [ 1.90003277e-07],\n",
      "              [-1.38461616e-07],\n",
      "              [ 1.06305194e-07],\n",
      "              [-1.36596805e-08],\n",
      "              [-1.29376474e-07],\n",
      "              [ 3.57571395e-07],\n",
      "              [-4.25093646e-07],\n",
      "              [ 3.79536857e-07],\n",
      "              [-4.76631357e-07],\n",
      "              [ 4.06084439e-07],\n",
      "              [-3.08564637e-07],\n",
      "              [ 4.63469860e-07],\n",
      "              [-5.34708363e-07],\n",
      "              [ 1.98579642e-07],\n",
      "              [-6.85786432e-08],\n",
      "              [ 7.64734338e-08],\n",
      "              [-1.18861898e-08],\n",
      "              [ 1.06301343e-07],\n",
      "              [-2.37858188e-07],\n",
      "              [ 1.58324553e-07],\n",
      "              [-1.67742641e-07],\n",
      "              [ 7.54606688e-08],\n",
      "              [ 2.01621390e-07]],\n",
      "\n",
      "             [[ 4.94514883e-01],\n",
      "              [ 3.13960224e-01],\n",
      "              [-5.38492650e-02],\n",
      "              [-7.48273656e-02],\n",
      "              [-9.42721218e-03],\n",
      "              [-1.55703603e-07],\n",
      "              [-4.95935666e-08],\n",
      "              [ 9.71371676e-08],\n",
      "              [ 1.68976953e-07],\n",
      "              [-3.91014680e-07],\n",
      "              [-5.76719472e-08],\n",
      "              [ 1.39008151e-07],\n",
      "              [ 9.77196990e-10],\n",
      "              [ 1.21822893e-07],\n",
      "              [ 1.30885383e-08],\n",
      "              [-2.04648273e-07],\n",
      "              [ 2.31678371e-07],\n",
      "              [-3.56511038e-07],\n",
      "              [ 1.24763972e-07],\n",
      "              [ 7.07151457e-08],\n",
      "              [-5.79061634e-08],\n",
      "              [ 8.16049237e-08],\n",
      "              [-1.88194406e-07],\n",
      "              [ 2.52780183e-07],\n",
      "              [-1.69567059e-07],\n",
      "              [ 1.55586790e-07],\n",
      "              [-1.35776844e-07],\n",
      "              [ 2.95279108e-08],\n",
      "              [-3.27560628e-08],\n",
      "              [-4.16662544e-08],\n",
      "              [ 6.06535053e-08],\n",
      "              [ 2.04408821e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.10127199],\n",
      "             [0.61892366]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 2.23125204e-01],\n",
      "              [-4.54680398e-02],\n",
      "              [-1.43972009e-01],\n",
      "              [ 1.20154589e-01],\n",
      "              [ 1.56972364e-01],\n",
      "              [ 4.41012569e-02],\n",
      "              [ 3.68787884e-03],\n",
      "              [-2.17320732e-07],\n",
      "              [ 4.47892283e-08],\n",
      "              [ 3.91072888e-07],\n",
      "              [-4.61935485e-07],\n",
      "              [ 4.69228667e-07],\n",
      "              [-3.90960594e-07],\n",
      "              [ 3.40897344e-07],\n",
      "              [-1.62948226e-07],\n",
      "              [-1.97765416e-07],\n",
      "              [ 4.19461855e-07],\n",
      "              [-3.49723479e-07],\n",
      "              [ 4.22405037e-07],\n",
      "              [-3.86507566e-07],\n",
      "              [ 8.54989892e-08],\n",
      "              [-9.89061348e-08],\n",
      "              [ 5.65914036e-07],\n",
      "              [-5.77203821e-07],\n",
      "              [ 3.09931892e-07],\n",
      "              [-2.04048646e-07],\n",
      "              [ 1.16114371e-07],\n",
      "              [-4.89270455e-08],\n",
      "              [ 1.17800866e-07],\n",
      "              [-8.15915016e-08],\n",
      "              [ 7.75694033e-08],\n",
      "              [-1.54597984e-07]],\n",
      "\n",
      "             [[ 5.30060768e-01],\n",
      "              [ 2.03154519e-01],\n",
      "              [-1.87492803e-01],\n",
      "              [-5.27307987e-02],\n",
      "              [ 5.22559658e-02],\n",
      "              [ 1.83136314e-02],\n",
      "              [ 1.53162587e-03],\n",
      "              [-8.36727310e-08],\n",
      "              [-1.95824033e-08],\n",
      "              [-9.85141213e-08],\n",
      "              [ 2.40389738e-07],\n",
      "              [ 1.10756190e-07],\n",
      "              [-2.50961250e-07],\n",
      "              [ 1.42558179e-07],\n",
      "              [-2.15409585e-07],\n",
      "              [ 8.04468101e-08],\n",
      "              [ 1.13009563e-07],\n",
      "              [-1.32703917e-07],\n",
      "              [ 3.54526037e-07],\n",
      "              [-3.19589390e-07],\n",
      "              [-7.11634129e-09],\n",
      "              [ 2.28850752e-08],\n",
      "              [ 1.60284927e-07],\n",
      "              [-1.31926726e-07],\n",
      "              [-1.40566826e-07],\n",
      "              [ 2.24522154e-07],\n",
      "              [-1.54844955e-07],\n",
      "              [ 2.09463010e-07],\n",
      "              [-1.73968999e-07],\n",
      "              [ 2.43805999e-07],\n",
      "              [-1.89309603e-07],\n",
      "              [-9.05541384e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.00995553],\n",
      "             [0.7225524 ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 1.75754353e-01],\n",
      "              [-9.29199085e-02],\n",
      "              [-9.37530324e-02],\n",
      "              [ 1.26544446e-01],\n",
      "              [-2.38695815e-02],\n",
      "              [-1.49988279e-01],\n",
      "              [-7.39153251e-02],\n",
      "              [-1.33907674e-02],\n",
      "              [-8.38593172e-04],\n",
      "              [-5.63080640e-08],\n",
      "              [-4.05759778e-07],\n",
      "              [ 5.09797530e-07],\n",
      "              [-3.97868064e-07],\n",
      "              [ 3.75392176e-07],\n",
      "              [-4.54369030e-07],\n",
      "              [ 3.78779788e-07],\n",
      "              [-1.77234639e-07],\n",
      "              [-7.48859250e-08],\n",
      "              [ 2.47633096e-07],\n",
      "              [-3.99061236e-07],\n",
      "              [ 4.74174470e-07],\n",
      "              [-2.90146914e-07],\n",
      "              [ 2.51454946e-09],\n",
      "              [-2.35614792e-07],\n",
      "              [ 5.26167071e-07],\n",
      "              [-5.54748397e-07],\n",
      "              [ 4.11412827e-07],\n",
      "              [-1.82366691e-07],\n",
      "              [-2.23357901e-08],\n",
      "              [-3.15437703e-08],\n",
      "              [-2.94531208e-08],\n",
      "              [ 1.49913063e-07]],\n",
      "\n",
      "             [[ 5.72836757e-01],\n",
      "              [ 1.81164876e-01],\n",
      "              [-1.50975332e-01],\n",
      "              [ 7.79755041e-02],\n",
      "              [ 9.66573507e-02],\n",
      "              [-1.63700525e-02],\n",
      "              [-2.07121987e-02],\n",
      "              [-4.22097091e-03],\n",
      "              [-2.63822440e-04],\n",
      "              [-9.44913552e-08],\n",
      "              [ 1.70468041e-07],\n",
      "              [-3.58624902e-07],\n",
      "              [-9.82781074e-08],\n",
      "              [ 1.76478551e-07],\n",
      "              [-6.78856225e-08],\n",
      "              [ 2.28098713e-07],\n",
      "              [-5.26483888e-08],\n",
      "              [-1.64797513e-07],\n",
      "              [ 3.28064935e-08],\n",
      "              [-1.12104701e-07],\n",
      "              [ 2.05880468e-07],\n",
      "              [ 1.23160319e-07],\n",
      "              [-2.05722444e-07],\n",
      "              [-7.48289786e-09],\n",
      "              [ 1.16771986e-07],\n",
      "              [ 5.90547558e-08],\n",
      "              [-2.18370488e-07],\n",
      "              [ 7.40034594e-08],\n",
      "              [ 1.05666231e-09],\n",
      "              [-4.20570245e-09],\n",
      "              [-1.76176513e-08],\n",
      "              [ 8.09077108e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.29279542],\n",
      "             [0.12798858]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 1.9703476e-01],\n",
      "              [-3.1231038e-02],\n",
      "              [ 2.3107942e-02],\n",
      "              [ 1.6493964e-01],\n",
      "              [-4.5034885e-02],\n",
      "              [-3.3076786e-02],\n",
      "              [ 1.2025125e-01],\n",
      "              [ 9.7792864e-02],\n",
      "              [ 2.9148988e-02],\n",
      "              [ 3.8795162e-03],\n",
      "              [ 1.9428460e-04],\n",
      "              [ 6.0739637e-08],\n",
      "              [-3.1024075e-07],\n",
      "              [ 7.4009500e-07],\n",
      "              [-8.1779774e-07],\n",
      "              [ 6.4182791e-07],\n",
      "              [-4.9136133e-07],\n",
      "              [ 3.8544709e-07],\n",
      "              [-2.5975450e-07],\n",
      "              [ 2.0162111e-07],\n",
      "              [-5.8408453e-08],\n",
      "              [-1.8653090e-07],\n",
      "              [ 1.4112310e-07],\n",
      "              [ 2.5295984e-07],\n",
      "              [-7.7826783e-08],\n",
      "              [-4.0073570e-07],\n",
      "              [ 5.4608279e-07],\n",
      "              [-5.1464275e-07],\n",
      "              [ 4.6492258e-07],\n",
      "              [-3.1397860e-07],\n",
      "              [ 3.4185658e-07],\n",
      "              [-2.3487246e-07]],\n",
      "\n",
      "             [[ 4.9195516e-01],\n",
      "              [ 4.0340908e-03],\n",
      "              [-2.7558962e-01],\n",
      "              [ 2.0259432e-04],\n",
      "              [-4.4300843e-02],\n",
      "              [-1.1596028e-01],\n",
      "              [-2.5029469e-02],\n",
      "              [ 1.3332540e-02],\n",
      "              [ 6.2478171e-03],\n",
      "              [ 9.1150863e-04],\n",
      "              [ 4.5632441e-05],\n",
      "              [ 9.8735150e-08],\n",
      "              [ 2.6204290e-07],\n",
      "              [-9.5278146e-08],\n",
      "              [ 2.2176536e-09],\n",
      "              [-5.0296403e-08],\n",
      "              [-1.3441286e-07],\n",
      "              [ 1.1808309e-08],\n",
      "              [ 2.1170440e-07],\n",
      "              [-1.3802493e-07],\n",
      "              [ 2.1616206e-07],\n",
      "              [-3.2757524e-07],\n",
      "              [ 1.0329405e-07],\n",
      "              [ 7.1421482e-08],\n",
      "              [-7.2828385e-08],\n",
      "              [-9.9326414e-10],\n",
      "              [ 8.0600273e-08],\n",
      "              [ 8.8267456e-08],\n",
      "              [-1.1436805e-07],\n",
      "              [ 1.2999298e-07],\n",
      "              [-8.3364831e-08],\n",
      "              [ 2.5523505e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.99540186],\n",
      "             [0.57040155]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.19860518e-01],\n",
      "              [ 1.60041094e-01],\n",
      "              [ 2.00323433e-01],\n",
      "              [ 2.06687003e-01],\n",
      "              [-5.94912171e-02],\n",
      "              [ 3.99919599e-03],\n",
      "              [ 6.54198900e-02],\n",
      "              [-7.56132826e-02],\n",
      "              [-1.09195106e-01],\n",
      "              [-4.86508720e-02],\n",
      "              [-1.03868200e-02],\n",
      "              [-1.09231635e-03],\n",
      "              [-4.55987283e-05],\n",
      "              [ 1.53383525e-07],\n",
      "              [-4.07641011e-07],\n",
      "              [ 6.64751440e-07],\n",
      "              [-6.38207780e-07],\n",
      "              [ 5.37248695e-07],\n",
      "              [-3.28999533e-07],\n",
      "              [ 1.24956728e-07],\n",
      "              [-3.67899418e-08],\n",
      "              [-9.94603226e-08],\n",
      "              [ 2.25263705e-07],\n",
      "              [-2.56733756e-07],\n",
      "              [-1.63364902e-07],\n",
      "              [ 1.73239556e-07],\n",
      "              [ 1.64490302e-07],\n",
      "              [-4.66476820e-07],\n",
      "              [ 5.36620973e-07],\n",
      "              [-5.53360110e-07],\n",
      "              [ 3.06995190e-07],\n",
      "              [-4.08484027e-07]],\n",
      "\n",
      "             [[ 5.04023671e-01],\n",
      "              [ 2.07990706e-02],\n",
      "              [-1.50176406e-01],\n",
      "              [ 1.74365968e-01],\n",
      "              [ 8.62271637e-02],\n",
      "              [ 4.72491533e-02],\n",
      "              [ 1.25129476e-01],\n",
      "              [ 6.71872795e-02],\n",
      "              [ 5.08046849e-03],\n",
      "              [-4.94501926e-03],\n",
      "              [-1.55107758e-03],\n",
      "              [-1.79019291e-04],\n",
      "              [-7.55026485e-06],\n",
      "              [-5.72205238e-07],\n",
      "              [ 4.88544970e-07],\n",
      "              [-1.66310684e-07],\n",
      "              [ 1.83835631e-08],\n",
      "              [ 2.36810280e-07],\n",
      "              [-8.20427317e-08],\n",
      "              [-2.81248219e-07],\n",
      "              [ 2.88846564e-07],\n",
      "              [-4.99207999e-07],\n",
      "              [ 5.33909599e-07],\n",
      "              [-1.08111500e-07],\n",
      "              [-1.10305578e-07],\n",
      "              [ 1.16756169e-08],\n",
      "              [ 9.14529750e-08],\n",
      "              [-3.19605363e-07],\n",
      "              [ 2.20975565e-07],\n",
      "              [-1.36706618e-07],\n",
      "              [-3.15749205e-08],\n",
      "              [-2.21013092e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.58847713],\n",
      "             [0.22614598]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.5567641e-01],\n",
      "              [ 1.7431086e-01],\n",
      "              [ 1.1940147e-01],\n",
      "              [-1.6786829e-03],\n",
      "              [-2.3897333e-01],\n",
      "              [-7.1304776e-02],\n",
      "              [-1.5348248e-02],\n",
      "              [-9.0500861e-02],\n",
      "              [ 2.0436250e-02],\n",
      "              [ 1.0311258e-01],\n",
      "              [ 6.7489967e-02],\n",
      "              [ 2.0816306e-02],\n",
      "              [ 3.4640050e-03],\n",
      "              [ 3.0123483e-04],\n",
      "              [ 1.0558117e-05],\n",
      "              [ 2.8346039e-07],\n",
      "              [-5.3862891e-07],\n",
      "              [ 5.2013053e-07],\n",
      "              [-5.2991766e-07],\n",
      "              [ 4.4222992e-07],\n",
      "              [-2.2648601e-07],\n",
      "              [ 1.5508544e-07],\n",
      "              [-4.9890048e-10],\n",
      "              [-1.4342965e-07],\n",
      "              [ 2.9515309e-07],\n",
      "              [ 5.1366655e-08],\n",
      "              [-3.1994284e-07],\n",
      "              [ 9.3612478e-08],\n",
      "              [ 2.4060182e-07],\n",
      "              [-3.9887647e-07],\n",
      "              [ 5.0142268e-07],\n",
      "              [-2.5650903e-07]],\n",
      "\n",
      "             [[ 4.6697247e-01],\n",
      "              [-4.0551972e-02],\n",
      "              [-1.6089991e-01],\n",
      "              [ 1.2789848e-01],\n",
      "              [-5.2095540e-02],\n",
      "              [-9.5692158e-02],\n",
      "              [-4.9347162e-02],\n",
      "              [-1.2314310e-01],\n",
      "              [-1.0410104e-01],\n",
      "              [-3.3261068e-02],\n",
      "              [-2.3970190e-03],\n",
      "              [ 1.0986915e-03],\n",
      "              [ 3.0017775e-04],\n",
      "              [ 2.9404880e-05],\n",
      "              [ 1.6152286e-06],\n",
      "              [-4.2116056e-07],\n",
      "              [ 1.4757161e-07],\n",
      "              [-7.1706509e-08],\n",
      "              [-2.7708651e-07],\n",
      "              [ 1.6878815e-07],\n",
      "              [ 2.9261892e-07],\n",
      "              [-2.4360099e-07],\n",
      "              [ 2.5210687e-07],\n",
      "              [-4.8971515e-07],\n",
      "              [ 2.9063236e-07],\n",
      "              [-5.7662501e-08],\n",
      "              [ 9.8517773e-08],\n",
      "              [-8.4184695e-09],\n",
      "              [ 1.4123887e-07],\n",
      "              [-1.6232710e-07],\n",
      "              [ 2.1170626e-07],\n",
      "              [-1.4290808e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.0353756],\n",
      "             [0.6732223]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.17993969e-01],\n",
      "              [ 7.75592551e-02],\n",
      "              [-4.06018645e-02],\n",
      "              [-1.61785871e-01],\n",
      "              [-2.37017408e-01],\n",
      "              [ 6.48391619e-02],\n",
      "              [ 9.84814763e-02],\n",
      "              [ 2.90234406e-02],\n",
      "              [ 1.05483234e-01],\n",
      "              [ 3.81647274e-02],\n",
      "              [-7.74736330e-02],\n",
      "              [-7.99860135e-02],\n",
      "              [-3.42251360e-02],\n",
      "              [-8.08216725e-03],\n",
      "              [-1.10224192e-03],\n",
      "              [-8.14831437e-05],\n",
      "              [-2.77519916e-06],\n",
      "              [ 4.18429437e-07],\n",
      "              [-4.07201782e-07],\n",
      "              [ 5.04638649e-07],\n",
      "              [-4.58530963e-07],\n",
      "              [ 2.48073491e-07],\n",
      "              [-1.94445533e-07],\n",
      "              [ 6.69620235e-08],\n",
      "              [ 1.00927913e-07],\n",
      "              [-3.05174723e-07],\n",
      "              [ 8.68256080e-08],\n",
      "              [ 3.19166219e-07],\n",
      "              [-2.13246153e-07],\n",
      "              [-7.51493801e-08],\n",
      "              [ 2.35908033e-07],\n",
      "              [-4.32100478e-07]],\n",
      "\n",
      "             [[ 4.91236925e-01],\n",
      "              [ 5.81765920e-03],\n",
      "              [-5.73190600e-02],\n",
      "              [ 2.00606287e-01],\n",
      "              [-1.76874623e-02],\n",
      "              [-1.80389732e-03],\n",
      "              [ 7.47348517e-02],\n",
      "              [ 4.09910195e-02],\n",
      "              [ 1.07169665e-01],\n",
      "              [ 1.28774300e-01],\n",
      "              [ 6.70330301e-02],\n",
      "              [ 1.75191108e-02],\n",
      "              [ 2.11375882e-03],\n",
      "              [ 3.42026487e-06],\n",
      "              [-2.81500779e-05],\n",
      "              [-3.13248870e-06],\n",
      "              [ 5.21531973e-08],\n",
      "              [ 1.97676655e-07],\n",
      "              [ 1.18508652e-07],\n",
      "              [ 1.13078791e-07],\n",
      "              [-3.14727004e-07],\n",
      "              [-5.46188517e-09],\n",
      "              [ 1.59614856e-07],\n",
      "              [-2.68361134e-07],\n",
      "              [ 3.95007248e-07],\n",
      "              [-3.67479828e-07],\n",
      "              [ 3.59618298e-07],\n",
      "              [-5.08952894e-07],\n",
      "              [ 1.88648954e-07],\n",
      "              [ 6.10989943e-08],\n",
      "              [ 6.65923494e-08],\n",
      "              [-4.62593903e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.7706082 ],\n",
      "             [0.87575054]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.65637422e-01],\n",
      "              [ 1.36316374e-01],\n",
      "              [ 2.28691623e-02],\n",
      "              [-3.96015719e-02],\n",
      "              [ 4.24408913e-03],\n",
      "              [ 2.75353312e-01],\n",
      "              [ 1.34140402e-01],\n",
      "              [-1.99828148e-02],\n",
      "              [-2.11504241e-03],\n",
      "              [-9.34445187e-02],\n",
      "              [-8.65450948e-02],\n",
      "              [ 3.55243050e-02],\n",
      "              [ 8.08538273e-02],\n",
      "              [ 4.80893031e-02],\n",
      "              [ 1.53195867e-02],\n",
      "              [ 2.93116877e-03],\n",
      "              [ 3.38567217e-04],\n",
      "              [ 2.19724334e-05],\n",
      "              [ 3.67012603e-07],\n",
      "              [ 1.39001813e-07],\n",
      "              [-4.41427517e-07],\n",
      "              [ 4.88867499e-07],\n",
      "              [-3.00725247e-07],\n",
      "              [ 2.24352391e-07],\n",
      "              [-4.41241674e-08],\n",
      "              [-3.14615335e-07],\n",
      "              [ 7.34234334e-07],\n",
      "              [-3.59917919e-07],\n",
      "              [-1.53758975e-07],\n",
      "              [ 1.32341114e-07],\n",
      "              [ 1.17658821e-07],\n",
      "              [-1.71076991e-07]],\n",
      "\n",
      "             [[ 5.31711757e-01],\n",
      "              [ 6.77487105e-02],\n",
      "              [ 2.30659842e-02],\n",
      "              [ 2.09162533e-01],\n",
      "              [-6.30087629e-02],\n",
      "              [-2.36117169e-02],\n",
      "              [ 2.13398691e-02],\n",
      "              [-4.77574170e-02],\n",
      "              [-2.53958311e-02],\n",
      "              [-7.80017972e-02],\n",
      "              [-1.35314807e-01],\n",
      "              [-9.97352973e-02],\n",
      "              [-4.02250327e-02],\n",
      "              [-9.89696197e-03],\n",
      "              [-1.56002818e-03],\n",
      "              [-1.62411699e-04],\n",
      "              [-1.13991728e-05],\n",
      "              [-7.18095350e-07],\n",
      "              [-2.22735309e-07],\n",
      "              [-4.84814962e-08],\n",
      "              [-9.21719163e-08],\n",
      "              [ 3.07748167e-07],\n",
      "              [-1.07324624e-07],\n",
      "              [-5.04831519e-08],\n",
      "              [ 1.01568503e-07],\n",
      "              [-1.97407388e-07],\n",
      "              [ 2.23975917e-07],\n",
      "              [-2.44170423e-07],\n",
      "              [ 5.06833601e-07],\n",
      "              [-2.34901364e-07],\n",
      "              [-6.73835530e-08],\n",
      "              [ 7.01660525e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.08752763],\n",
      "             [0.4019662 ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.39150667e-01],\n",
      "              [ 6.98259324e-02],\n",
      "              [-6.93100914e-02],\n",
      "              [-1.12711556e-01],\n",
      "              [-4.30479534e-02],\n",
      "              [ 1.14648916e-01],\n",
      "              [-1.43338427e-01],\n",
      "              [-2.19347000e-01],\n",
      "              [-8.56741369e-02],\n",
      "              [-6.52908310e-02],\n",
      "              [ 4.24190536e-02],\n",
      "              [ 1.07665859e-01],\n",
      "              [ 1.29719395e-02],\n",
      "              [-6.74246475e-02],\n",
      "              [-5.87774180e-02],\n",
      "              [-2.47620046e-02],\n",
      "              [-6.28557755e-03],\n",
      "              [-1.01076066e-03],\n",
      "              [-1.01237958e-04],\n",
      "              [-5.63967069e-06],\n",
      "              [-1.25597694e-07],\n",
      "              [ 3.32364237e-07],\n",
      "              [-6.13572070e-07],\n",
      "              [ 6.03344859e-07],\n",
      "              [-6.31827049e-07],\n",
      "              [ 5.24985126e-07],\n",
      "              [-1.18333503e-08],\n",
      "              [-5.97979977e-07],\n",
      "              [ 4.51686702e-07],\n",
      "              [-3.14649782e-08],\n",
      "              [ 3.62018113e-08],\n",
      "              [-1.92981133e-07]],\n",
      "\n",
      "             [[ 5.19355059e-01],\n",
      "              [ 3.59739959e-02],\n",
      "              [-2.44436488e-02],\n",
      "              [ 9.27324593e-02],\n",
      "              [-1.84498683e-01],\n",
      "              [-7.39340782e-02],\n",
      "              [-1.06109120e-02],\n",
      "              [-4.74515855e-02],\n",
      "              [ 1.50571335e-02],\n",
      "              [ 5.42512536e-03],\n",
      "              [ 3.94526310e-02],\n",
      "              [ 1.20729834e-01],\n",
      "              [ 1.23475105e-01],\n",
      "              [ 6.77901730e-02],\n",
      "              [ 2.34990474e-02],\n",
      "              [ 5.55459689e-03],\n",
      "              [ 9.31929506e-04],\n",
      "              [ 1.12237336e-04],\n",
      "              [ 9.44373005e-06],\n",
      "              [ 7.77275261e-07],\n",
      "              [ 3.23356630e-09],\n",
      "              [ 4.50423983e-08],\n",
      "              [-1.32895138e-07],\n",
      "              [-7.24179898e-08],\n",
      "              [ 2.99472617e-07],\n",
      "              [-3.43050345e-07],\n",
      "              [ 2.67511354e-07],\n",
      "              [-2.34062668e-07],\n",
      "              [ 1.23573301e-07],\n",
      "              [-3.90332190e-07],\n",
      "              [ 2.09890587e-07],\n",
      "              [ 6.88657877e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.27107787],\n",
      "             [0.5075493 ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.33231181e-01],\n",
      "              [ 4.87898439e-02],\n",
      "              [-8.26992840e-02],\n",
      "              [-7.76005387e-02],\n",
      "              [ 2.93120984e-02],\n",
      "              [ 1.30537599e-01],\n",
      "              [-1.06993116e-01],\n",
      "              [-1.99517161e-02],\n",
      "              [ 1.72241762e-01],\n",
      "              [ 1.40094325e-01],\n",
      "              [ 1.36641234e-01],\n",
      "              [ 4.03554477e-02],\n",
      "              [-8.92764851e-02],\n",
      "              [-5.34870923e-02],\n",
      "              [ 4.14964259e-02],\n",
      "              [ 6.26944453e-02],\n",
      "              [ 3.50425281e-02],\n",
      "              [ 1.14616444e-02],\n",
      "              [ 2.41854158e-03],\n",
      "              [ 3.34962213e-04],\n",
      "              [ 2.97558636e-05],\n",
      "              [ 1.32568755e-06],\n",
      "              [-1.53887441e-07],\n",
      "              [ 5.88689716e-07],\n",
      "              [-7.25462485e-07],\n",
      "              [ 5.77587343e-07],\n",
      "              [-4.50410823e-07],\n",
      "              [ 1.54172852e-07],\n",
      "              [ 3.90149921e-07],\n",
      "              [-4.83186056e-07],\n",
      "              [ 2.09585409e-07],\n",
      "              [-5.71503875e-08]],\n",
      "\n",
      "             [[ 5.18328249e-01],\n",
      "              [ 2.83483937e-02],\n",
      "              [-3.05620059e-02],\n",
      "              [ 6.30800352e-02],\n",
      "              [-1.63192362e-01],\n",
      "              [ 3.11717577e-02],\n",
      "              [ 8.92084166e-02],\n",
      "              [ 3.96005996e-02],\n",
      "              [ 7.39704594e-02],\n",
      "              [ 2.13237125e-02],\n",
      "              [ 1.66244451e-02],\n",
      "              [ 2.78946594e-03],\n",
      "              [-8.60123262e-02],\n",
      "              [-1.30955249e-01],\n",
      "              [-9.50254723e-02],\n",
      "              [-4.28236946e-02],\n",
      "              [-1.32480785e-02],\n",
      "              [-2.94690579e-03],\n",
      "              [-4.78695030e-04],\n",
      "              [-5.58567299e-05],\n",
      "              [-4.90659477e-06],\n",
      "              [-1.84759955e-07],\n",
      "              [-2.09418971e-09],\n",
      "              [ 7.07045160e-08],\n",
      "              [ 1.61660040e-07],\n",
      "              [-3.69112399e-07],\n",
      "              [ 4.14141823e-07],\n",
      "              [-2.84975556e-07],\n",
      "              [ 3.05965585e-07],\n",
      "              [-1.04190583e-07],\n",
      "              [ 3.49019899e-07],\n",
      "              [-2.61893319e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.41544926],\n",
      "             [0.8612207 ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.39808643e-01],\n",
      "              [ 5.17996848e-02],\n",
      "              [-6.56771436e-02],\n",
      "              [-2.56254636e-02],\n",
      "              [ 8.00861269e-02],\n",
      "              [ 1.07102908e-01],\n",
      "              [-1.20065272e-01],\n",
      "              [ 2.52240002e-02],\n",
      "              [ 1.12078026e-01],\n",
      "              [-5.79359904e-02],\n",
      "              [-1.14218302e-01],\n",
      "              [-1.68089017e-01],\n",
      "              [-1.27913520e-01],\n",
      "              [ 3.18418406e-02],\n",
      "              [ 7.14738965e-02],\n",
      "              [-9.74525884e-03],\n",
      "              [-5.77540509e-02],\n",
      "              [-4.40620929e-02],\n",
      "              [-1.83301251e-02],\n",
      "              [-4.90604760e-03],\n",
      "              [-8.85128276e-04],\n",
      "              [-1.07762899e-04],\n",
      "              [-8.55526287e-06],\n",
      "              [-6.78490508e-08],\n",
      "              [-7.17716716e-07],\n",
      "              [ 8.54735845e-07],\n",
      "              [-6.12301164e-07],\n",
      "              [ 5.08039307e-07],\n",
      "              [-3.02419551e-07],\n",
      "              [-1.39699651e-07],\n",
      "              [ 3.29507571e-07],\n",
      "              [-2.64112856e-07]],\n",
      "\n",
      "             [[ 5.45759559e-01],\n",
      "              [ 6.78450912e-02],\n",
      "              [ 1.69541016e-02],\n",
      "              [ 9.43975747e-02],\n",
      "              [-9.60028023e-02],\n",
      "              [ 1.16334349e-01],\n",
      "              [ 9.47329700e-02],\n",
      "              [-1.27963033e-02],\n",
      "              [-1.29976133e-02],\n",
      "              [-7.12866336e-02],\n",
      "              [-4.70813178e-02],\n",
      "              [-3.46630998e-02],\n",
      "              [-4.10198607e-02],\n",
      "              [ 3.67584489e-02],\n",
      "              [ 1.17574729e-01],\n",
      "              [ 1.15161128e-01],\n",
      "              [ 6.58481866e-02],\n",
      "              [ 2.54898239e-02],\n",
      "              [ 7.09981704e-03],\n",
      "              [ 1.45817408e-03],\n",
      "              [ 2.20423783e-04],\n",
      "              [ 2.42569968e-05],\n",
      "              [ 1.91152549e-06],\n",
      "              [-4.37359873e-08],\n",
      "              [ 2.15123364e-07],\n",
      "              [-5.19625189e-07],\n",
      "              [ 5.88475757e-07],\n",
      "              [-4.94346750e-07],\n",
      "              [ 4.62719782e-07],\n",
      "              [-6.17091189e-07],\n",
      "              [ 2.68805422e-07],\n",
      "              [-2.22670394e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.97598505],\n",
      "             [0.67529714]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.86932582e-01],\n",
      "              [ 1.20190673e-01],\n",
      "              [ 1.94139108e-02],\n",
      "              [ 7.21142069e-02],\n",
      "              [ 1.42101914e-01],\n",
      "              [ 9.19401571e-02],\n",
      "              [-1.14900589e-01],\n",
      "              [ 6.21360093e-02],\n",
      "              [ 6.50292784e-02],\n",
      "              [-1.03280731e-01],\n",
      "              [-3.85762192e-02],\n",
      "              [ 3.43162641e-02],\n",
      "              [ 1.37380511e-01],\n",
      "              [ 1.85807317e-01],\n",
      "              [ 4.88430224e-02],\n",
      "              [-5.82704507e-02],\n",
      "              [-1.78808570e-02],\n",
      "              [ 4.45786901e-02],\n",
      "              [ 4.96054403e-02],\n",
      "              [ 2.62180157e-02],\n",
      "              [ 8.72579683e-03],\n",
      "              [ 1.97673822e-03],\n",
      "              [ 3.11648007e-04],\n",
      "              [ 3.39102444e-05],\n",
      "              [ 1.77499305e-06],\n",
      "              [ 1.04788012e-06],\n",
      "              [-7.55900714e-07],\n",
      "              [ 3.19250546e-07],\n",
      "              [-4.60586477e-07],\n",
      "              [ 1.64901735e-07],\n",
      "              [ 2.08884828e-07],\n",
      "              [-2.02401679e-07]],\n",
      "\n",
      "             [[ 5.55354953e-01],\n",
      "              [ 7.35856295e-02],\n",
      "              [ 1.37944147e-02],\n",
      "              [ 6.35593757e-02],\n",
      "              [-1.11694396e-01],\n",
      "              [ 8.73161554e-02],\n",
      "              [-3.85547429e-03],\n",
      "              [-1.04984246e-01],\n",
      "              [-5.41410819e-02],\n",
      "              [-4.73239198e-02],\n",
      "              [ 2.89472956e-02],\n",
      "              [ 4.66640107e-02],\n",
      "              [ 3.93239930e-02],\n",
      "              [ 6.58285841e-02],\n",
      "              [ 1.69387907e-02],\n",
      "              [-8.33495930e-02],\n",
      "              [-1.21508375e-01],\n",
      "              [-8.85373428e-02],\n",
      "              [-4.21450995e-02],\n",
      "              [-1.43070621e-02],\n",
      "              [-3.59283644e-03],\n",
      "              [-6.74237206e-04],\n",
      "              [-9.41463877e-05],\n",
      "              [-9.58832698e-06],\n",
      "              [-4.29782006e-07],\n",
      "              [-3.35247734e-07],\n",
      "              [ 5.53586347e-07],\n",
      "              [-6.24420295e-07],\n",
      "              [ 4.55776558e-07],\n",
      "              [-4.59722912e-07],\n",
      "              [ 5.95348979e-07],\n",
      "              [-2.61070852e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.0340848 ],\n",
      "             [0.46322787]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.62598598e-01],\n",
      "              [ 6.48272783e-02],\n",
      "              [-5.66064753e-02],\n",
      "              [-2.18688622e-02],\n",
      "              [ 3.44122364e-03],\n",
      "              [-8.56820643e-02],\n",
      "              [-2.24389046e-01],\n",
      "              [ 3.78886727e-03],\n",
      "              [-2.68908162e-02],\n",
      "              [-1.29014403e-01],\n",
      "              [ 2.01183204e-02],\n",
      "              [ 6.15537316e-02],\n",
      "              [ 4.28383090e-02],\n",
      "              [-5.70761375e-02],\n",
      "              [-1.89477712e-01],\n",
      "              [-1.26428336e-01],\n",
      "              [ 1.53944455e-02],\n",
      "              [ 3.14408615e-02],\n",
      "              [-2.68194303e-02],\n",
      "              [-5.01730777e-02],\n",
      "              [-3.39868963e-02],\n",
      "              [-1.39105069e-02],\n",
      "              [-3.86565155e-03],\n",
      "              [-7.59374874e-04],\n",
      "              [-1.06470805e-04],\n",
      "              [-9.63351522e-06],\n",
      "              [-1.62337847e-06],\n",
      "              [ 6.32295325e-07],\n",
      "              [-1.34169071e-07],\n",
      "              [ 4.68970825e-07],\n",
      "              [-2.57608519e-07],\n",
      "              [-2.45484330e-07]],\n",
      "\n",
      "             [[ 5.49001396e-01],\n",
      "              [ 5.35029434e-02],\n",
      "              [-1.75854154e-02],\n",
      "              [ 1.54619776e-02],\n",
      "              [-1.32267356e-01],\n",
      "              [ 6.94985390e-02],\n",
      "              [-4.21626605e-02],\n",
      "              [-8.20906684e-02],\n",
      "              [ 2.83201933e-02],\n",
      "              [ 4.75656316e-02],\n",
      "              [ 8.41812864e-02],\n",
      "              [ 2.95305327e-02],\n",
      "              [-1.91251021e-02],\n",
      "              [-2.45492551e-02],\n",
      "              [-6.88041374e-02],\n",
      "              [-6.20833449e-02],\n",
      "              [ 3.39673981e-02],\n",
      "              [ 1.09573998e-01],\n",
      "              [ 1.05455279e-01],\n",
      "              [ 6.16375841e-02],\n",
      "              [ 2.51651425e-02],\n",
      "              [ 7.57479714e-03],\n",
      "              [ 1.71716698e-03],\n",
      "              [ 2.94170866e-04],\n",
      "              [ 3.78282821e-05],\n",
      "              [ 3.14066028e-06],\n",
      "              [ 6.26070289e-07],\n",
      "              [-4.93423101e-07],\n",
      "              [ 4.49634854e-07],\n",
      "              [-3.65029848e-07],\n",
      "              [ 4.62845776e-07],\n",
      "              [-5.77248954e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.6823162 ],\n",
      "             [0.76350224]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.83225322e-01],\n",
      "              [ 9.02176350e-02],\n",
      "              [-2.25807205e-02],\n",
      "              [ 2.43114941e-02],\n",
      "              [ 4.71040495e-02],\n",
      "              [-2.31048428e-02],\n",
      "              [-6.83445930e-02],\n",
      "              [ 1.84173062e-01],\n",
      "              [ 9.73232985e-02],\n",
      "              [ 1.90885551e-02],\n",
      "              [ 1.48620471e-01],\n",
      "              [ 8.03933144e-02],\n",
      "              [-7.21798232e-03],\n",
      "              [-6.63189888e-02],\n",
      "              [-3.26013938e-02],\n",
      "              [ 1.37183100e-01],\n",
      "              [ 1.74321979e-01],\n",
      "              [ 4.50289957e-02],\n",
      "              [-2.47450396e-02],\n",
      "              [ 1.03015313e-02],\n",
      "              [ 4.57064956e-02],\n",
      "              [ 4.03288417e-02],\n",
      "              [ 2.01884527e-02],\n",
      "              [ 6.77637570e-03],\n",
      "              [ 1.61817204e-03],\n",
      "              [ 2.80865206e-04],\n",
      "              [ 3.47836612e-05],\n",
      "              [ 3.60408148e-06],\n",
      "              [-4.61338416e-08],\n",
      "              [-2.08732843e-07],\n",
      "              [-9.48112131e-08],\n",
      "              [ 1.87891928e-07]],\n",
      "\n",
      "             [[ 5.62840223e-01],\n",
      "              [ 6.92864135e-02],\n",
      "              [-6.67698681e-04],\n",
      "              [ 3.07565890e-02],\n",
      "              [-8.41037929e-02],\n",
      "              [ 1.17283404e-01],\n",
      "              [-1.15292631e-02],\n",
      "              [-1.24416463e-02],\n",
      "              [ 9.03487355e-02],\n",
      "              [ 4.78735082e-02],\n",
      "              [ 1.72226094e-02],\n",
      "              [-6.26646951e-02],\n",
      "              [-6.57846257e-02],\n",
      "              [-1.79227237e-02],\n",
      "              [-5.64040057e-03],\n",
      "              [ 4.71209325e-02],\n",
      "              [ 8.62403437e-02],\n",
      "              [ 1.97739359e-02],\n",
      "              [-7.89951459e-02],\n",
      "              [-1.11074179e-01],\n",
      "              [-8.08428079e-02],\n",
      "              [-3.95363271e-02],\n",
      "              [-1.40978238e-02],\n",
      "              [-3.79172829e-03],\n",
      "              [-7.78728572e-04],\n",
      "              [-1.22084122e-04],\n",
      "              [-1.40020720e-05],\n",
      "              [-1.54143106e-06],\n",
      "              [ 2.93385057e-07],\n",
      "              [-3.78520156e-07],\n",
      "              [ 3.69984150e-07],\n",
      "              [-4.73194063e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.30973995],\n",
      "             [0.470829  ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "f:\n",
      "[[[0.48190224]\n",
      "  [0.19776285]\n",
      "  [0.10127199]\n",
      "  [0.00995553]\n",
      "  [0.29279542]\n",
      "  [0.99540186]\n",
      "  [0.58847713]\n",
      "  [0.0353756 ]\n",
      "  [0.7706082 ]\n",
      "  [0.08752763]\n",
      "  [0.27107787]\n",
      "  [0.41544926]\n",
      "  [0.97598505]\n",
      "  [0.0340848 ]\n",
      "  [0.6823162 ]\n",
      "  [0.30973995]]\n",
      "\n",
      " [[0.44523168]\n",
      "  [0.7910527 ]\n",
      "  [0.61892366]\n",
      "  [0.7225524 ]\n",
      "  [0.12798858]\n",
      "  [0.57040155]\n",
      "  [0.22614598]\n",
      "  [0.6732223 ]\n",
      "  [0.87575054]\n",
      "  [0.4019662 ]\n",
      "  [0.5075493 ]\n",
      "  [0.8612207 ]\n",
      "  [0.67529714]\n",
      "  [0.46322787]\n",
      "  [0.76350224]\n",
      "  [0.470829  ]]]\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.]],\n",
      "\n",
      "             [[0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.],\n",
      "              [0.]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.48190224],\n",
      "             [0.44523168]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.2126796e-01],\n",
      "              [ 2.7822685e-01],\n",
      "              [ 7.1837269e-02],\n",
      "              [-7.1809026e-08],\n",
      "              [ 7.1809026e-08],\n",
      "              [-7.3604255e-08],\n",
      "              [-2.1183664e-07],\n",
      "              [ 2.1542709e-07],\n",
      "              [-2.1542709e-08],\n",
      "              [ 8.7966065e-08],\n",
      "              [ 6.4628125e-08],\n",
      "              [-3.1595974e-07],\n",
      "              [ 4.3085419e-07],\n",
      "              [-5.4754383e-07],\n",
      "              [ 4.7034914e-07],\n",
      "              [-3.3391200e-07],\n",
      "              [ 2.2440322e-07],\n",
      "              [-3.2314063e-08],\n",
      "              [ 5.8344838e-08],\n",
      "              [-6.1037674e-08],\n",
      "              [-1.6875121e-07],\n",
      "              [ 2.9441702e-07],\n",
      "              [-1.4002761e-07],\n",
      "              [ 8.0785156e-09],\n",
      "              [ 2.0645096e-08],\n",
      "              [-1.2207535e-07],\n",
      "              [ 1.1040638e-07],\n",
      "              [ 7.1809030e-09],\n",
      "              [ 1.6157031e-08],\n",
      "              [ 5.7447224e-08],\n",
      "              [-1.5438941e-07],\n",
      "              [-5.7447224e-08]],\n",
      "\n",
      "             [[ 2.9682094e-01],\n",
      "              [ 2.5705504e-01],\n",
      "              [ 6.6370778e-02],\n",
      "              [-6.6344690e-08],\n",
      "              [ 6.6344690e-08],\n",
      "              [-6.8003310e-08],\n",
      "              [-1.9571684e-07],\n",
      "              [ 1.9903408e-07],\n",
      "              [-1.9903407e-08],\n",
      "              [ 8.1272248e-08],\n",
      "              [ 5.9710217e-08],\n",
      "              [-2.9191665e-07],\n",
      "              [ 3.9806815e-07],\n",
      "              [-5.0587823e-07],\n",
      "              [ 4.3455771e-07],\n",
      "              [-3.0850282e-07],\n",
      "              [ 2.0732716e-07],\n",
      "              [-2.9855109e-08],\n",
      "              [ 5.3905062e-08],\n",
      "              [-5.6392985e-08],\n",
      "              [-1.5591002e-07],\n",
      "              [ 2.7201324e-07],\n",
      "              [-1.2937214e-07],\n",
      "              [ 7.4637772e-09],\n",
      "              [ 1.9074099e-08],\n",
      "              [-1.1278597e-07],\n",
      "              [ 1.0200496e-07],\n",
      "              [ 6.6344690e-09],\n",
      "              [ 1.4927554e-08],\n",
      "              [ 5.3075752e-08],\n",
      "              [-1.4264108e-07],\n",
      "              [-5.3075752e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.19776285],\n",
      "             [0.7910527 ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 2.71866649e-01],\n",
      "              [ 3.56980935e-02],\n",
      "              [-2.26551116e-01],\n",
      "              [-1.30763426e-01],\n",
      "              [-1.64747015e-02],\n",
      "              [-2.99394003e-08],\n",
      "              [ 1.64629114e-07],\n",
      "              [ 7.32500638e-08],\n",
      "              [-3.34665799e-07],\n",
      "              [ 1.90003277e-07],\n",
      "              [-1.38461616e-07],\n",
      "              [ 1.06305194e-07],\n",
      "              [-1.36596805e-08],\n",
      "              [-1.29376474e-07],\n",
      "              [ 3.57571395e-07],\n",
      "              [-4.25093646e-07],\n",
      "              [ 3.79536857e-07],\n",
      "              [-4.76631357e-07],\n",
      "              [ 4.06084439e-07],\n",
      "              [-3.08564637e-07],\n",
      "              [ 4.63469860e-07],\n",
      "              [-5.34708363e-07],\n",
      "              [ 1.98579642e-07],\n",
      "              [-6.85786432e-08],\n",
      "              [ 7.64734338e-08],\n",
      "              [-1.18861898e-08],\n",
      "              [ 1.06301343e-07],\n",
      "              [-2.37858188e-07],\n",
      "              [ 1.58324553e-07],\n",
      "              [-1.67742641e-07],\n",
      "              [ 7.54606688e-08],\n",
      "              [ 2.01621390e-07]],\n",
      "\n",
      "             [[ 4.94514883e-01],\n",
      "              [ 3.13960224e-01],\n",
      "              [-5.38492650e-02],\n",
      "              [-7.48273656e-02],\n",
      "              [-9.42721218e-03],\n",
      "              [-1.55703603e-07],\n",
      "              [-4.95935666e-08],\n",
      "              [ 9.71371676e-08],\n",
      "              [ 1.68976953e-07],\n",
      "              [-3.91014680e-07],\n",
      "              [-5.76719472e-08],\n",
      "              [ 1.39008151e-07],\n",
      "              [ 9.77196990e-10],\n",
      "              [ 1.21822893e-07],\n",
      "              [ 1.30885383e-08],\n",
      "              [-2.04648273e-07],\n",
      "              [ 2.31678371e-07],\n",
      "              [-3.56511038e-07],\n",
      "              [ 1.24763972e-07],\n",
      "              [ 7.07151457e-08],\n",
      "              [-5.79061634e-08],\n",
      "              [ 8.16049237e-08],\n",
      "              [-1.88194406e-07],\n",
      "              [ 2.52780183e-07],\n",
      "              [-1.69567059e-07],\n",
      "              [ 1.55586790e-07],\n",
      "              [-1.35776844e-07],\n",
      "              [ 2.95279108e-08],\n",
      "              [-3.27560628e-08],\n",
      "              [-4.16662544e-08],\n",
      "              [ 6.06535053e-08],\n",
      "              [ 2.04408821e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.10127199],\n",
      "             [0.61892366]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 2.23125204e-01],\n",
      "              [-4.54680398e-02],\n",
      "              [-1.43972009e-01],\n",
      "              [ 1.20154589e-01],\n",
      "              [ 1.56972364e-01],\n",
      "              [ 4.41012569e-02],\n",
      "              [ 3.68787884e-03],\n",
      "              [-2.17320732e-07],\n",
      "              [ 4.47892283e-08],\n",
      "              [ 3.91072888e-07],\n",
      "              [-4.61935485e-07],\n",
      "              [ 4.69228667e-07],\n",
      "              [-3.90960594e-07],\n",
      "              [ 3.40897344e-07],\n",
      "              [-1.62948226e-07],\n",
      "              [-1.97765416e-07],\n",
      "              [ 4.19461855e-07],\n",
      "              [-3.49723479e-07],\n",
      "              [ 4.22405037e-07],\n",
      "              [-3.86507566e-07],\n",
      "              [ 8.54989892e-08],\n",
      "              [-9.89061348e-08],\n",
      "              [ 5.65914036e-07],\n",
      "              [-5.77203821e-07],\n",
      "              [ 3.09931892e-07],\n",
      "              [-2.04048646e-07],\n",
      "              [ 1.16114371e-07],\n",
      "              [-4.89270455e-08],\n",
      "              [ 1.17800866e-07],\n",
      "              [-8.15915016e-08],\n",
      "              [ 7.75694033e-08],\n",
      "              [-1.54597984e-07]],\n",
      "\n",
      "             [[ 5.30060768e-01],\n",
      "              [ 2.03154519e-01],\n",
      "              [-1.87492803e-01],\n",
      "              [-5.27307987e-02],\n",
      "              [ 5.22559658e-02],\n",
      "              [ 1.83136314e-02],\n",
      "              [ 1.53162587e-03],\n",
      "              [-8.36727310e-08],\n",
      "              [-1.95824033e-08],\n",
      "              [-9.85141213e-08],\n",
      "              [ 2.40389738e-07],\n",
      "              [ 1.10756190e-07],\n",
      "              [-2.50961250e-07],\n",
      "              [ 1.42558179e-07],\n",
      "              [-2.15409585e-07],\n",
      "              [ 8.04468101e-08],\n",
      "              [ 1.13009563e-07],\n",
      "              [-1.32703917e-07],\n",
      "              [ 3.54526037e-07],\n",
      "              [-3.19589390e-07],\n",
      "              [-7.11634129e-09],\n",
      "              [ 2.28850752e-08],\n",
      "              [ 1.60284927e-07],\n",
      "              [-1.31926726e-07],\n",
      "              [-1.40566826e-07],\n",
      "              [ 2.24522154e-07],\n",
      "              [-1.54844955e-07],\n",
      "              [ 2.09463010e-07],\n",
      "              [-1.73968999e-07],\n",
      "              [ 2.43805999e-07],\n",
      "              [-1.89309603e-07],\n",
      "              [-9.05541384e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.00995553],\n",
      "             [0.7225524 ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 1.75754353e-01],\n",
      "              [-9.29199085e-02],\n",
      "              [-9.37530324e-02],\n",
      "              [ 1.26544446e-01],\n",
      "              [-2.38695815e-02],\n",
      "              [-1.49988279e-01],\n",
      "              [-7.39153251e-02],\n",
      "              [-1.33907674e-02],\n",
      "              [-8.38593172e-04],\n",
      "              [-5.63080640e-08],\n",
      "              [-4.05759778e-07],\n",
      "              [ 5.09797530e-07],\n",
      "              [-3.97868064e-07],\n",
      "              [ 3.75392176e-07],\n",
      "              [-4.54369030e-07],\n",
      "              [ 3.78779788e-07],\n",
      "              [-1.77234639e-07],\n",
      "              [-7.48859250e-08],\n",
      "              [ 2.47633096e-07],\n",
      "              [-3.99061236e-07],\n",
      "              [ 4.74174470e-07],\n",
      "              [-2.90146914e-07],\n",
      "              [ 2.51454946e-09],\n",
      "              [-2.35614792e-07],\n",
      "              [ 5.26167071e-07],\n",
      "              [-5.54748397e-07],\n",
      "              [ 4.11412827e-07],\n",
      "              [-1.82366691e-07],\n",
      "              [-2.23357901e-08],\n",
      "              [-3.15437703e-08],\n",
      "              [-2.94531208e-08],\n",
      "              [ 1.49913063e-07]],\n",
      "\n",
      "             [[ 5.72836757e-01],\n",
      "              [ 1.81164876e-01],\n",
      "              [-1.50975332e-01],\n",
      "              [ 7.79755041e-02],\n",
      "              [ 9.66573507e-02],\n",
      "              [-1.63700525e-02],\n",
      "              [-2.07121987e-02],\n",
      "              [-4.22097091e-03],\n",
      "              [-2.63822440e-04],\n",
      "              [-9.44913552e-08],\n",
      "              [ 1.70468041e-07],\n",
      "              [-3.58624902e-07],\n",
      "              [-9.82781074e-08],\n",
      "              [ 1.76478551e-07],\n",
      "              [-6.78856225e-08],\n",
      "              [ 2.28098713e-07],\n",
      "              [-5.26483888e-08],\n",
      "              [-1.64797513e-07],\n",
      "              [ 3.28064935e-08],\n",
      "              [-1.12104701e-07],\n",
      "              [ 2.05880468e-07],\n",
      "              [ 1.23160319e-07],\n",
      "              [-2.05722444e-07],\n",
      "              [-7.48289786e-09],\n",
      "              [ 1.16771986e-07],\n",
      "              [ 5.90547558e-08],\n",
      "              [-2.18370488e-07],\n",
      "              [ 7.40034594e-08],\n",
      "              [ 1.05666231e-09],\n",
      "              [-4.20570245e-09],\n",
      "              [-1.76176513e-08],\n",
      "              [ 8.09077108e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.29279542],\n",
      "             [0.12798858]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 1.9703476e-01],\n",
      "              [-3.1231038e-02],\n",
      "              [ 2.3107942e-02],\n",
      "              [ 1.6493964e-01],\n",
      "              [-4.5034885e-02],\n",
      "              [-3.3076786e-02],\n",
      "              [ 1.2025125e-01],\n",
      "              [ 9.7792864e-02],\n",
      "              [ 2.9148988e-02],\n",
      "              [ 3.8795162e-03],\n",
      "              [ 1.9428460e-04],\n",
      "              [ 6.0739637e-08],\n",
      "              [-3.1024075e-07],\n",
      "              [ 7.4009500e-07],\n",
      "              [-8.1779774e-07],\n",
      "              [ 6.4182791e-07],\n",
      "              [-4.9136133e-07],\n",
      "              [ 3.8544709e-07],\n",
      "              [-2.5975450e-07],\n",
      "              [ 2.0162111e-07],\n",
      "              [-5.8408453e-08],\n",
      "              [-1.8653090e-07],\n",
      "              [ 1.4112310e-07],\n",
      "              [ 2.5295984e-07],\n",
      "              [-7.7826783e-08],\n",
      "              [-4.0073570e-07],\n",
      "              [ 5.4608279e-07],\n",
      "              [-5.1464275e-07],\n",
      "              [ 4.6492258e-07],\n",
      "              [-3.1397860e-07],\n",
      "              [ 3.4185658e-07],\n",
      "              [-2.3487246e-07]],\n",
      "\n",
      "             [[ 4.9195516e-01],\n",
      "              [ 4.0340908e-03],\n",
      "              [-2.7558962e-01],\n",
      "              [ 2.0259432e-04],\n",
      "              [-4.4300843e-02],\n",
      "              [-1.1596028e-01],\n",
      "              [-2.5029469e-02],\n",
      "              [ 1.3332540e-02],\n",
      "              [ 6.2478171e-03],\n",
      "              [ 9.1150863e-04],\n",
      "              [ 4.5632441e-05],\n",
      "              [ 9.8735150e-08],\n",
      "              [ 2.6204290e-07],\n",
      "              [-9.5278146e-08],\n",
      "              [ 2.2176536e-09],\n",
      "              [-5.0296403e-08],\n",
      "              [-1.3441286e-07],\n",
      "              [ 1.1808309e-08],\n",
      "              [ 2.1170440e-07],\n",
      "              [-1.3802493e-07],\n",
      "              [ 2.1616206e-07],\n",
      "              [-3.2757524e-07],\n",
      "              [ 1.0329405e-07],\n",
      "              [ 7.1421482e-08],\n",
      "              [-7.2828385e-08],\n",
      "              [-9.9326414e-10],\n",
      "              [ 8.0600273e-08],\n",
      "              [ 8.8267456e-08],\n",
      "              [-1.1436805e-07],\n",
      "              [ 1.2999298e-07],\n",
      "              [-8.3364831e-08],\n",
      "              [ 2.5523505e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.99540186],\n",
      "             [0.57040155]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.19860518e-01],\n",
      "              [ 1.60041094e-01],\n",
      "              [ 2.00323433e-01],\n",
      "              [ 2.06687003e-01],\n",
      "              [-5.94912171e-02],\n",
      "              [ 3.99919599e-03],\n",
      "              [ 6.54198900e-02],\n",
      "              [-7.56132826e-02],\n",
      "              [-1.09195106e-01],\n",
      "              [-4.86508720e-02],\n",
      "              [-1.03868200e-02],\n",
      "              [-1.09231635e-03],\n",
      "              [-4.55987283e-05],\n",
      "              [ 1.53383525e-07],\n",
      "              [-4.07641011e-07],\n",
      "              [ 6.64751440e-07],\n",
      "              [-6.38207780e-07],\n",
      "              [ 5.37248695e-07],\n",
      "              [-3.28999533e-07],\n",
      "              [ 1.24956728e-07],\n",
      "              [-3.67899418e-08],\n",
      "              [-9.94603226e-08],\n",
      "              [ 2.25263705e-07],\n",
      "              [-2.56733756e-07],\n",
      "              [-1.63364902e-07],\n",
      "              [ 1.73239556e-07],\n",
      "              [ 1.64490302e-07],\n",
      "              [-4.66476820e-07],\n",
      "              [ 5.36620973e-07],\n",
      "              [-5.53360110e-07],\n",
      "              [ 3.06995190e-07],\n",
      "              [-4.08484027e-07]],\n",
      "\n",
      "             [[ 5.04023671e-01],\n",
      "              [ 2.07990706e-02],\n",
      "              [-1.50176406e-01],\n",
      "              [ 1.74365968e-01],\n",
      "              [ 8.62271637e-02],\n",
      "              [ 4.72491533e-02],\n",
      "              [ 1.25129476e-01],\n",
      "              [ 6.71872795e-02],\n",
      "              [ 5.08046849e-03],\n",
      "              [-4.94501926e-03],\n",
      "              [-1.55107758e-03],\n",
      "              [-1.79019291e-04],\n",
      "              [-7.55026485e-06],\n",
      "              [-5.72205238e-07],\n",
      "              [ 4.88544970e-07],\n",
      "              [-1.66310684e-07],\n",
      "              [ 1.83835631e-08],\n",
      "              [ 2.36810280e-07],\n",
      "              [-8.20427317e-08],\n",
      "              [-2.81248219e-07],\n",
      "              [ 2.88846564e-07],\n",
      "              [-4.99207999e-07],\n",
      "              [ 5.33909599e-07],\n",
      "              [-1.08111500e-07],\n",
      "              [-1.10305578e-07],\n",
      "              [ 1.16756169e-08],\n",
      "              [ 9.14529750e-08],\n",
      "              [-3.19605363e-07],\n",
      "              [ 2.20975565e-07],\n",
      "              [-1.36706618e-07],\n",
      "              [-3.15749205e-08],\n",
      "              [-2.21013092e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.58847713],\n",
      "             [0.22614598]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.5567641e-01],\n",
      "              [ 1.7431086e-01],\n",
      "              [ 1.1940147e-01],\n",
      "              [-1.6786829e-03],\n",
      "              [-2.3897333e-01],\n",
      "              [-7.1304776e-02],\n",
      "              [-1.5348248e-02],\n",
      "              [-9.0500861e-02],\n",
      "              [ 2.0436250e-02],\n",
      "              [ 1.0311258e-01],\n",
      "              [ 6.7489967e-02],\n",
      "              [ 2.0816306e-02],\n",
      "              [ 3.4640050e-03],\n",
      "              [ 3.0123483e-04],\n",
      "              [ 1.0558117e-05],\n",
      "              [ 2.8346039e-07],\n",
      "              [-5.3862891e-07],\n",
      "              [ 5.2013053e-07],\n",
      "              [-5.2991766e-07],\n",
      "              [ 4.4222992e-07],\n",
      "              [-2.2648601e-07],\n",
      "              [ 1.5508544e-07],\n",
      "              [-4.9890048e-10],\n",
      "              [-1.4342965e-07],\n",
      "              [ 2.9515309e-07],\n",
      "              [ 5.1366655e-08],\n",
      "              [-3.1994284e-07],\n",
      "              [ 9.3612478e-08],\n",
      "              [ 2.4060182e-07],\n",
      "              [-3.9887647e-07],\n",
      "              [ 5.0142268e-07],\n",
      "              [-2.5650903e-07]],\n",
      "\n",
      "             [[ 4.6697247e-01],\n",
      "              [-4.0551972e-02],\n",
      "              [-1.6089991e-01],\n",
      "              [ 1.2789848e-01],\n",
      "              [-5.2095540e-02],\n",
      "              [-9.5692158e-02],\n",
      "              [-4.9347162e-02],\n",
      "              [-1.2314310e-01],\n",
      "              [-1.0410104e-01],\n",
      "              [-3.3261068e-02],\n",
      "              [-2.3970190e-03],\n",
      "              [ 1.0986915e-03],\n",
      "              [ 3.0017775e-04],\n",
      "              [ 2.9404880e-05],\n",
      "              [ 1.6152286e-06],\n",
      "              [-4.2116056e-07],\n",
      "              [ 1.4757161e-07],\n",
      "              [-7.1706509e-08],\n",
      "              [-2.7708651e-07],\n",
      "              [ 1.6878815e-07],\n",
      "              [ 2.9261892e-07],\n",
      "              [-2.4360099e-07],\n",
      "              [ 2.5210687e-07],\n",
      "              [-4.8971515e-07],\n",
      "              [ 2.9063236e-07],\n",
      "              [-5.7662501e-08],\n",
      "              [ 9.8517773e-08],\n",
      "              [-8.4184695e-09],\n",
      "              [ 1.4123887e-07],\n",
      "              [-1.6232710e-07],\n",
      "              [ 2.1170626e-07],\n",
      "              [-1.4290808e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.0353756],\n",
      "             [0.6732223]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.17993969e-01],\n",
      "              [ 7.75592551e-02],\n",
      "              [-4.06018645e-02],\n",
      "              [-1.61785871e-01],\n",
      "              [-2.37017408e-01],\n",
      "              [ 6.48391619e-02],\n",
      "              [ 9.84814763e-02],\n",
      "              [ 2.90234406e-02],\n",
      "              [ 1.05483234e-01],\n",
      "              [ 3.81647274e-02],\n",
      "              [-7.74736330e-02],\n",
      "              [-7.99860135e-02],\n",
      "              [-3.42251360e-02],\n",
      "              [-8.08216725e-03],\n",
      "              [-1.10224192e-03],\n",
      "              [-8.14831437e-05],\n",
      "              [-2.77519916e-06],\n",
      "              [ 4.18429437e-07],\n",
      "              [-4.07201782e-07],\n",
      "              [ 5.04638649e-07],\n",
      "              [-4.58530963e-07],\n",
      "              [ 2.48073491e-07],\n",
      "              [-1.94445533e-07],\n",
      "              [ 6.69620235e-08],\n",
      "              [ 1.00927913e-07],\n",
      "              [-3.05174723e-07],\n",
      "              [ 8.68256080e-08],\n",
      "              [ 3.19166219e-07],\n",
      "              [-2.13246153e-07],\n",
      "              [-7.51493801e-08],\n",
      "              [ 2.35908033e-07],\n",
      "              [-4.32100478e-07]],\n",
      "\n",
      "             [[ 4.91236925e-01],\n",
      "              [ 5.81765920e-03],\n",
      "              [-5.73190600e-02],\n",
      "              [ 2.00606287e-01],\n",
      "              [-1.76874623e-02],\n",
      "              [-1.80389732e-03],\n",
      "              [ 7.47348517e-02],\n",
      "              [ 4.09910195e-02],\n",
      "              [ 1.07169665e-01],\n",
      "              [ 1.28774300e-01],\n",
      "              [ 6.70330301e-02],\n",
      "              [ 1.75191108e-02],\n",
      "              [ 2.11375882e-03],\n",
      "              [ 3.42026487e-06],\n",
      "              [-2.81500779e-05],\n",
      "              [-3.13248870e-06],\n",
      "              [ 5.21531973e-08],\n",
      "              [ 1.97676655e-07],\n",
      "              [ 1.18508652e-07],\n",
      "              [ 1.13078791e-07],\n",
      "              [-3.14727004e-07],\n",
      "              [-5.46188517e-09],\n",
      "              [ 1.59614856e-07],\n",
      "              [-2.68361134e-07],\n",
      "              [ 3.95007248e-07],\n",
      "              [-3.67479828e-07],\n",
      "              [ 3.59618298e-07],\n",
      "              [-5.08952894e-07],\n",
      "              [ 1.88648954e-07],\n",
      "              [ 6.10989943e-08],\n",
      "              [ 6.65923494e-08],\n",
      "              [-4.62593903e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.7706082 ],\n",
      "             [0.87575054]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.65637422e-01],\n",
      "              [ 1.36316374e-01],\n",
      "              [ 2.28691623e-02],\n",
      "              [-3.96015719e-02],\n",
      "              [ 4.24408913e-03],\n",
      "              [ 2.75353312e-01],\n",
      "              [ 1.34140402e-01],\n",
      "              [-1.99828148e-02],\n",
      "              [-2.11504241e-03],\n",
      "              [-9.34445187e-02],\n",
      "              [-8.65450948e-02],\n",
      "              [ 3.55243050e-02],\n",
      "              [ 8.08538273e-02],\n",
      "              [ 4.80893031e-02],\n",
      "              [ 1.53195867e-02],\n",
      "              [ 2.93116877e-03],\n",
      "              [ 3.38567217e-04],\n",
      "              [ 2.19724334e-05],\n",
      "              [ 3.67012603e-07],\n",
      "              [ 1.39001813e-07],\n",
      "              [-4.41427517e-07],\n",
      "              [ 4.88867499e-07],\n",
      "              [-3.00725247e-07],\n",
      "              [ 2.24352391e-07],\n",
      "              [-4.41241674e-08],\n",
      "              [-3.14615335e-07],\n",
      "              [ 7.34234334e-07],\n",
      "              [-3.59917919e-07],\n",
      "              [-1.53758975e-07],\n",
      "              [ 1.32341114e-07],\n",
      "              [ 1.17658821e-07],\n",
      "              [-1.71076991e-07]],\n",
      "\n",
      "             [[ 5.31711757e-01],\n",
      "              [ 6.77487105e-02],\n",
      "              [ 2.30659842e-02],\n",
      "              [ 2.09162533e-01],\n",
      "              [-6.30087629e-02],\n",
      "              [-2.36117169e-02],\n",
      "              [ 2.13398691e-02],\n",
      "              [-4.77574170e-02],\n",
      "              [-2.53958311e-02],\n",
      "              [-7.80017972e-02],\n",
      "              [-1.35314807e-01],\n",
      "              [-9.97352973e-02],\n",
      "              [-4.02250327e-02],\n",
      "              [-9.89696197e-03],\n",
      "              [-1.56002818e-03],\n",
      "              [-1.62411699e-04],\n",
      "              [-1.13991728e-05],\n",
      "              [-7.18095350e-07],\n",
      "              [-2.22735309e-07],\n",
      "              [-4.84814962e-08],\n",
      "              [-9.21719163e-08],\n",
      "              [ 3.07748167e-07],\n",
      "              [-1.07324624e-07],\n",
      "              [-5.04831519e-08],\n",
      "              [ 1.01568503e-07],\n",
      "              [-1.97407388e-07],\n",
      "              [ 2.23975917e-07],\n",
      "              [-2.44170423e-07],\n",
      "              [ 5.06833601e-07],\n",
      "              [-2.34901364e-07],\n",
      "              [-6.73835530e-08],\n",
      "              [ 7.01660525e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.08752763],\n",
      "             [0.4019662 ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.39150667e-01],\n",
      "              [ 6.98259324e-02],\n",
      "              [-6.93100914e-02],\n",
      "              [-1.12711556e-01],\n",
      "              [-4.30479534e-02],\n",
      "              [ 1.14648916e-01],\n",
      "              [-1.43338427e-01],\n",
      "              [-2.19347000e-01],\n",
      "              [-8.56741369e-02],\n",
      "              [-6.52908310e-02],\n",
      "              [ 4.24190536e-02],\n",
      "              [ 1.07665859e-01],\n",
      "              [ 1.29719395e-02],\n",
      "              [-6.74246475e-02],\n",
      "              [-5.87774180e-02],\n",
      "              [-2.47620046e-02],\n",
      "              [-6.28557755e-03],\n",
      "              [-1.01076066e-03],\n",
      "              [-1.01237958e-04],\n",
      "              [-5.63967069e-06],\n",
      "              [-1.25597694e-07],\n",
      "              [ 3.32364237e-07],\n",
      "              [-6.13572070e-07],\n",
      "              [ 6.03344859e-07],\n",
      "              [-6.31827049e-07],\n",
      "              [ 5.24985126e-07],\n",
      "              [-1.18333503e-08],\n",
      "              [-5.97979977e-07],\n",
      "              [ 4.51686702e-07],\n",
      "              [-3.14649782e-08],\n",
      "              [ 3.62018113e-08],\n",
      "              [-1.92981133e-07]],\n",
      "\n",
      "             [[ 5.19355059e-01],\n",
      "              [ 3.59739959e-02],\n",
      "              [-2.44436488e-02],\n",
      "              [ 9.27324593e-02],\n",
      "              [-1.84498683e-01],\n",
      "              [-7.39340782e-02],\n",
      "              [-1.06109120e-02],\n",
      "              [-4.74515855e-02],\n",
      "              [ 1.50571335e-02],\n",
      "              [ 5.42512536e-03],\n",
      "              [ 3.94526310e-02],\n",
      "              [ 1.20729834e-01],\n",
      "              [ 1.23475105e-01],\n",
      "              [ 6.77901730e-02],\n",
      "              [ 2.34990474e-02],\n",
      "              [ 5.55459689e-03],\n",
      "              [ 9.31929506e-04],\n",
      "              [ 1.12237336e-04],\n",
      "              [ 9.44373005e-06],\n",
      "              [ 7.77275261e-07],\n",
      "              [ 3.23356630e-09],\n",
      "              [ 4.50423983e-08],\n",
      "              [-1.32895138e-07],\n",
      "              [-7.24179898e-08],\n",
      "              [ 2.99472617e-07],\n",
      "              [-3.43050345e-07],\n",
      "              [ 2.67511354e-07],\n",
      "              [-2.34062668e-07],\n",
      "              [ 1.23573301e-07],\n",
      "              [-3.90332190e-07],\n",
      "              [ 2.09890587e-07],\n",
      "              [ 6.88657877e-08]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.27107787],\n",
      "             [0.5075493 ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.33231181e-01],\n",
      "              [ 4.87898439e-02],\n",
      "              [-8.26992840e-02],\n",
      "              [-7.76005387e-02],\n",
      "              [ 2.93120984e-02],\n",
      "              [ 1.30537599e-01],\n",
      "              [-1.06993116e-01],\n",
      "              [-1.99517161e-02],\n",
      "              [ 1.72241762e-01],\n",
      "              [ 1.40094325e-01],\n",
      "              [ 1.36641234e-01],\n",
      "              [ 4.03554477e-02],\n",
      "              [-8.92764851e-02],\n",
      "              [-5.34870923e-02],\n",
      "              [ 4.14964259e-02],\n",
      "              [ 6.26944453e-02],\n",
      "              [ 3.50425281e-02],\n",
      "              [ 1.14616444e-02],\n",
      "              [ 2.41854158e-03],\n",
      "              [ 3.34962213e-04],\n",
      "              [ 2.97558636e-05],\n",
      "              [ 1.32568755e-06],\n",
      "              [-1.53887441e-07],\n",
      "              [ 5.88689716e-07],\n",
      "              [-7.25462485e-07],\n",
      "              [ 5.77587343e-07],\n",
      "              [-4.50410823e-07],\n",
      "              [ 1.54172852e-07],\n",
      "              [ 3.90149921e-07],\n",
      "              [-4.83186056e-07],\n",
      "              [ 2.09585409e-07],\n",
      "              [-5.71503875e-08]],\n",
      "\n",
      "             [[ 5.18328249e-01],\n",
      "              [ 2.83483937e-02],\n",
      "              [-3.05620059e-02],\n",
      "              [ 6.30800352e-02],\n",
      "              [-1.63192362e-01],\n",
      "              [ 3.11717577e-02],\n",
      "              [ 8.92084166e-02],\n",
      "              [ 3.96005996e-02],\n",
      "              [ 7.39704594e-02],\n",
      "              [ 2.13237125e-02],\n",
      "              [ 1.66244451e-02],\n",
      "              [ 2.78946594e-03],\n",
      "              [-8.60123262e-02],\n",
      "              [-1.30955249e-01],\n",
      "              [-9.50254723e-02],\n",
      "              [-4.28236946e-02],\n",
      "              [-1.32480785e-02],\n",
      "              [-2.94690579e-03],\n",
      "              [-4.78695030e-04],\n",
      "              [-5.58567299e-05],\n",
      "              [-4.90659477e-06],\n",
      "              [-1.84759955e-07],\n",
      "              [-2.09418971e-09],\n",
      "              [ 7.07045160e-08],\n",
      "              [ 1.61660040e-07],\n",
      "              [-3.69112399e-07],\n",
      "              [ 4.14141823e-07],\n",
      "              [-2.84975556e-07],\n",
      "              [ 3.05965585e-07],\n",
      "              [-1.04190583e-07],\n",
      "              [ 3.49019899e-07],\n",
      "              [-2.61893319e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.41544926],\n",
      "             [0.8612207 ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.39808643e-01],\n",
      "              [ 5.17996848e-02],\n",
      "              [-6.56771436e-02],\n",
      "              [-2.56254636e-02],\n",
      "              [ 8.00861269e-02],\n",
      "              [ 1.07102908e-01],\n",
      "              [-1.20065272e-01],\n",
      "              [ 2.52240002e-02],\n",
      "              [ 1.12078026e-01],\n",
      "              [-5.79359904e-02],\n",
      "              [-1.14218302e-01],\n",
      "              [-1.68089017e-01],\n",
      "              [-1.27913520e-01],\n",
      "              [ 3.18418406e-02],\n",
      "              [ 7.14738965e-02],\n",
      "              [-9.74525884e-03],\n",
      "              [-5.77540509e-02],\n",
      "              [-4.40620929e-02],\n",
      "              [-1.83301251e-02],\n",
      "              [-4.90604760e-03],\n",
      "              [-8.85128276e-04],\n",
      "              [-1.07762899e-04],\n",
      "              [-8.55526287e-06],\n",
      "              [-6.78490508e-08],\n",
      "              [-7.17716716e-07],\n",
      "              [ 8.54735845e-07],\n",
      "              [-6.12301164e-07],\n",
      "              [ 5.08039307e-07],\n",
      "              [-3.02419551e-07],\n",
      "              [-1.39699651e-07],\n",
      "              [ 3.29507571e-07],\n",
      "              [-2.64112856e-07]],\n",
      "\n",
      "             [[ 5.45759559e-01],\n",
      "              [ 6.78450912e-02],\n",
      "              [ 1.69541016e-02],\n",
      "              [ 9.43975747e-02],\n",
      "              [-9.60028023e-02],\n",
      "              [ 1.16334349e-01],\n",
      "              [ 9.47329700e-02],\n",
      "              [-1.27963033e-02],\n",
      "              [-1.29976133e-02],\n",
      "              [-7.12866336e-02],\n",
      "              [-4.70813178e-02],\n",
      "              [-3.46630998e-02],\n",
      "              [-4.10198607e-02],\n",
      "              [ 3.67584489e-02],\n",
      "              [ 1.17574729e-01],\n",
      "              [ 1.15161128e-01],\n",
      "              [ 6.58481866e-02],\n",
      "              [ 2.54898239e-02],\n",
      "              [ 7.09981704e-03],\n",
      "              [ 1.45817408e-03],\n",
      "              [ 2.20423783e-04],\n",
      "              [ 2.42569968e-05],\n",
      "              [ 1.91152549e-06],\n",
      "              [-4.37359873e-08],\n",
      "              [ 2.15123364e-07],\n",
      "              [-5.19625189e-07],\n",
      "              [ 5.88475757e-07],\n",
      "              [-4.94346750e-07],\n",
      "              [ 4.62719782e-07],\n",
      "              [-6.17091189e-07],\n",
      "              [ 2.68805422e-07],\n",
      "              [-2.22670394e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.97598505],\n",
      "             [0.67529714]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.86932582e-01],\n",
      "              [ 1.20190673e-01],\n",
      "              [ 1.94139108e-02],\n",
      "              [ 7.21142069e-02],\n",
      "              [ 1.42101914e-01],\n",
      "              [ 9.19401571e-02],\n",
      "              [-1.14900589e-01],\n",
      "              [ 6.21360093e-02],\n",
      "              [ 6.50292784e-02],\n",
      "              [-1.03280731e-01],\n",
      "              [-3.85762192e-02],\n",
      "              [ 3.43162641e-02],\n",
      "              [ 1.37380511e-01],\n",
      "              [ 1.85807317e-01],\n",
      "              [ 4.88430224e-02],\n",
      "              [-5.82704507e-02],\n",
      "              [-1.78808570e-02],\n",
      "              [ 4.45786901e-02],\n",
      "              [ 4.96054403e-02],\n",
      "              [ 2.62180157e-02],\n",
      "              [ 8.72579683e-03],\n",
      "              [ 1.97673822e-03],\n",
      "              [ 3.11648007e-04],\n",
      "              [ 3.39102444e-05],\n",
      "              [ 1.77499305e-06],\n",
      "              [ 1.04788012e-06],\n",
      "              [-7.55900714e-07],\n",
      "              [ 3.19250546e-07],\n",
      "              [-4.60586477e-07],\n",
      "              [ 1.64901735e-07],\n",
      "              [ 2.08884828e-07],\n",
      "              [-2.02401679e-07]],\n",
      "\n",
      "             [[ 5.55354953e-01],\n",
      "              [ 7.35856295e-02],\n",
      "              [ 1.37944147e-02],\n",
      "              [ 6.35593757e-02],\n",
      "              [-1.11694396e-01],\n",
      "              [ 8.73161554e-02],\n",
      "              [-3.85547429e-03],\n",
      "              [-1.04984246e-01],\n",
      "              [-5.41410819e-02],\n",
      "              [-4.73239198e-02],\n",
      "              [ 2.89472956e-02],\n",
      "              [ 4.66640107e-02],\n",
      "              [ 3.93239930e-02],\n",
      "              [ 6.58285841e-02],\n",
      "              [ 1.69387907e-02],\n",
      "              [-8.33495930e-02],\n",
      "              [-1.21508375e-01],\n",
      "              [-8.85373428e-02],\n",
      "              [-4.21450995e-02],\n",
      "              [-1.43070621e-02],\n",
      "              [-3.59283644e-03],\n",
      "              [-6.74237206e-04],\n",
      "              [-9.41463877e-05],\n",
      "              [-9.58832698e-06],\n",
      "              [-4.29782006e-07],\n",
      "              [-3.35247734e-07],\n",
      "              [ 5.53586347e-07],\n",
      "              [-6.24420295e-07],\n",
      "              [ 4.55776558e-07],\n",
      "              [-4.59722912e-07],\n",
      "              [ 5.95348979e-07],\n",
      "              [-2.61070852e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.0340848 ],\n",
      "             [0.46322787]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.62598598e-01],\n",
      "              [ 6.48272783e-02],\n",
      "              [-5.66064753e-02],\n",
      "              [-2.18688622e-02],\n",
      "              [ 3.44122364e-03],\n",
      "              [-8.56820643e-02],\n",
      "              [-2.24389046e-01],\n",
      "              [ 3.78886727e-03],\n",
      "              [-2.68908162e-02],\n",
      "              [-1.29014403e-01],\n",
      "              [ 2.01183204e-02],\n",
      "              [ 6.15537316e-02],\n",
      "              [ 4.28383090e-02],\n",
      "              [-5.70761375e-02],\n",
      "              [-1.89477712e-01],\n",
      "              [-1.26428336e-01],\n",
      "              [ 1.53944455e-02],\n",
      "              [ 3.14408615e-02],\n",
      "              [-2.68194303e-02],\n",
      "              [-5.01730777e-02],\n",
      "              [-3.39868963e-02],\n",
      "              [-1.39105069e-02],\n",
      "              [-3.86565155e-03],\n",
      "              [-7.59374874e-04],\n",
      "              [-1.06470805e-04],\n",
      "              [-9.63351522e-06],\n",
      "              [-1.62337847e-06],\n",
      "              [ 6.32295325e-07],\n",
      "              [-1.34169071e-07],\n",
      "              [ 4.68970825e-07],\n",
      "              [-2.57608519e-07],\n",
      "              [-2.45484330e-07]],\n",
      "\n",
      "             [[ 5.49001396e-01],\n",
      "              [ 5.35029434e-02],\n",
      "              [-1.75854154e-02],\n",
      "              [ 1.54619776e-02],\n",
      "              [-1.32267356e-01],\n",
      "              [ 6.94985390e-02],\n",
      "              [-4.21626605e-02],\n",
      "              [-8.20906684e-02],\n",
      "              [ 2.83201933e-02],\n",
      "              [ 4.75656316e-02],\n",
      "              [ 8.41812864e-02],\n",
      "              [ 2.95305327e-02],\n",
      "              [-1.91251021e-02],\n",
      "              [-2.45492551e-02],\n",
      "              [-6.88041374e-02],\n",
      "              [-6.20833449e-02],\n",
      "              [ 3.39673981e-02],\n",
      "              [ 1.09573998e-01],\n",
      "              [ 1.05455279e-01],\n",
      "              [ 6.16375841e-02],\n",
      "              [ 2.51651425e-02],\n",
      "              [ 7.57479714e-03],\n",
      "              [ 1.71716698e-03],\n",
      "              [ 2.94170866e-04],\n",
      "              [ 3.78282821e-05],\n",
      "              [ 3.14066028e-06],\n",
      "              [ 6.26070289e-07],\n",
      "              [-4.93423101e-07],\n",
      "              [ 4.49634854e-07],\n",
      "              [-3.65029848e-07],\n",
      "              [ 4.62845776e-07],\n",
      "              [-5.77248954e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.6823162 ],\n",
      "             [0.76350224]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k_i:\n",
      "Traced<ShapedArray(float32[32,1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[[ 3.83225322e-01],\n",
      "              [ 9.02176350e-02],\n",
      "              [-2.25807205e-02],\n",
      "              [ 2.43114941e-02],\n",
      "              [ 4.71040495e-02],\n",
      "              [-2.31048428e-02],\n",
      "              [-6.83445930e-02],\n",
      "              [ 1.84173062e-01],\n",
      "              [ 9.73232985e-02],\n",
      "              [ 1.90885551e-02],\n",
      "              [ 1.48620471e-01],\n",
      "              [ 8.03933144e-02],\n",
      "              [-7.21798232e-03],\n",
      "              [-6.63189888e-02],\n",
      "              [-3.26013938e-02],\n",
      "              [ 1.37183100e-01],\n",
      "              [ 1.74321979e-01],\n",
      "              [ 4.50289957e-02],\n",
      "              [-2.47450396e-02],\n",
      "              [ 1.03015313e-02],\n",
      "              [ 4.57064956e-02],\n",
      "              [ 4.03288417e-02],\n",
      "              [ 2.01884527e-02],\n",
      "              [ 6.77637570e-03],\n",
      "              [ 1.61817204e-03],\n",
      "              [ 2.80865206e-04],\n",
      "              [ 3.47836612e-05],\n",
      "              [ 3.60408148e-06],\n",
      "              [-4.61338416e-08],\n",
      "              [-2.08732843e-07],\n",
      "              [-9.48112131e-08],\n",
      "              [ 1.87891928e-07]],\n",
      "\n",
      "             [[ 5.62840223e-01],\n",
      "              [ 6.92864135e-02],\n",
      "              [-6.67698681e-04],\n",
      "              [ 3.07565890e-02],\n",
      "              [-8.41037929e-02],\n",
      "              [ 1.17283404e-01],\n",
      "              [-1.15292631e-02],\n",
      "              [-1.24416463e-02],\n",
      "              [ 9.03487355e-02],\n",
      "              [ 4.78735082e-02],\n",
      "              [ 1.72226094e-02],\n",
      "              [-6.26646951e-02],\n",
      "              [-6.57846257e-02],\n",
      "              [-1.79227237e-02],\n",
      "              [-5.64040057e-03],\n",
      "              [ 4.71209325e-02],\n",
      "              [ 8.62403437e-02],\n",
      "              [ 1.97739359e-02],\n",
      "              [-7.89951459e-02],\n",
      "              [-1.11074179e-01],\n",
      "              [-8.08428079e-02],\n",
      "              [-3.95363271e-02],\n",
      "              [-1.40978238e-02],\n",
      "              [-3.79172829e-03],\n",
      "              [-7.78728572e-04],\n",
      "              [-1.22084122e-04],\n",
      "              [-1.40020720e-05],\n",
      "              [-1.54143106e-06],\n",
      "              [ 2.93385057e-07],\n",
      "              [-3.78520156e-07],\n",
      "              [ 3.69984150e-07],\n",
      "              [-4.73194063e-07]]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "c_k_i shape:\n",
      "(32, 1)\n",
      "\n",
      "f_k:\n",
      "Traced<ShapedArray(float32[1])>with<BatchTrace(level=1/0)> with\n",
      "  val = DeviceArray([[0.30973995],\n",
      "             [0.470829  ]], dtype=float32)\n",
      "  batch_dim = 0\n",
      "f_k shape:\n",
      "(1,)\n",
      "\n",
      "c_k shape: (2, 16, 32, 1)\n",
      "gu_c shape: (2, 16, 32, 1)\n",
      "c_k @ b0 t0 - before vmap:\n",
      "[[ 3.2126796e-01]\n",
      " [ 2.7822685e-01]\n",
      " [ 7.1837269e-02]\n",
      " [-7.1809026e-08]\n",
      " [ 7.1809026e-08]\n",
      " [-7.3604255e-08]\n",
      " [-2.1183664e-07]\n",
      " [ 2.1542709e-07]\n",
      " [-2.1542709e-08]\n",
      " [ 8.7966065e-08]\n",
      " [ 6.4628125e-08]\n",
      " [-3.1595974e-07]\n",
      " [ 4.3085419e-07]\n",
      " [-5.4754383e-07]\n",
      " [ 4.7034914e-07]\n",
      " [-3.3391200e-07]\n",
      " [ 2.2440322e-07]\n",
      " [-3.2314063e-08]\n",
      " [ 5.8344838e-08]\n",
      " [-6.1037674e-08]\n",
      " [-1.6875121e-07]\n",
      " [ 2.9441702e-07]\n",
      " [-1.4002761e-07]\n",
      " [ 8.0785156e-09]\n",
      " [ 2.0645096e-08]\n",
      " [-1.2207535e-07]\n",
      " [ 1.1040638e-07]\n",
      " [ 7.1809030e-09]\n",
      " [ 1.6157031e-08]\n",
      " [ 5.7447224e-08]\n",
      " [-1.5438941e-07]\n",
      " [-5.7447224e-08]]\n",
      "\n",
      "gu_c @ b0 t0 - before vmap:\n",
      "[[ 3.2126817e-01]\n",
      " [ 2.7822638e-01]\n",
      " [ 7.1837738e-02]\n",
      " [-9.2988524e-09]\n",
      " [ 1.6364931e-08]\n",
      " [-1.4595950e-09]\n",
      " [-1.1984261e-08]\n",
      " [ 6.7409665e-09]\n",
      " [ 3.3056060e-09]\n",
      " [-1.5159825e-08]\n",
      " [ 1.1766488e-08]\n",
      " [ 9.9288062e-09]\n",
      " [-1.2020047e-08]\n",
      " [-5.0590518e-09]\n",
      " [ 6.0567036e-09]\n",
      " [ 8.7230791e-09]\n",
      " [-2.3180123e-08]\n",
      " [ 3.8354496e-08]\n",
      " [-3.8614331e-08]\n",
      " [ 3.1026957e-08]\n",
      " [-3.1194261e-08]\n",
      " [ 2.2146029e-08]\n",
      " [-5.1775855e-09]\n",
      " [-1.0105660e-08]\n",
      " [ 1.8570317e-08]\n",
      " [-2.0427619e-08]\n",
      " [ 1.6493720e-08]\n",
      " [-7.9763733e-09]\n",
      " [ 1.1620057e-08]\n",
      " [-2.5215348e-08]\n",
      " [ 3.1616739e-08]\n",
      " [-2.9206975e-08]]\n",
      "\n",
      "batch 0 on trajectory 0 compare : True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60022/3587711683.py:32: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  gu_c = jnp.asarray(GU_c_k, dtype=jnp.float64)  # convert torch array to jax array\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nb_gu_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test()\n",
      "Cell \u001b[0;32mIn[33], line 134\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBryan\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms Coeffiecients for HiPPO-\u001b[39m\u001b[39m{\u001b[39;00mthe_measure\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    133\u001b[0m nb_gu_hippo_legs \u001b[39m=\u001b[39m HiPPO_LegS(N, max_length\u001b[39m=\u001b[39mL)  \u001b[39m# The Gu's\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m test_hippo_legs_operator(hippo_legs\u001b[39m=\u001b[39;49mhippo_LegS_B, \n\u001b[1;32m    135\u001b[0m                          nb_hippo_legs\u001b[39m=\u001b[39;49mnb_hippo_LegS_B,\n\u001b[1;32m    136\u001b[0m                          gu_hippo_legs\u001b[39m=\u001b[39;49mgu_hippo_legs, \n\u001b[1;32m    137\u001b[0m                          nb_gu_hippo_legs\u001b[39m=\u001b[39;49mnb_gu_hippo_legs,\n\u001b[1;32m    138\u001b[0m                          random_input\u001b[39m=\u001b[39;49mx_np, \n\u001b[1;32m    139\u001b[0m                          legs_key\u001b[39m=\u001b[39;49mkey2,\n\u001b[1;32m    140\u001b[0m                          nb_legs_key\u001b[39m=\u001b[39;49mkey4)\n\u001b[1;32m    142\u001b[0m \u001b[39m# y_legs = hippo_LegS_B.apply(\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m#     {\"params\": params}, c_k, method=hippo_LegS_B.reconstruct\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[39m# print(f\"Bryan's Reconstruction for HiPPO-{the_measure}:\\n{y_legs}\")\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39m# print(f\"Bryan's Reconstruction shape for HiPPO-{the_measure}:\\n{y_legs.shape}\")\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend of test for HiPPO-\u001b[39m\u001b[39m{\u001b[39;00mthe_measure\u001b[39m}\u001b[39;00m\u001b[39m model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 58\u001b[0m, in \u001b[0;36mtest_hippo_legs_operator\u001b[0;34m(hippo_legs, nb_hippo_legs, gu_hippo_legs, nb_gu_hippo_legs, random_input, legs_key, nb_legs_key)\u001b[0m\n\u001b[1;32m     55\u001b[0m jax\u001b[39m.\u001b[39mdebug\u001b[39m.\u001b[39mprint(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m on trajectory \u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m compare : \u001b[39m\u001b[39m{\u001b[39;00mjnp\u001b[39m.\u001b[39mallclose(c_k[i,j,:,:], gu_c[i,j,:,:], rtol\u001b[39m=\u001b[39m\u001b[39m1e-03\u001b[39m, atol\u001b[39m=\u001b[39m\u001b[39m1e-03\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[39m# jax.debug.print(f\"no batch on trajectory {j} compare : {jnp.allclose(nb_c_k[j,:,:], gu_c[i,j,:,:], rtol=1e-03, atol=1e-03)}\")\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# jax.debug.print(f\"no batch on trajectory {j} compare : {jnp.allclose(nb_c_k[j,:,:], nb_gu_c[j,:,:], rtol=1e-03, atol=1e-03)}\")\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m jax\u001b[39m.\u001b[39mdebug\u001b[39m.\u001b[39mprint(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno batch on trajectory \u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m compare : \u001b[39m\u001b[39m{\u001b[39;00mjnp\u001b[39m.\u001b[39mallclose(c_k[i,j,:,:], nb_gu_c[j,:,:], rtol\u001b[39m=\u001b[39m\u001b[39m1e-03\u001b[39m, atol\u001b[39m=\u001b[39m\u001b[39m1e-03\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nb_gu_c' is not defined"
     ]
    }
   ],
   "source": [
    "test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('s4mer-pkg-jZnBSgjq-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a81e05d1d7f7eae781698b7c1b81c0d771335201ebad1d81045cb177cef974b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
