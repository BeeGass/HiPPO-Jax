{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagonal Plus Low Rank (DPLR) HiPPO Matrices\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Loading In Necessary Packages](#load-packages)\n",
    "    * [Instantiate The HiPPO Matrix](#instantiate-the-hippo-matrix)\n",
    "        * [Translated Legendre (LegT)](#translated-legendre-legt)\n",
    "            * [LegT](#legt)\n",
    "            * [LMU](#lmu)\n",
    "        * [Translated Laguerre (LagT)](#translated-laguerre-lagt)\n",
    "        * [Scaled Legendre (LegS)](#scaled-legendre-legs)\n",
    "        * [Fourier Basis](#fourier-basis)\n",
    "            * [Fourier Recurrent Unit (FRU)](#fourier-recurrent-unit-fru)\n",
    "            * [Truncated Fourier (FouT)](#truncated-fourier-fout)\n",
    "            * [Fourier With Decay (FourD)](#fourier-with-decay-fourd)\n",
    "    * [Make HiPPO Matrices DPLR](#make-hippo-matrices-dplr)\n",
    "        * [DPLR-LegT](#dplr-legt)\n",
    "            * [DPLR-LegT](#dplr-legt)\n",
    "            * [DPLR-LMU](#dplr-lmu)\n",
    "        * [DPLR-LagT](#dplr-lagt)\n",
    "        * [DPLR-LegS](#dplr-legs)\n",
    "        * [DPLR Applied To Fourier Basis](#dplr-applied-to-fourier-basis)\n",
    "            * [DPLR-FRU](#nplr-fru)\n",
    "            * [DPLR-FouT](#nplr-fout)\n",
    "            * [DPLR-FouD](#nplr-foud)\n",
    "    * [Utilities For Gu HiPPO Operator](#utilities-for-gu-hippo-operator)\n",
    "    * [Gu's HiPPO LegT Operator](#gus-hippo-legt-operator)\n",
    "    * [Gu's Scale invariant HiPPO LegS Operator](#gus-scale-invariant-hippo-legs-operator)\n",
    "    * [Implementation Of General HiPPO Operator](#implementation-of-general-hippo-operator)\n",
    "    * [Output](#output)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../../\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StreamExecutorGpuDevice(id=0, process_index=0)]\n",
      "The Device: gpu\n"
     ]
    }
   ],
   "source": [
    "## import packages\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from opt_einsum import contract\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from src.models.hippo.transition import TransMatrix\n",
    "from src.models.hippo.gu_transition import GuLowRankMatrix\n",
    "\n",
    "print(jax.devices())\n",
    "print(f\"The Device: {jax.lib.xla_bridge.get_backend().platform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS enabled: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"MPS enabled: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=150)\n",
    "np.set_printoptions(linewidth=150)\n",
    "jnp.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1701\n",
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_copies = 5\n",
    "rng, key2, key3, key4, key5 = jax.random.split(key, num=num_copies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make HiPPO Matrices DPLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LowRankMatrix:\n",
    "    def __init__(\n",
    "        self,\n",
    "        N,\n",
    "        rank,\n",
    "        measure=\"legs\",\n",
    "        lambda_n=1,\n",
    "        fourier_type=\"fru\",\n",
    "        alpha=0,\n",
    "        beta=1,\n",
    "        DPLR=True,\n",
    "        dtype=jnp.float32,\n",
    "    ):\n",
    "        self.N = N\n",
    "        self.measure = measure\n",
    "        self.rank = rank\n",
    "        _trans_matrix = TransMatrix(N, measure, lambda_n, fourier_type, alpha, beta)\n",
    "\n",
    "        Lambda = None\n",
    "        B = None\n",
    "        V = None\n",
    "        A, B, P, S = self.make_NPLR(trans_matrix=_trans_matrix, dtype=dtype)\n",
    "        if DPLR:\n",
    "            Lambda, P, B, V = self.make_DPLR(B=B, P=P, S=S)\n",
    "            self.Lambda = (Lambda.copy()).astype(dtype)  # real eigenvalues\n",
    "            self.V = (V.copy()).astype(dtype)  # imaginary (complex) eigenvalues\n",
    "\n",
    "        self.A = (A.copy()).astype(dtype)  # HiPPO A Matrix (N x N)\n",
    "        self.B = (B.copy()).astype(dtype)  # HiPPO B Matrix (N x 1)\n",
    "        self.P = (P.copy()).astype(dtype)  # HiPPO rank correction matrix (N x rank)\n",
    "        self.S = (S.copy()).astype(\n",
    "            dtype\n",
    "        )  # HiPPO normal (skew-symmetric) matrix (N x N)\n",
    "\n",
    "    def check_skew(self, S):\n",
    "        \"\"\"Check if a matrix is skew symmetric\n",
    "\n",
    "        We require AP to be nearly skew-symmetric. To be clear, AP IS NOT skew-symmetric.\n",
    "        However, it is skew-symmetric up to a small error. This function checks that error is within an acceptable tolerance.\n",
    "\n",
    "        refer to:\n",
    "        - https://www.cuemath.com/algebra/skew-symmetric-matrix/\n",
    "        - https://en.wikipedia.org/wiki/Skew-symmetric_matrix\n",
    "\n",
    "        \"\"\"\n",
    "        _S = S + S.transpose(\n",
    "            -1, -2\n",
    "        )  # ensure matrices are skew symmetric by assuming S is skew symmetric, adding two skew symmetric matrices results in a skew symmetric matrix\n",
    "        if (\n",
    "            err := jnp.sum((_S - _S[0, 0] * jnp.eye(self.N)) ** 2) / self.N\n",
    "        ) > 1e-5:  # if not torch.allclose(_A - _A[0,0]*torch.eye(N), torch.zeros(N, N), atol=1e-5):\n",
    "            print(\"WARNING: HiPPO matrix not skew symmetric\", err)\n",
    "            # print(\n",
    "            #     f\"Transposed matrix:\\n{_S.transpose(-1, -2)}\\n\\nUnchanged matrix:\\n{-_S}\"\n",
    "            # )  # the transpose of a skew symmetric matrix is equal to the negative of the matrix\n",
    "\n",
    "        return _S\n",
    "\n",
    "    def fix_zeroed_eigvals(self, Lambda, V, S):\n",
    "        # Only keep half of each conjugate pair\n",
    "        imaginary_eigvals = Lambda.imag\n",
    "        idx = jnp.argsort(imaginary_eigvals)\n",
    "        Lambda_sorted = Lambda[idx]\n",
    "        V_sorted = V[:, idx]\n",
    "\n",
    "        # There is an edge case when eigenvalues can be 0, which requires some machinery to handle\n",
    "        # We use a huge hack here: Assume only one pair is 0, and that it is the first row/column of A (only happens in Fourier case)\n",
    "        V = V_sorted[:, : self.N // 2]\n",
    "        Lambda = Lambda_sorted[: self.N // 2]\n",
    "        assert (\n",
    "            jnp.abs(Lambda[-2]) > 1e-4\n",
    "        ), \"Only 1 zero eigenvalue allowed in diagonal part of A\"\n",
    "        if jnp.abs(Lambda[-1]) < 1e-4:\n",
    "            # x = x.at[idx].set(y)\n",
    "            V = V.at[:, -1].set(0.0)  # V[:, -1] = 0.0\n",
    "            V = V.at[0, -1].set(2**-0.5)  # V[0, -1] = 2**-0.5\n",
    "            V = V.at[1, -1].set(2**-0.5 * 1j)  # V[1, -1] = 2**-0.5 * 1j\n",
    "\n",
    "        _AP = V @ jnp.diag(Lambda) @ V.conj().transpose(-1, -2)\n",
    "\n",
    "        if (err := jnp.sum((2 * _AP.real - S) ** 2) / self.N) > 1e-5:\n",
    "            print(\n",
    "                \"Warning: Diagonalization of A matrix not numerically precise - error\",\n",
    "                err,\n",
    "            )\n",
    "\n",
    "        return Lambda, V\n",
    "\n",
    "    def make_NPLR(self, trans_matrix, dtype=jnp.float32):\n",
    "        A = trans_matrix.A_matrix\n",
    "        B = trans_matrix.B_matrix\n",
    "\n",
    "        P = self.rank_correction(dtype=dtype)  # (r N)\n",
    "\n",
    "        S = A + jnp.sum(\n",
    "            jnp.expand_dims(P, -2) * jnp.expand_dims(P, -1), axis=-3\n",
    "        )  # rank correct if rank > 1, summation happens in outer most dimension\n",
    "        # S is nearly skew-symmetric\n",
    "\n",
    "        return A, B, P, S\n",
    "\n",
    "    def make_DPLR(self, B, P, S):\n",
    "        \"\"\"Diagonalize NPLR representation\"\"\"\n",
    "\n",
    "        _S = self.check_skew(S=S)\n",
    "\n",
    "        # Check skew symmetry\n",
    "        S_diag = jnp.diagonal(S)\n",
    "        Lambda_real = jnp.mean(S_diag, -1, keepdims=True) * jnp.ones_like(\n",
    "            S_diag\n",
    "        )  # S itself is not skew-symmetric. It is skew-symmetric by: S + c * I. Extract the value c, c = mean(S_diag)\n",
    "\n",
    "        # Diagonalize S to V \\Lambda V^*\n",
    "        Lambda_imaginary, V = jnp.linalg.eigh(S * -1j)\n",
    "        Lambda = Lambda_real + 1j * Lambda_imaginary\n",
    "\n",
    "        Lambda, V = self.fix_zeroed_eigvals(Lambda=Lambda, V=V, S=_S)\n",
    "        B = B[:, 0]\n",
    "        V_inv = V.conj().transpose(-1, -2)\n",
    "        print(f\"Lambda:\\n{Lambda}\")\n",
    "        print(f\"V_inv:\\n{V_inv}\")\n",
    "        print(f\"P:\\n{P}\")\n",
    "        print(f\"B:\\n{B}\")\n",
    "        print(f\"V_inv  shape:\\n{V_inv.shape}\")\n",
    "        print(f\"P shape:\\n{P.shape}\")\n",
    "        print(f\"B shape:\\n{B.shape}\")\n",
    "\n",
    "        B = contract(\"ij, j -> i\", V_inv, B)\n",
    "        # B = contract(\"ij, j -> i\", V.conj().transpose(-1, -2), B.to(V))  # V^* B\n",
    "\n",
    "        P = contract(\"ij, ...j -> ...i\", V_inv, P)\n",
    "        # P = contract(\"ij, ...j -> ...i\", V.conj().transpose(-1, -2), P.to(V))  # V^* P\n",
    "\n",
    "        print(f\"B after einsum:\\n{B}\")\n",
    "        print(f\"P after einsum:\\n{P}\")\n",
    "\n",
    "        return Lambda, P, B, V\n",
    "\n",
    "    def rank_correction(self, dtype=jnp.float32):\n",
    "        \"\"\"Return low-rank matrix L such that A + L is normal\"\"\"\n",
    "\n",
    "        if self.measure == \"legs\":\n",
    "            assert self.rank >= 1\n",
    "            P = jnp.expand_dims(\n",
    "                jnp.sqrt(0.5 + jnp.arange(self.N, dtype=dtype)), 0\n",
    "            )  # (1 N)\n",
    "\n",
    "        elif self.measure == \"legt\":\n",
    "            assert self.rank >= 2\n",
    "            P = jnp.sqrt(1 + 2 * jnp.arange(self.N, dtype=dtype))  # (N)\n",
    "            P0 = P.clone()\n",
    "            P0 = P0.at[0::2].set(0.0)  # P0[0::2] = 0.0\n",
    "            P1 = P.clone()\n",
    "            P1 = P1.at[1::2].set(0.0)  # P1[1::2] = 0.0\n",
    "            P = jnp.stack([P0, P1], axis=0)  # (2 N)\n",
    "            P = P * (\n",
    "                2 ** (-0.5)\n",
    "            )  # Halve the rank correct just like the original matrix was halved\n",
    "\n",
    "        elif self.measure == \"lagt\":\n",
    "            assert self.rank >= 1\n",
    "            P = 0.5**0.5 * jnp.ones((1, self.N), dtype=dtype)\n",
    "\n",
    "        elif self.measure in [\"fourier\", \"fout\"]:\n",
    "            P = jnp.zeros(self.N)\n",
    "            P = P.at[0::2].set(2**0.5)  # P[0::2] = 2**0.5\n",
    "            P = P.at[0].set(1)  # P[0] = 1\n",
    "            P = jnp.expand_dims(P, 0)\n",
    "\n",
    "        elif self.measure == \"fourier_decay\":\n",
    "            P = jnp.zeros(self.N)\n",
    "            P = P.at[0::2].set(2**0.5)  # P[0::2] = 2**0.5\n",
    "            P = P.at[0].set(1)  # P[0] = 1\n",
    "            P = jnp.expand_dims(P, 0)\n",
    "            P = P / 2**0.5\n",
    "\n",
    "        elif self.measure == \"fourier2\":\n",
    "            P = jnp.zeros(self.N)\n",
    "            P = P.at[0::2].set(2**0.5)  # P[0::2] = 2**0.5\n",
    "            P = P.at[0].set(1)  # P[0] = 1\n",
    "            P = 2**0.5 * jnp.expand_dims(P, 0)\n",
    "\n",
    "        elif self.measure in [\"fourier_diag\", \"foud\", \"legsd\"]:\n",
    "            P = jnp.zeros((1, self.N), dtype=dtype)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        d = jnp.size(P, axis=0)\n",
    "        if self.rank > d:\n",
    "            P = jnp.concatenate(\n",
    "                [P, jnp.zeros((self.rank - d, self.N), dtype=dtype)], axis=0\n",
    "            )  # (rank N)\n",
    "\n",
    "        return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [NPLR](#nplr)\n",
    "- [DPLR](#dplr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# NPLR\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPLR-LegT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NPLR-LegT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NPLR_LegT():\n",
    "    the_measure = \"legt\"\n",
    "    rank = 2\n",
    "    nplr_legt = LowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, lambda_n=1.0, DPLR=False\n",
    "    )\n",
    "    gu_nplr_legt = GuLowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, lambda_n=1.0, DPLR=False\n",
    "    )\n",
    "    A, B, P, S = nplr_legt.A, nplr_legt.B, nplr_legt.P, nplr_legt.S\n",
    "    gu_A, gu_B, gu_P, gu_S = (\n",
    "        jnp.asarray(gu_nplr_legt.A, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_legt.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_legt.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_legt.S, dtype=jnp.float32),\n",
    "    )\n",
    "    print(\"NPLR LEGT\")\n",
    "    print(f\"\\nA:\\n{A}\\n\")\n",
    "    print(f\"gu_A:\\n{gu_A}\\n\")\n",
    "    assert jnp.allclose(A, gu_A, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"S:\\n{S}\\n\")\n",
    "    print(f\"gu_S:\\n{gu_S}\\n\")\n",
    "    assert jnp.allclose(S, gu_S, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beegass/Documents/Coding/s4mer/src/models/hippo/gu_transition.py:349: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "  A = torch.from_numpy(np_A)  # (N, N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPLR LEGT\n",
      "\n",
      "A:\n",
      "[[ -1.          1.7320508  -2.2360678   2.6457512  -3.          3.3166246  -3.6055512   3.8729832]\n",
      " [ -1.7320508  -3.          3.872983   -4.5825753   5.196152   -5.744562    6.244998   -6.708204 ]\n",
      " [ -2.2360678  -3.872983   -4.999999    5.916079   -6.7082033   7.4161973  -8.062257    8.660253 ]\n",
      " [ -2.6457512  -4.5825753  -5.916079   -6.9999995   7.937254   -8.774963    9.5393915 -10.24695  ]\n",
      " [ -3.         -5.196152   -6.7082033  -7.937254   -9.          9.949874  -10.816654   11.61895  ]\n",
      " [ -3.3166246  -5.744562   -7.4161973  -8.774963   -9.949874  -10.999999   11.958261  -12.845232 ]\n",
      " [ -3.6055512  -6.244998   -8.062257   -9.5393915 -10.816654  -11.958261  -13.         13.964239 ]\n",
      " [ -3.8729832  -6.708204   -8.660253  -10.24695   -11.61895   -12.845232  -13.964239  -14.999999 ]]\n",
      "\n",
      "gu_A:\n",
      "[[ -1.          1.7320508  -2.2360678   2.6457512  -3.          3.3166246  -3.6055512   3.8729832]\n",
      " [ -1.7320508  -3.          3.872983   -4.5825753   5.196152   -5.744562    6.244998   -6.708204 ]\n",
      " [ -2.2360678  -3.872983   -4.999999    5.916079   -6.7082033   7.4161973  -8.062257    8.660253 ]\n",
      " [ -2.6457512  -4.5825753  -5.916079   -6.9999995   7.937254   -8.774963    9.5393915 -10.24695  ]\n",
      " [ -3.         -5.196152   -6.7082033  -7.937254   -9.          9.949874  -10.816654   11.61895  ]\n",
      " [ -3.3166246  -5.744562   -7.4161973  -8.774963   -9.949874  -10.999999   11.958261  -12.845232 ]\n",
      " [ -3.6055512  -6.244998   -8.062257   -9.5393915 -10.816654  -11.958261  -13.         13.964239 ]\n",
      " [ -3.8729832  -6.708204   -8.660253  -10.24695   -11.61895   -12.845232  -13.964239  -14.999999 ]]\n",
      "\n",
      "B:\n",
      "[[1.       ]\n",
      " [1.7320508]\n",
      " [2.2360678]\n",
      " [2.6457512]\n",
      " [3.       ]\n",
      " [3.3166246]\n",
      " [3.6055512]\n",
      " [3.8729832]]\n",
      "\n",
      "gu_B:\n",
      "[[1.       ]\n",
      " [1.7320508]\n",
      " [2.2360678]\n",
      " [2.6457512]\n",
      " [3.       ]\n",
      " [3.3166246]\n",
      " [3.6055512]\n",
      " [3.8729832]]\n",
      "\n",
      "P:\n",
      "[[0.         1.2247448  0.         1.8708286  0.         2.3452077  0.         2.7386127 ]\n",
      " [0.70710677 0.         1.5811386  0.         2.1213202  0.         2.5495098  0.        ]]\n",
      "\n",
      "gu_P:\n",
      "[[0.         1.2247448  0.         1.8708286  0.         2.345208   0.         2.738613  ]\n",
      " [0.70710677 0.         1.5811388  0.         2.1213202  0.         2.5495098  0.        ]]\n",
      "\n",
      "S:\n",
      "[[ -0.5         1.7320508  -1.118034    2.6457512  -1.5000001   3.3166246  -1.8027756   3.8729832]\n",
      " [ -1.7320508  -1.5000002   3.872983   -2.2912877   5.196152   -2.8722813   6.244998   -3.3541021]\n",
      " [ -1.118034   -3.872983   -2.4999998   5.916079   -3.354102    7.4161973  -4.0311284   8.660253 ]\n",
      " [ -2.6457512  -2.2912877  -5.916079   -3.4999998   7.937254   -4.3874817   9.5393915  -5.123475 ]\n",
      " [ -1.5000001  -5.196152   -3.354102   -7.937254   -4.5000005   9.949874   -5.4083276  11.61895  ]\n",
      " [ -3.3166246  -2.8722813  -7.4161973  -4.3874817  -9.949874   -5.5        11.958261   -6.4226165]\n",
      " [ -1.8027756  -6.244998   -4.0311284  -9.5393915  -5.4083276 -11.958261   -6.5        13.964239 ]\n",
      " [ -3.8729832  -3.3541021  -8.660253   -5.123475  -11.61895    -6.4226165 -13.964239   -7.5      ]]\n",
      "\n",
      "gu_S:\n",
      "[[ -0.5         1.7320508  -1.1180338   2.6457512  -1.5000001   3.3166246  -1.8027756   3.8729832]\n",
      " [ -1.7320508  -1.5000002   3.872983   -2.2912877   5.196152   -2.8722808   6.244998   -3.354102 ]\n",
      " [ -1.1180338  -3.872983   -2.499999    5.916079   -3.3541014   7.4161973  -4.031128    8.660253 ]\n",
      " [ -2.6457512  -2.2912877  -5.916079   -3.4999998   7.937254   -4.387481    9.5393915  -5.1234746]\n",
      " [ -1.5000001  -5.196152   -3.3541014  -7.937254   -4.5000005   9.949874   -5.4083276  11.61895  ]\n",
      " [ -3.3166246  -2.8722808  -7.4161973  -4.387481   -9.949874   -5.499999   11.958261   -6.4226155]\n",
      " [ -1.8027756  -6.244998   -4.031128   -9.5393915  -5.4083276 -11.958261   -6.5        13.964239 ]\n",
      " [ -3.8729832  -3.354102   -8.660253   -5.1234746 -11.61895    -6.4226155 -13.964239   -7.4999986]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_NPLR_LegT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NPLR-LMU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NPLR_LMU():\n",
    "    the_measure = \"legt\"\n",
    "    rank = 2\n",
    "    nplr_lmu = LowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, lambda_n=2.0, DPLR=False\n",
    "    )\n",
    "    gu_nplr_lmu = GuLowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, lambda_n=2.0, DPLR=False\n",
    "    )  # change lambda so resulting matrix is in the form of LMU\n",
    "    print(\"NPLR LMU\")\n",
    "    A, B, P, S = nplr_lmu.A, nplr_lmu.B, nplr_lmu.P, nplr_lmu.S\n",
    "    gu_A, gu_B, gu_P, gu_S = (\n",
    "        jnp.asarray(gu_nplr_lmu.A, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_lmu.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_lmu.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_lmu.S, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nA:\\n{A}\\n\")\n",
    "    print(f\"gu_A:\\n{gu_A}\\n\")\n",
    "    assert jnp.allclose(A, gu_A, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"S:\\n{S}\\n\")\n",
    "    print(f\"gu_S:\\n{gu_S}\\n\")\n",
    "    assert jnp.allclose(S, gu_S, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPLR LMU\n",
      "\n",
      "A:\n",
      "[[ -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -3.  -3.  -3.  -3.  -3.  -3.  -3.]\n",
      " [ -5.   5.  -5.  -5.  -5.  -5.  -5.  -5.]\n",
      " [  7.  -7.   7.  -7.  -7.  -7.  -7.  -7.]\n",
      " [ -9.   9.  -9.   9.  -9.  -9.  -9.  -9.]\n",
      " [ 11. -11.  11. -11.  11. -11. -11. -11.]\n",
      " [-13.  13. -13.  13. -13.  13. -13. -13.]\n",
      " [ 15. -15.  15. -15.  15. -15.  15. -15.]]\n",
      "\n",
      "gu_A:\n",
      "[[ -1.  -1.  -1.  -1.  -1.  -1.  -1.  -1.]\n",
      " [  3.  -3.  -3.  -3.  -3.  -3.  -3.  -3.]\n",
      " [ -5.   5.  -5.  -5.  -5.  -5.  -5.  -5.]\n",
      " [  7.  -7.   7.  -7.  -7.  -7.  -7.  -7.]\n",
      " [ -9.   9.  -9.   9.  -9.  -9.  -9.  -9.]\n",
      " [ 11. -11.  11. -11.  11. -11. -11. -11.]\n",
      " [-13.  13. -13.  13. -13.  13. -13. -13.]\n",
      " [ 15. -15.  15. -15.  15. -15.  15. -15.]]\n",
      "\n",
      "B:\n",
      "[[  1.]\n",
      " [ -3.]\n",
      " [  5.]\n",
      " [ -7.]\n",
      " [  9.]\n",
      " [-11.]\n",
      " [ 13.]\n",
      " [-15.]]\n",
      "\n",
      "gu_B:\n",
      "[[  1.]\n",
      " [ -3.]\n",
      " [  5.]\n",
      " [ -7.]\n",
      " [  9.]\n",
      " [-11.]\n",
      " [ 13.]\n",
      " [-15.]]\n",
      "\n",
      "P:\n",
      "[[0.         1.2247448  0.         1.8708286  0.         2.3452077  0.         2.7386127 ]\n",
      " [0.70710677 0.         1.5811386  0.         2.1213202  0.         2.5495098  0.        ]]\n",
      "\n",
      "gu_P:\n",
      "[[0.         1.2247448  0.         1.8708286  0.         2.345208   0.         2.738613  ]\n",
      " [0.70710677 0.         1.5811388  0.         2.1213202  0.         2.5495098  0.        ]]\n",
      "\n",
      "S:\n",
      "[[ -0.5         -1.           0.11803377  -1.           0.49999988  -1.           0.8027756   -1.        ]\n",
      " [  3.          -1.5000002   -3.          -0.70871234  -3.          -0.12771916  -3.           0.35410166]\n",
      " [ -3.881966     5.          -2.5000007   -5.          -1.6458986   -5.          -0.9688716   -5.        ]\n",
      " [  7.          -4.7087126    7.          -3.5000002   -7.          -2.6125183   -7.          -1.8765249 ]\n",
      " [ -7.5          9.          -5.645899     9.          -4.5000005   -9.          -3.5916734   -9.        ]\n",
      " [ 11.          -8.127719    11.          -6.6125183   11.          -5.500001   -11.          -4.5773845 ]\n",
      " [-11.197225    13.          -8.968872    13.          -7.5916734   13.          -6.5        -13.        ]\n",
      " [ 15.         -11.645899    15.          -9.876525    15.          -8.577385    15.          -7.500001  ]]\n",
      "\n",
      "gu_S:\n",
      "[[ -0.5         -1.           0.11803401  -1.           0.49999988  -1.           0.8027756   -1.        ]\n",
      " [  3.          -1.5000002   -3.          -0.70871234  -3.          -0.12771869  -3.           0.3541019 ]\n",
      " [ -3.881966     5.          -2.5         -5.          -1.6458981   -5.          -0.9688711   -5.        ]\n",
      " [  7.          -4.7087126    7.          -3.5000002   -7.          -2.6125178   -7.          -1.8765244 ]\n",
      " [ -7.5          9.          -5.645898     9.          -4.5000005   -9.          -3.5916734   -9.        ]\n",
      " [ 11.          -8.127719    11.          -6.612518    11.          -5.5        -11.          -4.5773835 ]\n",
      " [-11.197225    13.          -8.968871    13.          -7.5916734   13.          -6.5        -13.        ]\n",
      " [ 15.         -11.645898    15.          -9.876524    15.          -8.577383    15.          -7.4999995 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_NPLR_LMU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPLR-LagT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NPLR_LagT():\n",
    "    the_measure = \"lagt\"\n",
    "    rank = 1\n",
    "    nplr_lagt = LowRankMatrix(\n",
    "        N=8,\n",
    "        rank=rank,\n",
    "        measure=the_measure,\n",
    "        alpha=0.0,  # change resulting tilt through alpha and beta\n",
    "        beta=1.0,\n",
    "        DPLR=False,\n",
    "    )  # change resulting tilt through alpha and beta\n",
    "    gu_nplr_lagt = GuLowRankMatrix(\n",
    "        N=8,\n",
    "        rank=rank,\n",
    "        measure=the_measure,\n",
    "        alpha=0.0,\n",
    "        beta=1.0,\n",
    "        DPLR=False,\n",
    "    )\n",
    "    print(\"NPLR LAGT\")\n",
    "    A, B, P, S = nplr_lagt.A, nplr_lagt.B, nplr_lagt.P, nplr_lagt.S\n",
    "    gu_A, gu_B, gu_P, gu_S = (\n",
    "        jnp.asarray(gu_nplr_lagt.A, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_lagt.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_lagt.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_lagt.S, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nA:\\n{A}\\n\")\n",
    "    print(f\"gu_A:\\n{gu_A}\\n\")\n",
    "    assert jnp.allclose(A, gu_A, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"S:\\n{S}\\n\")\n",
    "    print(f\"gu_S:\\n{gu_S}\\n\")\n",
    "    assert jnp.allclose(S, gu_S, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPLR LAGT\n",
      "\n",
      "A:\n",
      "[[-1.         -0.         -0.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -0.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.         -0.        ]\n",
      " [-0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -1.        ]]\n",
      "\n",
      "gu_A:\n",
      "[[-1.         -0.         -0.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -0.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -0.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -0.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -0.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -0.         -0.        ]\n",
      " [-1.         -1.         -1.         -1.         -1.         -1.         -1.         -0.        ]\n",
      " [-0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -0.99999976 -1.        ]]\n",
      "\n",
      "B:\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999976]]\n",
      "\n",
      "gu_B:\n",
      "[[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.99999976]]\n",
      "\n",
      "P:\n",
      "[[0.70710677 0.70710677 0.70710677 0.70710677 0.70710677 0.70710677 0.70710677 0.70710677]]\n",
      "\n",
      "gu_P:\n",
      "[[0.70710677 0.70710677 0.70710677 0.70710677 0.70710677 0.70710677 0.70710677 0.70710677]]\n",
      "\n",
      "S:\n",
      "[[-0.5         0.49999997  0.49999997  0.49999997  0.49999997  0.49999997  0.49999997  0.49999997]\n",
      " [-0.5        -0.5         0.49999997  0.49999997  0.49999997  0.49999997  0.49999997  0.49999997]\n",
      " [-0.5        -0.5        -0.5         0.49999997  0.49999997  0.49999997  0.49999997  0.49999997]\n",
      " [-0.5        -0.5        -0.5        -0.5         0.49999997  0.49999997  0.49999997  0.49999997]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5         0.49999997  0.49999997  0.49999997]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5         0.49999997  0.49999997]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5         0.49999997]\n",
      " [-0.4999998  -0.4999998  -0.4999998  -0.4999998  -0.4999998  -0.4999998  -0.4999998  -0.5       ]]\n",
      "\n",
      "gu_S:\n",
      "[[-0.5         0.49999997  0.49999997  0.49999997  0.49999997  0.49999997  0.49999997  0.49999997]\n",
      " [-0.5        -0.5         0.49999997  0.49999997  0.49999997  0.49999997  0.49999997  0.49999997]\n",
      " [-0.5        -0.5        -0.5         0.49999997  0.49999997  0.49999997  0.49999997  0.49999997]\n",
      " [-0.5        -0.5        -0.5        -0.5         0.49999997  0.49999997  0.49999997  0.49999997]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5         0.49999997  0.49999997  0.49999997]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5         0.49999997  0.49999997]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5         0.49999997]\n",
      " [-0.4999998  -0.4999998  -0.4999998  -0.4999998  -0.4999998  -0.4999998  -0.4999998  -0.5       ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_NPLR_LagT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPLR-LegS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NPLR_LegS():\n",
    "    the_measure = \"legs\"\n",
    "    rank = 1\n",
    "    nplr_legs = LowRankMatrix(N=8, rank=rank, measure=the_measure, DPLR=False)\n",
    "    gu_nplr_legs = GuLowRankMatrix(N=8, rank=rank, measure=the_measure, DPLR=False)\n",
    "    print(\"NPLR LEGS\")\n",
    "    A, B, P, S = nplr_legs.A, nplr_legs.B, nplr_legs.P, nplr_legs.S\n",
    "    gu_A, gu_B, gu_P, gu_S = (\n",
    "        jnp.asarray(gu_nplr_legs.A, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_legs.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_legs.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_legs.S, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nA:\\n{A}\\n\")\n",
    "    print(f\"gu_A:\\n{gu_A}\\n\")\n",
    "    assert jnp.allclose(A, gu_A, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"S:\\n{S}\\n\")\n",
    "    print(f\"gu_S:\\n{gu_S}\\n\")\n",
    "    assert jnp.allclose(S, gu_S, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPLR LEGS\n",
      "\n",
      "A:\n",
      "[[ -1.         -0.         -0.         -0.         -0.         -0.         -0.         -0.       ]\n",
      " [ -1.7320508  -2.         -0.         -0.         -0.         -0.         -0.         -0.       ]\n",
      " [ -2.2360678  -3.872983   -3.         -0.         -0.         -0.         -0.         -0.       ]\n",
      " [ -2.6457512  -4.5825753  -5.916079   -4.         -0.         -0.         -0.         -0.       ]\n",
      " [ -3.         -5.196152   -6.7082033  -7.937254   -5.         -0.         -0.         -0.       ]\n",
      " [ -3.3166246  -5.744562   -7.4161973  -8.774963   -9.949874   -6.         -0.         -0.       ]\n",
      " [ -3.6055512  -6.244998   -8.062257   -9.5393915 -10.816654  -11.958261   -7.         -0.       ]\n",
      " [ -3.8729832  -6.708204   -8.660253  -10.24695   -11.61895   -12.845232  -13.964239   -8.       ]]\n",
      "\n",
      "gu_A:\n",
      "[[ -1.          0.          0.          0.          0.          0.          0.          0.       ]\n",
      " [ -1.7320508  -1.9999999   0.          0.          0.          0.          0.          0.       ]\n",
      " [ -2.2360678  -3.872983   -3.          0.          0.          0.          0.          0.       ]\n",
      " [ -2.6457512  -4.582576   -5.91608    -4.          0.          0.          0.          0.       ]\n",
      " [ -3.         -5.196152   -6.7082047  -7.9372544  -5.          0.          0.          0.       ]\n",
      " [ -3.3166246  -5.744562   -7.4161987  -8.774965   -9.949874   -6.          0.          0.       ]\n",
      " [ -3.6055512  -6.244998   -8.062259   -9.539392  -10.816654  -11.958261   -7.          0.       ]\n",
      " [ -3.8729832  -6.708204   -8.6602545 -10.246951  -11.61895   -12.845232  -13.964239   -7.9999995]]\n",
      "\n",
      "B:\n",
      "[[1.       ]\n",
      " [1.7320508]\n",
      " [2.2360678]\n",
      " [2.6457512]\n",
      " [3.       ]\n",
      " [3.3166246]\n",
      " [3.6055512]\n",
      " [3.8729832]]\n",
      "\n",
      "gu_B:\n",
      "[[1.       ]\n",
      " [1.7320508]\n",
      " [2.2360678]\n",
      " [2.6457512]\n",
      " [3.       ]\n",
      " [3.3166246]\n",
      " [3.6055512]\n",
      " [3.8729832]]\n",
      "\n",
      "P:\n",
      "[[0.70710677 1.2247448  1.5811388  1.8708286  2.1213202  2.3452077  2.5495098  2.7386127 ]]\n",
      "\n",
      "gu_P:\n",
      "[[0.70710677 1.2247449  1.5811388  1.8708287  2.1213202  2.345208   2.5495098  2.738613  ]]\n",
      "\n",
      "S:\n",
      "[[-0.5         0.8660253   1.118034    1.3228756   1.4999999   1.6583122   1.8027756   1.9364915 ]\n",
      " [-0.86602545 -0.50000024  1.9364916   2.2912877   2.5980759   2.8722808   3.1224988   3.3541017 ]\n",
      " [-1.1180338  -1.9364914  -0.5         2.9580398   3.354102    3.708099    4.031129    4.330127  ]\n",
      " [-1.3228756  -2.2912877  -2.9580393  -0.50000024  3.9686267   4.3874817   4.7696958   5.123475  ]\n",
      " [-1.5000001  -2.5980763  -3.3541014  -3.9686272  -0.5000005   4.9749365   5.4083266   5.8094745 ]\n",
      " [-1.6583124  -2.8722813  -3.7080984  -4.3874817  -4.9749374  -0.50000095  5.97913     6.4226155 ]\n",
      " [-1.8027756  -3.1224992  -4.031128   -4.7696958  -5.4083276  -5.9791307  -0.5         6.9821196 ]\n",
      " [-1.9364917  -3.3541021  -4.330126   -5.123475   -5.8094754  -6.4226165  -6.9821196  -0.50000095]]\n",
      "\n",
      "gu_S:\n",
      "[[-0.5         0.86602545  1.118034    1.3228756   1.4999999   1.6583124   1.8027756   1.9364917 ]\n",
      " [-0.8660253  -0.49999976  1.9364917   2.291288    2.598076    2.8722816   3.1224992   3.3541021 ]\n",
      " [-1.1180338  -1.9364913  -0.5         2.95804     3.354102    3.7080994   4.031129    4.3301272 ]\n",
      " [-1.3228756  -2.291288   -2.95804    -0.49999976  3.968627    4.3874826   4.769696    5.1234756 ]\n",
      " [-1.5000001  -2.598076   -3.3541028  -3.9686275  -0.5000005   4.974937    5.4083266   5.809475  ]\n",
      " [-1.6583122  -2.8722806  -3.7080994  -4.3874826  -4.974937   -0.5         5.9791307   6.4226165 ]\n",
      " [-1.8027756  -3.1224988  -4.03113    -4.769696   -5.4083276  -5.97913    -0.5         6.9821205 ]\n",
      " [-1.9364915  -3.3541017  -4.3301272  -5.1234756  -5.809475   -6.4226155  -6.9821186  -0.49999905]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_NPLR_LegS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPLR Applied To Fourier Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NPLR-FRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NPLR_FRU():\n",
    "    the_measure = \"fourier\"\n",
    "    fourier_type = \"fru\"\n",
    "    rank = 1\n",
    "    nplr_fru = LowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=False\n",
    "    )\n",
    "    gu_nplr_fru = GuLowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=False\n",
    "    )\n",
    "    print(\"NPLR FRU\")\n",
    "    A, B, P, S = nplr_fru.A, nplr_fru.B, nplr_fru.P, nplr_fru.S\n",
    "    gu_A, gu_B, gu_P, gu_S = (\n",
    "        jnp.asarray(gu_nplr_fru.A, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_fru.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_fru.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_fru.S, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nA:\\n{A}\\n\")\n",
    "    print(f\"gu_A:\\n{gu_A}\\n\")\n",
    "    assert jnp.allclose(A, gu_A, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"S:\\n{S}\\n\")\n",
    "    print(f\"gu_S:\\n{gu_S}\\n\")\n",
    "    assert jnp.allclose(S, gu_S, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPLR FRU\n",
      "\n",
      "A:\n",
      "[[-1.        -0.        -1.4142135  0.        -1.4142135  0.        -1.4142135  0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.       ]\n",
      " [-1.4142135  0.        -2.        -3.1415927 -2.         0.        -2.         0.       ]\n",
      " [ 0.         0.         3.1415927  0.         0.         0.         0.         0.       ]\n",
      " [-1.4142135  0.        -2.         0.        -2.        -6.2831855 -2.         0.       ]\n",
      " [ 0.         0.         0.         0.         6.2831855  0.         0.         0.       ]\n",
      " [-1.4142135  0.        -2.         0.        -2.         0.        -2.        -9.424778 ]\n",
      " [ 0.         0.         0.         0.         0.         0.         9.424778   0.       ]]\n",
      "\n",
      "gu_A:\n",
      "[[-1.         0.        -1.4142135  0.        -1.4142135  0.        -1.4142135  0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.       ]\n",
      " [-1.4142135  0.        -1.9999999 -3.1415927 -1.9999999  0.        -1.9999999  0.       ]\n",
      " [ 0.         0.         3.1415927  0.         0.         0.         0.         0.       ]\n",
      " [-1.4142135  0.        -1.9999999  0.        -1.9999999 -6.2831855 -1.9999999  0.       ]\n",
      " [ 0.         0.         0.         0.         6.2831855  0.         0.         0.       ]\n",
      " [-1.4142135  0.        -1.9999999  0.        -1.9999999  0.        -1.9999999 -9.424778 ]\n",
      " [ 0.         0.         0.         0.         0.         0.         9.424778   0.       ]]\n",
      "\n",
      "B:\n",
      "[[1.       ]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]]\n",
      "\n",
      "gu_B:\n",
      "[[1.       ]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]\n",
      " [1.4142135]\n",
      " [0.       ]]\n",
      "\n",
      "P:\n",
      "[[1.        0.        1.4142135 0.        1.4142135 0.        1.4142135 0.       ]]\n",
      "\n",
      "gu_P:\n",
      "[[1.        0.        1.4142135 0.        1.4142135 0.        1.4142135 0.       ]]\n",
      "\n",
      "S:\n",
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00 -1.1920929e-07 -3.1415927e+00 -1.1920929e-07  0.0000000e+00 -1.1920929e-07  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  3.1415927e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00 -1.1920929e-07  0.0000000e+00 -1.1920929e-07 -6.2831855e+00 -1.1920929e-07  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  6.2831855e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00 -1.1920929e-07  0.0000000e+00 -1.1920929e-07  0.0000000e+00 -1.1920929e-07 -9.4247780e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00  9.4247780e+00  0.0000000e+00]]\n",
      "\n",
      "gu_S:\n",
      "[[ 0.         0.         0.         0.         0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.        -3.1415927  0.         0.         0.         0.       ]\n",
      " [ 0.         0.         3.1415927  0.         0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.        -6.2831855  0.         0.       ]\n",
      " [ 0.         0.         0.         0.         6.2831855  0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.        -9.424778 ]\n",
      " [ 0.         0.         0.         0.         0.         0.         9.424778   0.       ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_NPLR_FRU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NPLR-FouT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NPLR_FouT():\n",
    "    the_measure = \"fourier\"\n",
    "    fourier_type = \"fout\"\n",
    "    rank = 1\n",
    "    nplr_fout = LowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=False\n",
    "    )\n",
    "    gu_nplr_fout = GuLowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=False\n",
    "    )\n",
    "    print(\"NPLR FOUT\")\n",
    "    A, B, P, S = nplr_fout.A, nplr_fout.B, nplr_fout.P, nplr_fout.S\n",
    "    gu_A, gu_B, gu_P, gu_S = (\n",
    "        jnp.asarray(gu_nplr_fout.A, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_fout.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_fout.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_fout.S, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nA:\\n{A}\\n\")\n",
    "    print(f\"gu_A:\\n{gu_A}\\n\")\n",
    "    assert jnp.allclose(A, gu_A, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"S:\\n{S}\\n\")\n",
    "    print(f\"gu_S:\\n{gu_S}\\n\")\n",
    "    assert jnp.allclose(S, gu_S, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPLR FOUT\n",
      "\n",
      "A:\n",
      "[[ -2.         -0.         -2.828427    0.         -2.828427    0.         -2.828427    0.       ]\n",
      " [  0.          0.          0.          0.          0.          0.          0.          0.       ]\n",
      " [ -2.828427    0.         -4.         -6.2831855  -4.          0.         -4.          0.       ]\n",
      " [  0.          0.          6.2831855   0.          0.          0.          0.          0.       ]\n",
      " [ -2.828427    0.         -4.          0.         -4.        -12.566371   -4.          0.       ]\n",
      " [  0.          0.          0.          0.         12.566371    0.          0.          0.       ]\n",
      " [ -2.828427    0.         -4.          0.         -4.          0.         -4.        -18.849556 ]\n",
      " [  0.          0.          0.          0.          0.          0.         18.849556    0.       ]]\n",
      "\n",
      "gu_A:\n",
      "[[ -2.          0.         -2.828427    0.         -2.828427    0.         -2.828427    0.       ]\n",
      " [  0.          0.          0.          0.          0.          0.          0.          0.       ]\n",
      " [ -2.828427    0.         -3.9999998  -6.2831855  -3.9999998   0.         -3.9999998   0.       ]\n",
      " [  0.          0.          6.2831855   0.          0.          0.          0.          0.       ]\n",
      " [ -2.828427    0.         -3.9999998   0.         -3.9999998 -12.566371   -3.9999998   0.       ]\n",
      " [  0.          0.          0.          0.         12.566371    0.          0.          0.       ]\n",
      " [ -2.828427    0.         -3.9999998   0.         -3.9999998   0.         -3.9999998 -18.849556 ]\n",
      " [  0.          0.          0.          0.          0.          0.         18.849556    0.       ]]\n",
      "\n",
      "B:\n",
      "[[2.      ]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]]\n",
      "\n",
      "gu_B:\n",
      "[[2.      ]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]\n",
      " [2.828427]\n",
      " [0.      ]]\n",
      "\n",
      "P:\n",
      "[[1.        0.        1.4142135 0.        1.4142135 0.        1.4142135 0.       ]]\n",
      "\n",
      "gu_P:\n",
      "[[1.        0.        1.4142135 0.        1.4142135 0.        1.4142135 0.       ]]\n",
      "\n",
      "S:\n",
      "[[ -1.          0.         -1.4142135   0.         -1.4142135   0.         -1.4142135   0.       ]\n",
      " [  0.          0.          0.          0.          0.          0.          0.          0.       ]\n",
      " [ -1.4142135   0.         -2.         -6.2831855  -2.          0.         -2.          0.       ]\n",
      " [  0.          0.          6.2831855   0.          0.          0.          0.          0.       ]\n",
      " [ -1.4142135   0.         -2.          0.         -2.        -12.566371   -2.          0.       ]\n",
      " [  0.          0.          0.          0.         12.566371    0.          0.          0.       ]\n",
      " [ -1.4142135   0.         -2.          0.         -2.          0.         -2.        -18.849556 ]\n",
      " [  0.          0.          0.          0.          0.          0.         18.849556    0.       ]]\n",
      "\n",
      "gu_S:\n",
      "[[ -1.          0.         -1.4142135   0.         -1.4142135   0.         -1.4142135   0.       ]\n",
      " [  0.          0.          0.          0.          0.          0.          0.          0.       ]\n",
      " [ -1.4142135   0.         -1.9999999  -6.2831855  -1.9999999   0.         -1.9999999   0.       ]\n",
      " [  0.          0.          6.2831855   0.          0.          0.          0.          0.       ]\n",
      " [ -1.4142135   0.         -1.9999999   0.         -1.9999999 -12.566371   -1.9999999   0.       ]\n",
      " [  0.          0.          0.          0.         12.566371    0.          0.          0.       ]\n",
      " [ -1.4142135   0.         -1.9999999   0.         -1.9999999   0.         -1.9999999 -18.849556 ]\n",
      " [  0.          0.          0.          0.          0.          0.         18.849556    0.       ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_NPLR_FouT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NPLR-FouD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_NPLR_FouD():\n",
    "    the_measure = \"fourier\"\n",
    "    fourier_type = \"foud\"\n",
    "    rank = 1\n",
    "    nplr_foud = LowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=False\n",
    "    )\n",
    "    gu_nplr_foud = GuLowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=False\n",
    "    )\n",
    "    print(\"NPLR FOUD\")\n",
    "    A, B, P, S = nplr_foud.A, nplr_foud.B, nplr_foud.P, nplr_foud.S\n",
    "    gu_A, gu_B, gu_P, gu_S = (\n",
    "        jnp.asarray(gu_nplr_foud.A, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_foud.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_foud.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_nplr_foud.S, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nA:\\n{A}\\n\")\n",
    "    print(f\"gu_A:\\n{gu_A}\\n\")\n",
    "    assert jnp.allclose(A, gu_A, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"S:\\n{S}\\n\")\n",
    "    print(f\"gu_S:\\n{gu_S}\\n\")\n",
    "    assert jnp.allclose(S, gu_S, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NPLR FOUD\n",
      "\n",
      "A:\n",
      "[[-0.5        -0.         -0.70710677  0.         -0.70710677  0.         -0.70710677  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [-0.70710677  0.         -1.         -3.1415927  -1.          0.         -1.          0.        ]\n",
      " [ 0.          0.          3.1415927   0.          0.          0.          0.          0.        ]\n",
      " [-0.70710677  0.         -1.          0.         -1.         -6.2831855  -1.          0.        ]\n",
      " [ 0.          0.          0.          0.          6.2831855   0.          0.          0.        ]\n",
      " [-0.70710677  0.         -1.          0.         -1.          0.         -1.         -9.424778  ]\n",
      " [ 0.          0.          0.          0.          0.          0.          9.424778    0.        ]]\n",
      "\n",
      "gu_A:\n",
      "[[-0.5         0.         -0.70710677  0.         -0.70710677  0.         -0.70710677  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [-0.70710677  0.         -0.99999994 -3.1415927  -0.99999994  0.         -0.99999994  0.        ]\n",
      " [ 0.          0.          3.1415927   0.          0.          0.          0.          0.        ]\n",
      " [-0.70710677  0.         -0.99999994  0.         -0.99999994 -6.2831855  -0.99999994  0.        ]\n",
      " [ 0.          0.          0.          0.          6.2831855   0.          0.          0.        ]\n",
      " [-0.70710677  0.         -0.99999994  0.         -0.99999994  0.         -0.99999994 -9.424778  ]\n",
      " [ 0.          0.          0.          0.          0.          0.          9.424778    0.        ]]\n",
      "\n",
      "B:\n",
      "[[0.5       ]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]]\n",
      "\n",
      "gu_B:\n",
      "[[0.5       ]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]\n",
      " [0.70710677]\n",
      " [0.        ]]\n",
      "\n",
      "P:\n",
      "[[1.        0.        1.4142135 0.        1.4142135 0.        1.4142135 0.       ]]\n",
      "\n",
      "gu_P:\n",
      "[[1.        0.        1.4142135 0.        1.4142135 0.        1.4142135 0.       ]]\n",
      "\n",
      "S:\n",
      "[[ 0.5         0.          0.70710677  0.          0.70710677  0.          0.70710677  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.70710677  0.          0.9999999  -3.1415927   0.9999999   0.          0.9999999   0.        ]\n",
      " [ 0.          0.          3.1415927   0.          0.          0.          0.          0.        ]\n",
      " [ 0.70710677  0.          0.9999999   0.          0.9999999  -6.2831855   0.9999999   0.        ]\n",
      " [ 0.          0.          0.          0.          6.2831855   0.          0.          0.        ]\n",
      " [ 0.70710677  0.          0.9999999   0.          0.9999999   0.          0.9999999  -9.424778  ]\n",
      " [ 0.          0.          0.          0.          0.          0.          9.424778    0.        ]]\n",
      "\n",
      "gu_S:\n",
      "[[ 0.5         0.          0.70710677  0.          0.70710677  0.          0.70710677  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.70710677  0.          0.99999994 -3.1415927   0.99999994  0.          0.99999994  0.        ]\n",
      " [ 0.          0.          3.1415927   0.          0.          0.          0.          0.        ]\n",
      " [ 0.70710677  0.          0.99999994  0.          0.99999994 -6.2831855   0.99999994  0.        ]\n",
      " [ 0.          0.          0.          0.          6.2831855   0.          0.          0.        ]\n",
      " [ 0.70710677  0.          0.99999994  0.          0.99999994  0.          0.99999994 -9.424778  ]\n",
      " [ 0.          0.          0.          0.          0.          0.          9.424778    0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_NPLR_FouD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DPLR\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPLR-LegT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPLR-LegT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DPLR_LegT():\n",
    "    the_measure = \"legt\"\n",
    "    rank = 2\n",
    "    DPLR_bool = True\n",
    "    gu_dplr_legt = GuLowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, lambda_n=1.0, DPLR=DPLR_bool\n",
    "    )\n",
    "    dplr_legt = LowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, lambda_n=1.0, DPLR=DPLR_bool\n",
    "    )\n",
    "    print(\"DPLR LEGT\")\n",
    "    Lambda, P, B, V = dplr_legt.Lambda, dplr_legt.P, dplr_legt.B, dplr_legt.V\n",
    "    gu_Lambda, gu_P, gu_B, gu_V = (\n",
    "        jnp.asarray(gu_dplr_legt.Lambda, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_legt.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_legt.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_legt.V, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nLambda:\\n{Lambda}\\n\")\n",
    "    print(f\"gu_Lambda:\\n{gu_Lambda}\\n\")\n",
    "    assert jnp.allclose(Lambda, gu_Lambda, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"V:\\n{V}\\n\")\n",
    "    print(f\"gu_V:\\n{gu_V}\\n\")\n",
    "    assert jnp.allclose(V, gu_V, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = 4\n",
    "# g1 = np.random.randint(10, size=(4, r))\n",
    "# print(g1)\n",
    "# g2 = np.random.randint(10, size=(r, 2))\n",
    "# print(g2)\n",
    "# g3 = np.random.randint(10, size=(r))\n",
    "# print(g3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_12 = jnp.einsum(\"ij, j -> i\", g1, g2)\n",
    "# print(g_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_13 = jnp.einsum(\"ij, j -> i\", g1, g3)\n",
    "# print(g_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: HiPPO matrix not skew symmetric tensor(244.9999)\n",
      "imaginary eigvals: tensor([-30.7341, -12.7962,  -8.2184,  -2.6705,   2.6705,   8.2184,  12.7962,  30.7341])\n",
      "idx of imaginary eigvals: torch.return_types.sort(\n",
      "values=tensor([-30.7341, -12.7962,  -8.2184,  -2.6705,   2.6705,   8.2184,  12.7962,  30.7341]),\n",
      "indices=tensor([0, 1, 2, 3, 4, 5, 6, 7]))\n",
      "Warning: Diagonalization of A matrix not numerically precise - error tensor(92.7500, dtype=torch.float64)\n",
      "Lambda:\n",
      "tensor([-4.0000-30.7341j, -4.0000-12.7962j, -4.0000-8.2184j, -4.0000-2.6705j])\n",
      "V_inv:\n",
      "tensor([[ 1.1935e-01+0.0000e+00j,  2.2051e-01-1.1108e-02j,  2.6306e-01+8.1315e-02j,  2.9111e-01+1.3390e-01j,  2.2782e-01+3.2152e-01j,\n",
      "          7.1471e-02+3.6970e-01j, -1.6505e-01+4.4722e-01j, -4.4603e-01+1.8783e-01j],\n",
      "        [-9.4520e-02-0.0000e+00j,  1.2050e-04+1.7041e-01j, -3.0141e-01-6.7072e-02j,  3.4156e-02-9.0232e-03j, -2.9464e-01-2.3023e-01j,\n",
      "          5.0705e-01-2.3987e-01j, -6.8414e-02+5.1170e-01j, -2.2463e-01-3.0658e-01j],\n",
      "        [-2.2495e-01-0.0000e+00j, -9.6499e-02+2.3030e-05j, -4.2658e-01-2.5132e-01j,  4.1259e-01-4.6532e-01j,  2.0975e-01+4.0052e-01j,\n",
      "         -2.0796e-01+5.6561e-03j, -2.4097e-02-4.8674e-03j, -7.4802e-03-2.4463e-01j],\n",
      "        [ 6.5285e-01-0.0000e+00j, -7.3544e-02+6.3835e-01j, -2.3872e-01-1.6347e-01j,  9.3894e-02-2.2622e-02j, -1.2032e-02+1.8724e-02j,\n",
      "         -1.1313e-02+1.2943e-02j,  1.1965e-02-7.4059e-02j,  4.6438e-02+2.4346e-01j]])\n",
      "P:\n",
      "tensor([[0.0000, 1.2247, 0.0000, 1.8708, 0.0000, 2.3452, 0.0000, 2.7386],\n",
      "        [0.7071, 0.0000, 1.5811, 0.0000, 2.1213, 0.0000, 2.5495, 0.0000]])\n",
      "B:\n",
      "tensor([1.0000, 1.7321, 2.2361, 2.6458, 3.0000, 3.3166, 3.6056, 3.8730])\n",
      "V_inv  shape:\n",
      "torch.Size([4, 8])\n",
      "P shape:\n",
      "torch.Size([2, 8])\n",
      "B shape:\n",
      "torch.Size([8])\n",
      "gu_B after einsum:\n",
      "tensor([ 0.4576+5.0475j, -0.9968-0.7074j, -0.4307-1.5377j,  0.3895+1.4553j])\n",
      "gu_P after einsum:\n",
      "tensor([[-0.2392+1.6183j,  0.6380-1.2103j,  0.1455-1.5272j,  0.1862+1.4366j],\n",
      "        [ 0.5628+1.9508j, -1.3429+0.7101j, -0.4501+0.4398j,  0.0892-0.4076j]])\n",
      "WARNING: HiPPO matrix not skew symmetric 245.0\n",
      "Warning: Diagonalization of A matrix not numerically precise - error 464.0003\n",
      "Lambda:\n",
      "[-4.-24.131672j -4.-18.487362j -4. -8.672629j -4. -2.943789j]\n",
      "V_inv:\n",
      "[[-0.0345785 -0.j          0.        +0.25450024j -0.15901132-0.j          0.        +0.31078964j -0.41778263-0.j          0.        +0.04507836j\n",
      "  -0.54678863-0.j          0.        -0.58017904j]\n",
      " [-0.17605098-0.j          0.        +0.0335331j  -0.4077114 -0.j          0.        -0.20971805j -0.366924  -0.j          0.        -0.6578515j\n",
      "   0.41005382-0.j          0.        -0.14874524j]\n",
      " [-0.19979724-0.j          0.        +0.04514367j -0.48708007-0.j          0.        -0.5955707j   0.43665475-0.j          0.        +0.2553374j\n",
      "  -0.17935063-0.j          0.        -0.27939287j]\n",
      " [ 0.6541342 -0.j          0.        +0.6573183j  -0.2669079 -0.j          0.        -0.06872981j  0.01253388-0.j          0.        -0.00142932j\n",
      "   0.02667569-0.j          0.        +0.25140986j]]\n",
      "P:\n",
      "[[0.         1.2247448  0.         1.8708286  0.         2.3452077  0.         2.7386127 ]\n",
      " [0.70710677 0.         1.5811386  0.         2.1213202  0.         2.5495098  0.        ]]\n",
      "B:\n",
      "[1.        1.7320508 2.2360678 2.6457512 3.        3.3166246 3.6055512 3.8729832]\n",
      "V_inv  shape:\n",
      "(4, 8)\n",
      "P shape:\n",
      "(2, 8)\n",
      "B shape:\n",
      "(8,)\n",
      "B after einsum:\n",
      "[-3.614961  -0.8344363j -0.7100231 -3.254715j  -0.6256349 -1.7327663j  0.19109225+1.9256324j]\n",
      "P after einsum:\n",
      "[[ 0.        -0.5900355j  0.        -2.3014312j  0.        -1.2252508j  0.        +1.3616276j]\n",
      " [-2.5561633 +0.j        -0.50206214+0.j        -0.4423907 +0.j         0.13512266+0.j       ]]\n",
      "DPLR LEGT\n",
      "\n",
      "Lambda:\n",
      "[-4. -4. -4. -4.]\n",
      "\n",
      "gu_Lambda:\n",
      "[[-0.5 -0.5 -0.5 -0.5]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beegass/.cache/pypoetry/virtualenvs/s4mer-pkg-jZnBSgjq-py3.8/lib/python3.8/site-packages/jax/_src/lax/lax.py:558: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return _convert_element_type(operand, new_dtype, weak_type=False)\n",
      "/tmp/ipykernel_14827/4209973404.py:29: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  self.B = (B.copy()).astype(dtype)  # HiPPO B Matrix (N x 1)\n",
      "/tmp/ipykernel_14827/4209973404.py:30: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  self.P = (P.copy()).astype(dtype)  # HiPPO rank correction matrix (N x rank)\n",
      "/home/beegass/.cache/pypoetry/virtualenvs/s4mer-pkg-jZnBSgjq-py3.8/lib/python3.8/site-packages/torch/_tensor.py:957: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return self.numpy().astype(dtype, copy=False)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_DPLR_LegT()\n",
      "Cell \u001b[0;32mIn [39], line 21\u001b[0m, in \u001b[0;36mtest_DPLR_LegT\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mLambda:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mLambda\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgu_Lambda:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mgu_Lambda\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[39massert\u001b[39;00m jnp\u001b[39m.\u001b[39mallclose(Lambda, gu_Lambda, rtol\u001b[39m=\u001b[39m\u001b[39m1e-04\u001b[39m, atol\u001b[39m=\u001b[39m\u001b[39m1e-06\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mP:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mP\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgu_P:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mgu_P\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_DPLR_LegT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPLR-LMU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DPLR_LMU():\n",
    "    the_measure = \"legt\"\n",
    "    rank = 2\n",
    "    DPLR_bool = True\n",
    "    dplr_lmu = LowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, lambda_n=2.0, DPLR=DPLR_bool\n",
    "    )\n",
    "    gu_dplr_lmu = GuLowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, lambda_n=2.0, DPLR=DPLR_bool\n",
    "    )  # change lambda so resulting matrix is in the form of LMU\n",
    "    print(\"DPLR LMU\")\n",
    "    Lambda, P, B, V = dplr_lmu.Lambda, dplr_lmu.P, dplr_lmu.B, dplr_lmu.V\n",
    "    gu_Lambda, gu_P, gu_B, gu_V = (\n",
    "        jnp.asarray(gu_dplr_lmu.Lambda, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_lmu.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_lmu.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_lmu.V, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nLambda:\\n{Lambda}\\n\")\n",
    "    print(f\"gu_Lambda:\\n{gu_Lambda}\\n\")\n",
    "    assert jnp.allclose(Lambda, gu_Lambda, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"V:\\n{V}\\n\")\n",
    "    print(f\"gu_V:\\n{gu_V}\\n\")\n",
    "    assert jnp.allclose(V, gu_V, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_DPLR_LMU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPLR-LagT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DPLR_LagT():\n",
    "    the_measure = \"lagt\"\n",
    "    rank = 1\n",
    "    DPLR_bool = True\n",
    "    dplr_lagt = LowRankMatrix(\n",
    "        N=8,\n",
    "        rank=rank,\n",
    "        measure=the_measure,\n",
    "        alpha=0.0,  # change resulting tilt through alpha and beta\n",
    "        beta=1.0,\n",
    "        DPLR=DPLR_bool,\n",
    "    )  # change resulting tilt through alpha and beta\n",
    "    gu_dplr_lagt = GuLowRankMatrix(\n",
    "        N=8,\n",
    "        rank=rank,\n",
    "        measure=the_measure,\n",
    "        alpha=0.0,\n",
    "        beta=1.0,\n",
    "        DPLR=DPLR_bool,\n",
    "    )\n",
    "    print(\"DPLR LAGT\")\n",
    "    Lambda, P, B, V = dplr_lagt.Lambda, dplr_lagt.P, dplr_lagt.B, dplr_lagt.V\n",
    "    gu_Lambda, gu_P, gu_B, gu_V = (\n",
    "        jnp.asarray(gu_dplr_lagt.Lambda, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_lagt.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_lagt.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_lagt.V, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nLambda:\\n{Lambda}\\n\")\n",
    "    print(f\"gu_Lambda:\\n{gu_Lambda}\\n\")\n",
    "    assert jnp.allclose(Lambda, gu_Lambda, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"V:\\n{V}\\n\")\n",
    "    print(f\"gu_V:\\n{gu_V}\\n\")\n",
    "    assert jnp.allclose(V, gu_V, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_DPLR_LagT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPLR-LegS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DPLR_LegS():\n",
    "    the_measure = \"legs\"\n",
    "    rank = 1\n",
    "    DPLR_bool = True\n",
    "    dplr_legs = LowRankMatrix(N=8, rank=rank, measure=the_measure, DPLR=DPLR_bool)\n",
    "    gu_dplr_legs = GuLowRankMatrix(N=8, rank=rank, measure=the_measure, DPLR=DPLR_bool)\n",
    "    print(\"DPLR LEGS\")\n",
    "    Lambda, P, B, V = dplr_legs.Lambda, dplr_legs.P, dplr_legs.B, dplr_legs.V\n",
    "    gu_Lambda, gu_P, gu_B, gu_V = (\n",
    "        jnp.asarray(gu_dplr_legs.Lambda, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_legs.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_legs.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_legs.V, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nLambda:\\n{Lambda}\\n\")\n",
    "    print(f\"gu_Lambda:\\n{gu_Lambda}\\n\")\n",
    "    assert jnp.allclose(Lambda, gu_Lambda, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"V:\\n{V}\\n\")\n",
    "    print(f\"gu_V:\\n{gu_V}\\n\")\n",
    "    assert jnp.allclose(V, gu_V, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_DPLR_LegS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPLR Applied To Fourier Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPLR-FRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DPLR_FRU():\n",
    "    the_measure = \"fourier\"\n",
    "    fourier_type = \"fru\"\n",
    "    rank = 1\n",
    "    DPLR_bool = True\n",
    "    dplr_fru = LowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=DPLR_bool\n",
    "    )\n",
    "    gu_dplr_fru = GuLowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=DPLR_bool\n",
    "    )\n",
    "    print(\"DPLR FRU\")\n",
    "    Lambda, P, B, V = dplr_fru.Lambda, dplr_fru.P, dplr_fru.B, dplr_fru.V\n",
    "    gu_Lambda, gu_P, gu_B, gu_V = (\n",
    "        jnp.asarray(gu_dplr_fru.Lambda, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_fru.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_fru.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_fru.V, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nLambda:\\n{Lambda}\\n\")\n",
    "    print(f\"gu_Lambda:\\n{gu_Lambda}\\n\")\n",
    "    assert jnp.allclose(Lambda, gu_Lambda, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"V:\\n{V}\\n\")\n",
    "    print(f\"gu_V:\\n{gu_V}\\n\")\n",
    "    assert jnp.allclose(V, gu_V, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_DPLR_FRU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPLR-FouT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DPLR_FouT():\n",
    "    the_measure = \"fourier\"\n",
    "    fourier_type = \"fout\"\n",
    "    rank = 1\n",
    "    DPLR_bool = True\n",
    "    dplr_fout = LowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=DPLR_bool\n",
    "    )\n",
    "    gu_dplr_fout = GuLowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=DPLR_bool\n",
    "    )\n",
    "    print(\"DPLR FOUT\")\n",
    "    Lambda, P, B, V = dplr_fout.Lambda, dplr_fout.P, dplr_fout.B, dplr_fout.V\n",
    "    gu_Lambda, gu_P, gu_B, gu_V = (\n",
    "        jnp.asarray(gu_dplr_fout.Lambda, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_fout.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_fout.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_fout.V, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nLambda:\\n{Lambda}\\n\")\n",
    "    print(f\"gu_Lambda:\\n{gu_Lambda}\\n\")\n",
    "    assert jnp.allclose(Lambda, gu_Lambda, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"V:\\n{V}\\n\")\n",
    "    print(f\"gu_V:\\n{gu_V}\\n\")\n",
    "    assert jnp.allclose(V, gu_V, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_DPLR_FouT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPLR-FouD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Navigate Back To Low Rank Matrix Class](#make-hippo-matrices-dplr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DPLR_FouD():\n",
    "    the_measure = \"fourier\"\n",
    "    fourier_type = \"foud\"\n",
    "    rank = 1\n",
    "    DPLR_bool = True\n",
    "    dplr_foud = LowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=DPLR_bool\n",
    "    )\n",
    "    gu_dplr_foud = GuLowRankMatrix(\n",
    "        N=8, rank=rank, measure=the_measure, fourier_type=fourier_type, DPLR=DPLR_bool\n",
    "    )\n",
    "    print(\"DPLR FOUD\")\n",
    "    Lambda, P, B, V = dplr_foud.Lambda, dplr_foud.P, dplr_foud.B, dplr_foud.V\n",
    "    gu_Lambda, gu_P, gu_B, gu_V = (\n",
    "        jnp.asarray(gu_dplr_foud.Lambda, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_foud.P, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_foud.B, dtype=jnp.float32),\n",
    "        jnp.asarray(gu_dplr_foud.V, dtype=jnp.float32),\n",
    "    )\n",
    "    print(f\"\\nLambda:\\n{Lambda}\\n\")\n",
    "    print(f\"gu_Lambda:\\n{gu_Lambda}\\n\")\n",
    "    assert jnp.allclose(Lambda, gu_Lambda, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"P:\\n{P}\\n\")\n",
    "    print(f\"gu_P:\\n{gu_P}\\n\")\n",
    "    assert jnp.allclose(P, gu_P, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"B:\\n{B}\\n\")\n",
    "    print(f\"gu_B:\\n{gu_B}\\n\")\n",
    "    assert jnp.allclose(B, gu_B, rtol=1e-04, atol=1e-06)\n",
    "\n",
    "    print(f\"V:\\n{V}\\n\")\n",
    "    print(f\"gu_V:\\n{gu_V}\\n\")\n",
    "    assert jnp.allclose(V, gu_V, rtol=1e-04, atol=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_DPLR_FouD()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('s4mer-pkg-jZnBSgjq-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a81e05d1d7f7eae781698b7c1b81c0d771335201ebad1d81045cb177cef974b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
