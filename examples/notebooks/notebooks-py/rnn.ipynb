{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.ops\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax import optim\n",
    "from flax.linen.recurrent import RNNCellBase\n",
    "\n",
    "import optax\n",
    "\n",
    "import numpy as np  # convention: original numpy\n",
    "\n",
    "from typing import Any, Callable, Sequence, Optional, Tuple, Union\n",
    "from collections import defaultdict\n",
    "\n",
    "from src.models.hippo.hippo import HiPPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1701\n",
    "key = jax.random.PRNGKey(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_copies = 5\n",
    "rng, key2, key3, key4, key5 = jax.random.split(key, num=num_copies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_batch(nest, batch_size: Optional[int]):\n",
    "    \"\"\"Adds a batch dimension at axis 0 to the leaves of a nested structure.\"\"\"\n",
    "    broadcast = lambda x: jnp.broadcast_to(x, (batch_size,) + x.shape)\n",
    "\n",
    "    return jax.tree_map(broadcast, nest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(RNNCellBase):\n",
    "    hidden_size: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, input):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            W_xh = x_{t} @ W_{xh} - multiply the previous hidden state with\n",
    "            W_hh = H_{t-1} @ W_{hh} + b_{h} - this a linear layer\n",
    "\n",
    "            H_{t} = f_{w}(H_{t-1}, x)\n",
    "            H_{t} = tanh(H_{t-1} @ W_{hh}) + (x_{t} @ W_{xh})\n",
    "\n",
    "        Args:\n",
    "            hidden_size (int): hidden state size\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "\n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        \"\"\"\n",
    "        ht_1, _ = carry\n",
    "\n",
    "        h_t = self.rnn_update(input, ht_1)\n",
    "\n",
    "        return (h_t, h_t), h_t\n",
    "\n",
    "    def rnn_update(self, input, ht_1):\n",
    "\n",
    "        W_hh = nn.Dense(self.hidden_size)(ht_1)\n",
    "        W_xh = nn.Dense(self.hidden_size)(input)\n",
    "        h_t = nn.relu(W_hh + W_xh)  # H_{t} = tanh(H_{t-1} @ W_{hh}) + (x_{t} @ W_{xh})\n",
    "\n",
    "        return h_t\n",
    "\n",
    "    def initial_state(self, batch_size: Optional[int]):\n",
    "        state = jnp.zeros([self.hidden_size])\n",
    "        if batch_size is not None:\n",
    "            state = add_batch(state, batch_size)\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(RNNCellBase):\n",
    "    hidden_size: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, input):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            i_{t} = sigmoid((W_{ii} @ x_{t} + b_{ii}) + (W_{hi} @ h_{t-1} + b_{hi}))\n",
    "            f_{t} = sigmoid((W_{if} @ x_{t} + b_{if}) + (W_{hf} @ h_{t-1} + b_{hf}))\n",
    "            g_{t} = tanh((W_{ig} @ x_{t} + b_{ig}) + (W_{hg} @ h_{t-1} + b_{hg}))\n",
    "            o_{t} = sigmoid((W_{io} @ x_{t} + b_{io}) + (W_{ho} @ h_{t-1} + b_{ho}))\n",
    "            c_{t} = f_{t} * c_{t-1} + i_{t} * g_{t}\n",
    "            h_{t} = o_{t} * tanh(c_{t})\n",
    "\n",
    "        Args:\n",
    "            hidden_size (int): hidden state size\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "\n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        \"\"\"\n",
    "        ht_1, ct_1 = carry\n",
    "\n",
    "        c_t, h_t = self.rnn_update(input, ht_1, ct_1)\n",
    "\n",
    "        return (h_t, c_t), h_t\n",
    "\n",
    "    def rnn_update(self, input, ht_1, ct_1):\n",
    "\n",
    "        i_ta = nn.Dense(self.hidden_size)(input)\n",
    "        i_tb = nn.Dense(self.hidden_size)(ht_1)\n",
    "        i_t = nn.sigmoid(i_ta + i_tb)  # input gate\n",
    "\n",
    "        o_ta = nn.Dense(self.hidden_size)(input)\n",
    "        o_tb = nn.Dense(self.hidden_size)(ht_1)\n",
    "        o_t = nn.sigmoid(o_ta + o_tb)  # output gate\n",
    "\n",
    "        f_ia = nn.Dense(self.hidden_size)(\n",
    "            input\n",
    "        )  # b^{f}_{i} + \\sum\\limits_{j} U^{f}_{i, j} x^{t}_{j}\n",
    "        f_ib = nn.Dense(self.hidden_size)(\n",
    "            ht_1\n",
    "        )  # \\sum\\limits_{j} W^{f}_{i, j} h^{(t-1)}_{j}\n",
    "        f_i = nn.sigmoid(f_ia + f_ib)  # forget gate\n",
    "\n",
    "        g_ia = nn.Dense(self.hidden_size)(\n",
    "            input\n",
    "        )  # b^{g}_{i} + \\sum\\limits_{j} U^{g}_{i, j} x^{t}_{j}\n",
    "        g_ib = nn.Dense(self.hidden_size)(\n",
    "            ht_1\n",
    "        )  # \\sum\\limits_{j} W^{g}_{i, j} h^{(t-1)}_{j}\n",
    "        g_i = nn.tanh(g_ia + g_ib)  # (external) input gate\n",
    "\n",
    "        c_t = (f_i * ct_1) + (i_t * g_i)  # internal cell state update\n",
    "\n",
    "        h_t = o_t * nn.tanh(c_t)  # hidden state update\n",
    "\n",
    "        return h_t, c_t\n",
    "\n",
    "    def initial_state(self, batch_size: Optional[int]):\n",
    "        state = jnp.zeros([self.hidden_size])\n",
    "        if batch_size is not None:\n",
    "            state = add_batch(state, batch_size)\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCell(RNNCellBase):\n",
    "    hidden_size: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, input):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            z_t = sigmoid((W_{iz} @ x_{t} + b_{iz}) + (W_{hz} @ h_{t-1} + b_{hz}))\n",
    "            r_t = sigmoid((W_{ir} @ x_{t} + b_{ir}) + (W_{hr} @ h_{t-1} + b_{hr}))\n",
    "            g_t = tanh(((W_{ig} @ x_{t} + b_{ig}) + r_t) * (W_{hg} @ h_{t-1} + b_{hg}))\n",
    "            h_t = (z_t * h_{t-1}) + ((1 - z_t) * g_i)\n",
    "\n",
    "        Args:\n",
    "            hidden_size (int): hidden state size\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "\n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        \"\"\"\n",
    "        ht_1 = carry\n",
    "\n",
    "        h_t = self.rnn_update(input, ht_1)\n",
    "\n",
    "        return (h_t, h_t), h_t\n",
    "\n",
    "    def rnn_update(self, input, ht_1):\n",
    "\n",
    "        z_ta = nn.Dense(self.hidden_size)(input)\n",
    "        z_tb = nn.Dense(self.hidden_size)(ht_1)\n",
    "        z_t = nn.sigmoid(z_ta + z_tb)  # reset gate\n",
    "\n",
    "        r_ta = nn.Dense(self.hidden_size)(input)\n",
    "        r_tb = nn.Dense(self.hidden_size)(ht_1)\n",
    "        r_t = nn.sigmoid(r_ta + r_tb)  # update gate\n",
    "\n",
    "        g_ta = nn.Dense(self.hidden_size)(input)\n",
    "        g_tb = nn.Dense(self.hidden_size)(ht_1)\n",
    "        g_t = nn.tanh((g_ta + r_t) * g_tb)  # (external) input gate\n",
    "\n",
    "        h_t = ((1 - z_t) * ht_1) + (z_t * g_t)  # internal cell state update\n",
    "\n",
    "        return h_t\n",
    "\n",
    "    def initial_state(self, batch_size: Optional[int]):\n",
    "        state = jnp.zeros([self.hidden_size])\n",
    "        if batch_size is not None:\n",
    "            state = add_batch(state, batch_size)\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPOCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        RNN update function\n",
    "        τ(h, x) = (1 - g(h, x)) ◦ h + g(h, x) ◦ tanh(Lτ (h, x))\n",
    "        g(h, x) = σ(Lg(h,x))\n",
    "\n",
    "    Args:\n",
    "        hidden_size (int): hidden state size\n",
    "        output_size (int): output size\n",
    "        hippo (HiPPO): hippo model object\n",
    "        cell (RNNCellBase): choice of RNN cell object\n",
    "            - RNNCell\n",
    "            - LSTMCell\n",
    "            - GRUCell\n",
    "    \"\"\"\n",
    "\n",
    "    hidden_size: int\n",
    "    output_size: int\n",
    "    hippo: HiPPO\n",
    "    model: RNNCellBase\n",
    "\n",
    "    def setup(self):\n",
    "        self.cell = self.model(self.hidden_size)\n",
    "\n",
    "    def __call__(self, carry, input):\n",
    "        \"\"\"\n",
    "        Description:\n",
    "            RNN update function\n",
    "            τ(h, x) = (1 - g(h, x)) ◦ h + g(h, x) ◦ tanh(Lτ (h, x))\n",
    "            g(h, x) = σ(Lg(h,x))\n",
    "\n",
    "        Args:\n",
    "            carry (jnp.ndarray): hidden state from previous time step\n",
    "            input (jnp.ndarray): # input vector\n",
    "\n",
    "        Returns:\n",
    "            A tuple with the new carry and the output.\n",
    "        \"\"\"\n",
    "\n",
    "        _, h_t = self.cell(carry, input)\n",
    "\n",
    "        y_t = nn.Dense(self.output_size)(h_t)  # f_t in the paper\n",
    "\n",
    "        c_t = self.hippo(y_t, init_state=None, kernel=False)\n",
    "\n",
    "        return (h_t, c_t), h_t\n",
    "\n",
    "    def initial_state(self, batch_size: Optional[int]):\n",
    "        state = jnp.zeros([self.hidden_size])\n",
    "        if batch_size is not None:\n",
    "            state = add_batch(state, batch_size)\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: refer to https://github.com/deepmind/dm-haiku/blob/main/haiku/_src/recurrent.py#L714-L762\n",
    "# also refer to https://dm-haiku.readthedocs.io/en/latest/api.html?highlight=DeepRNN#deeprnn\n",
    "class _DeepRNN(RNNCellBase):\n",
    "    layers: Sequence[Any]\n",
    "    skip_connections: bool\n",
    "    hidden_to_output_layer: bool\n",
    "    layer_name: Optional[str]\n",
    "\n",
    "    def setup(self):\n",
    "        if self.skip_connections:\n",
    "            for layer in self.layers:\n",
    "                if not (isinstance(layer, RNNCellBase) or isinstance(layer, HiPPOCell)):\n",
    "                    raise ValueError(\n",
    "                        f\"{self.layer_name} layer {layer} is not a RNNCellBase or HiPPOCell\"\n",
    "                    )\n",
    "\n",
    "    def __call__(self, carry, inputs):\n",
    "        current_carry = carry\n",
    "        next_states = []\n",
    "        h_t_outputs = []\n",
    "        c_t_outputs = []\n",
    "        state_idx = 0\n",
    "        h_t, c_t = current_carry  # c_t may actually be h_t in which case dont use it\n",
    "        (\n",
    "            h_t_copy,\n",
    "            c_t_copy,\n",
    "        ) = current_carry  # c_t may actually be h_t in which case dont use it\n",
    "        concat = lambda *args: jnp.concatenate(args, axis=-1)\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            if self.skip_connections and idx > 0:\n",
    "                skip_h_t = jax.tree_map(concat, h_t, h_t_copy)\n",
    "                skip_c_t = jax.tree_map(concat, c_t, c_t_copy)\n",
    "                current_carry = (skip_h_t, skip_c_t)\n",
    "\n",
    "            if isinstance(layer, RNNCellBase) or isinstance(layer, HiPPOCell):\n",
    "                current_carry, next_state = layer(current_carry, inputs[state_idx])\n",
    "                if self.hidden_to_output_layer:\n",
    "                    next_state = nn.Dense(next_state.shape[0])(next_state)\n",
    "\n",
    "                h_t, c_t = current_carry\n",
    "                h_t_outputs.append(h_t)\n",
    "                c_t_outputs.append(c_t)\n",
    "                next_states.append(next_state)\n",
    "                state_idx += 1\n",
    "\n",
    "            else:\n",
    "                current_carry = layer(current_carry)\n",
    "\n",
    "        if self.skip_connections:\n",
    "            skip_h_t_out = jax.tree_map(concat, *h_t_outputs)\n",
    "            skip_c_t_out = jax.tree_map(concat, *c_t_outputs)\n",
    "            out = (skip_h_t_out, skip_c_t_out)\n",
    "        else:\n",
    "            out = current_carry\n",
    "\n",
    "        return out, tuple(next_states)\n",
    "\n",
    "    def initial_state(self, batch_size: Optional[int]):\n",
    "        return tuple(\n",
    "            layer.initial_state_and_carry(batch_size)\n",
    "            for layer in self.layers\n",
    "            if isinstance(layer, RNNCellBase)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRNN(_DeepRNN):\n",
    "    r\"\"\"Wraps a sequence of cores and callables as a single core.\n",
    "        >>> deep_rnn = hk.DeepRNN([\n",
    "        ...     LSTMCell(hidden_size=4),\n",
    "        ...     jax.nn.relu,\n",
    "        ...     LSTMCell(hidden_size=2),\n",
    "        ... ])\n",
    "    The state of a :class:`DeepRNN` is a tuple with one element per\n",
    "    :class:`RNNCore`. If no layers are :class:`RNNCore`\\ s, the state is an empty\n",
    "    tuple.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        layers: Sequence[Any],\n",
    "        skip_connections: Optional[bool] = False,\n",
    "        hidden_to_output_layer: Optional[bool] = False,\n",
    "        name: Optional[str] = None,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            layers,\n",
    "            skip_connections=skip_connections,\n",
    "            hidden_to_output_layer=hidden_to_output_layer,\n",
    "            layer_name=name,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Training Types\n",
    "refer to [this](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one2one(params, init_carry, input, sequence_length, cell):\n",
    "    _, h_t = cell.apply(params, init_carry, input)\n",
    "    y_t = nn.Dense(input.shape[0])(h_t)  # output\n",
    "    return y_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one2many(params, init_carry, input, T_y, cell, tf_bool=True):\n",
    "    output = []\n",
    "    if not tf_bool:\n",
    "        for i in range(len(T_y)):\n",
    "            if i == 0:\n",
    "                carry, h_t = cell.apply(params, init_carry, input[i])\n",
    "            else:\n",
    "                carry, h_t = cell.apply(params, carry, output[i - 1])\n",
    "\n",
    "            y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
    "            output.append(y_t)\n",
    "    else:\n",
    "        for i in range(len(input)):\n",
    "            carry, h_t = cell.apply(params, init_carry, input[i])\n",
    "            y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
    "            output.append(y_t)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many2one(params, init_carry, input, T_x, cell, tf_bool=True):\n",
    "    y_t = None\n",
    "    carry = init_carry\n",
    "    for i in range(len(T_x)):\n",
    "        carry, h_t = cell.apply(params, carry, input[i])\n",
    "        if i == (len(T_x) - 1):\n",
    "            y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
    "\n",
    "    return y_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many2many(params, init_carry, input, T_xy, cell, tf_bool=True):\n",
    "    output = []\n",
    "    carry = init_carry\n",
    "    for i in range(len(T_xy)):\n",
    "        carry, h_t = cell.apply(params, carry, input[i])\n",
    "        y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
    "        output.append(y_t)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many2many(params, init_carry, input, T_x, T_y, cell, tf_bool=True):\n",
    "    assert T_x != T_y, \"T_x and T_y must be different\"\n",
    "    output = []\n",
    "    carry = init_carry\n",
    "    for i in range(len(T_x)):\n",
    "        carry, h_t = cell.apply(params, carry, input[i])\n",
    "\n",
    "    for i in range(len(T_y)):\n",
    "        carry, h_t = cell.apply(params, carry, input[i])\n",
    "        y_t = nn.Dense(input[i].shape[0])(h_t)  # output\n",
    "        output.append(y_t)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data_2_id(iterable):\n",
    "    \"\"\"\n",
    "    provides mapping to and from ids\n",
    "    \"\"\"\n",
    "    \n",
    "    id_2_data = {}\n",
    "    data_2_id = {}\n",
    "\n",
    "    for id, elem in enumerate(iterable):\n",
    "        id_2_data[id] = elem\n",
    "\n",
    "    for id, elem in enumerate(iterable):\n",
    "        data_2_id[elem] = id\n",
    "\n",
    "    return (id_2_data, data_2_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(i, n):\n",
    "    \"\"\"\n",
    "    create vector of size n with 1 at index i\n",
    "    \"\"\"\n",
    "    print(i)\n",
    "    x = defaultdict(lambda: jnp.zeros(n))\n",
    "    # x[i] = 1\n",
    "    return x[i].at[i].set(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(char):\n",
    "    return one_hot(data_2_id[char], len(data_2_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(predictions, id_2_data):\n",
    "    return id_2_data[int(jnp.argmax(predictions))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(fname):\n",
    "  with open(fname, \"r\") as reader:\n",
    "    data = reader.read()\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data):\n",
    "  chars = list(set(data))\n",
    "  vocab_size = len(chars)\n",
    "  char_to_id, id_to_char = map_data_2_id(chars)\n",
    "  char_to_id = {value:key for key, value in char_to_id.items()}\n",
    "  # data converted to ids\n",
    "  # data_id = [char_to_id[char] for char in data]\n",
    "  data_id = [char_to_id[char] for char in data]\n",
    "  return data_id, char_to_id, id_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 2, 1, 0, 0, 0, 3, 4, 2]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"abcd...abcd...\"\n",
    "data_id, char_to_id, id_to_char = prep_data(data)\n",
    "# print(data_id)\n",
    "data_id[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Helpers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check [this](https://github.com/deepmind/optax/blob/master/examples/quick_start.ipynb) out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_optimizer_fn(starting_learning_rate, name=\"adam\"):\n",
    "    # refer to https://optax.readthedocs.io/en/latest/api.html#optimizer-schedules\n",
    "    optim = None\n",
    "\n",
    "    if name == \"sgd\":\n",
    "        optim = optax.sgd(starting_learning_rate)\n",
    "    elif name == \"adam\":\n",
    "        optim = optax.adam(\n",
    "            starting_learning_rate,\n",
    "        )\n",
    "    elif name == \"adagrad\":\n",
    "        optim = optax.adagrad(starting_learning_rate)\n",
    "    elif name == \"rmsprop\":\n",
    "        optim = optax.rmsprop(starting_learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"optimizer name not recognized\")\n",
    "\n",
    "    return optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_scheduler_fn(\n",
    "    start_learning_rate, steps, decay_rate, init_value, end_val, name\n",
    "):\n",
    "    # refer to https://optax.readthedocs.io/en/latest/api.html#schedules\n",
    "    scheduler = None\n",
    "\n",
    "    if name == \"constant\":\n",
    "        scheduler = optax.constant_schedule(init_value)\n",
    "\n",
    "    elif name == \"exp_decay\":\n",
    "        scheduler = optax.exponential_decay(\n",
    "            init_value=start_learning_rate, transition_steps=1000, decay_rate=0.99\n",
    "        )\n",
    "    elif name == \"linear\":\n",
    "        scheduler = optax.linear_schedule(init_value=init_value, end_value=end_val)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"scheduler name not recognized\")\n",
    "\n",
    "    return scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add transformations\n",
    "# refer to https://optax.readthedocs.io/en/latest/api.html#optax-transformations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # A simple update loop.\n",
    "#     for _ in range(1000):\n",
    "#     grads = jax.grad(compute_loss)(params, xs, ys)\n",
    "#     updates, opt_state = gradient_transform.update(grads, opt_state)\n",
    "#     params = optax.apply_updates(params, updates)\n",
    "\n",
    "#     assert jnp.allclose(params, target_params), \\\n",
    "#     'Optimization should retrieve the target params used to generate the data.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def optimizer_fn(start_learning_rate, params, num_weights, x, y):\n",
    "#     optimizer = optax.adam(start_learning_rate)\n",
    "#     # Obtain the `opt_state` that contains statistics for the optimizer.\n",
    "#     params = {'w': jnp.ones((num_weights,))}\n",
    "#     opt_state = optimizer.init(params)\n",
    "\n",
    "#     compute_loss = lambda params, x, y: optax.l2_loss(params['w'].dot(x), y)\n",
    "#     grads = jax.grad(compute_loss)(params, xs, ys)\n",
    "\n",
    "#     updates, opt_state = optimizer.update(grads, opt_state)\n",
    "#     params = optax.apply_updates(params, updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNLM(nn.Module):\n",
    "    state_size: int\n",
    "    vocab_size: int\n",
    "    hidden_size: int\n",
    "    hippo_order_N: int\n",
    "    batch_size: int\n",
    "\n",
    "    def setup(self):\n",
    "        L = self.vocab_size\n",
    "        N = self.state_size\n",
    "\n",
    "        hippo = HiPPO(\n",
    "            N=N,\n",
    "            max_length=L,\n",
    "            measure=\"legs\",\n",
    "            step=1.0 / L,\n",
    "            GBT_alpha=0.5,\n",
    "            seq_L=L,\n",
    "            v=\"v\",\n",
    "            lambda_n=1.0,\n",
    "            fourier_type=\"fru\",\n",
    "            alpha=0.0,\n",
    "            beta=1.0,\n",
    "        )\n",
    "\n",
    "        cell1 = LSTMCell\n",
    "        cell2 = LSTMCell\n",
    "\n",
    "        input_layers = [\n",
    "            HiPPOCell(hippo=hippo, model=cell1, hidden_size=N, output_size=L),\n",
    "            nn.relu,\n",
    "            HiPPOCell(hippo=hippo, model=cell2, hidden_size=N, output_size=L),\n",
    "        ]\n",
    "\n",
    "        self.deep_cell = DeepRNN(\n",
    "            layers=input_layers,\n",
    "            skip_connections=True,\n",
    "            hidden_to_output_layer=True,\n",
    "            name=\"RNNLM\",\n",
    "        )\n",
    "\n",
    "    def __call__(self, carry, i):\n",
    "        input = one_hot(i, self.vocab_size)\n",
    "        carries, next_states = self.deep_cell(carry, input)\n",
    "        predictions = nn.softmax(nn.Dense(self.vocab_size)(next_states[-1]))\n",
    "        return carries, next_states, predictions\n",
    "\n",
    "    def initial_state(self, batch_size: Optional[int]):\n",
    "        state = jnp.zeros([self.hidden_size])\n",
    "        if batch_size is not None:\n",
    "            state = add_batch(state, batch_size)\n",
    "        return state\n",
    "\n",
    "    def initial_carry(self, batch_size: Optional[int]):\n",
    "        state = jnp.zeros([self.hidden_size])\n",
    "        if batch_size is not None:\n",
    "            state = add_batch(state, batch_size)\n",
    "        return (state, state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, params, bridge, initial=\"\", max_length=100):\n",
    "    char_to_id, id_to_char = bridge\n",
    "    state = model.init_state()\n",
    "    output = initial\n",
    "    if len(initial) > 0:\n",
    "        for char in initial[:-1]:\n",
    "            _, state, _ = model.apply(params, char_to_id[char], state)\n",
    "\n",
    "    next_char = initial[-1]\n",
    "    for i in range(max_length):\n",
    "        state, predictions = model.apply(params, state, char_to_id[next_char], state)\n",
    "        next_char = decode(predictions, id_to_char)\n",
    "        output += next_char\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to [this](https://github.com/manifest/flax-extra/blob/48efe1f1515893289b44646977bf5049a340b6c8/docs/notebooks/combinators.ipynb), [this](https://github.com/romanak/pyprobml/blob/65c82b9b43d2100cbc7c59e766161ee801c0f85f/notebooks/book1/15/rnn_jax.ipynb), [this](https://github.com/probml/pyprobml/blob/71d98dcdd3798525353eb1bfb9851b47e9d64bde/notebooks/book1/15/rnn_jax.ipynb) and [this](https://github.com/probml/probml-notebooks/blob/36cb173afce3f4a07a7b475cf8a7937025a60465/notebooks-d2l/rnn_jax.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "RNNLM layer <jax._src.custom_derivatives.custom_jvp object at 0x7f28edc0bfd0> is not a RNNCellBase or HiPPOCell",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb Cell 38\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=9'>10</a>\u001b[0m \u001b[39m# model = CharRNN(state_size, len(char_to_id))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=10'>11</a>\u001b[0m model \u001b[39m=\u001b[39m RNNLM(state_size, \u001b[39mlen\u001b[39m(char_to_id), hidden_size, hippo_order_N, batch_size)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=11'>12</a>\u001b[0m params \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49minit(subkey, model\u001b[39m.\u001b[39;49minitial_carry(batch_size), \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel state size: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mstate_size\u001b[39m}\u001b[39;00m\u001b[39m, vocab size: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39mvocab_size\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=14'>15</a>\u001b[0m \u001b[39m# output: Model state size: 8, vocab size: 5\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=15'>16</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=16'>17</a>\u001b[0m \u001b[39m# run a single example through the model to test that it works\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "\u001b[1;32m/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb Cell 38\u001b[0m in \u001b[0;36mRNNLM.__call__\u001b[0;34m(self, carry, i)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=41'>42</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, carry, i):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=42'>43</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m one_hot(i, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_size)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=43'>44</a>\u001b[0m     carries, next_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeep_cell(carry, \u001b[39minput\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=44'>45</a>\u001b[0m     predictions \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39msoftmax(nn\u001b[39m.\u001b[39mDense(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_size)(next_states[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=45'>46</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m carries, next_states, predictions\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "\u001b[1;32m/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb Cell 38\u001b[0m in \u001b[0;36m_DeepRNN.setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=11'>12</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(layer, RNNCellBase) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(layer, HiPPOCell)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=12'>13</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=13'>14</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m layer \u001b[39m\u001b[39m{\u001b[39;00mlayer\u001b[39m}\u001b[39;00m\u001b[39m is not a RNNCellBase or HiPPOCell\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/beegass/Documents/Coding/s4mer/examples/notebooks/notebooks-py/rnn.ipynb#ch0000037?line=14'>15</a>\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: RNNLM layer <jax._src.custom_derivatives.custom_jvp object at 0x7f28edc0bfd0> is not a RNNCellBase or HiPPOCell"
     ]
    }
   ],
   "source": [
    "state_size = 8\n",
    "\n",
    "# randomness is handled using explicit keys in Jax\n",
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "hidden_size = 4\n",
    "hippo_order_N = 16\n",
    "batch_size = 8\n",
    "\n",
    "# model = CharRNN(state_size, len(char_to_id))\n",
    "model = RNNLM(state_size, len(char_to_id), hidden_size, hippo_order_N, batch_size)\n",
    "params = model.init(subkey, model.initial_carry(batch_size), 0)\n",
    "\n",
    "print(f\"Model state size: {model.state_size}, vocab size: {model.vocab_size}\")\n",
    "# output: Model state size: 8, vocab size: 5\n",
    "\n",
    "# run a single example through the model to test that it works\n",
    "new_state, predictions = model.apply(params, model.initial_carry(), model.init_state())\n",
    "assert predictions.shape[0] == model.vocab_size\n",
    "\n",
    "# calling sample on random model leads to random output\n",
    "sample(model, params, (char_to_id, id_to_char), \"abc\", max_length=10)\n",
    "# output: 'abcadbaadbadd'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    \"\"\"\n",
    "    chunks a sequences into two subsequences\n",
    "    one for inputs, another for targets, by\n",
    "    shifting the input by 1\n",
    "    \"\"\"\n",
    "    n = len(seq)\n",
    "    p = 0\n",
    "    while p + 1 <= n:\n",
    "        # ensure the last chunk is of equal size\n",
    "        yield seq[p : min(n - 1, p + size)], seq[(p + 1) : (p + size + 1)]\n",
    "        p += size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_loss(params, model, carries, inputs, targets):\n",
    "    # use lax.scan to efficiently generate a loop over the inputs\n",
    "    # this function returns the final state, and predictions for every step\n",
    "    # note: scan input array needs have shape [length, 1]\n",
    "    final_state, predictions = jax.lax.scan(\n",
    "        lambda carry, input: model.apply(params, carry, input), carries, np.array([inputs]).T\n",
    "    )\n",
    "    loss = np.mean(jax.vmap(optax.softmax_cross_entropy)(predictions, np.array([targets]).T))\n",
    "    return loss, final_state\n",
    "\n",
    "\n",
    "# we want both the loss an gradient, we set has_aux because rnn_loss also return final state\n",
    "# use static_argnums=1 to indicate that the model is static;\n",
    "# a different model input will require recomplication\n",
    "# finally, we jit the function to improve runtime\n",
    "rnn_loss_grad = jax.jit(jax.value_and_grad(rnn_loss, has_aux=True), static_argnums=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_step(model, optimizer, state, inputs, targets):\n",
    "    (loss, state), grad = rnn_loss_grad(optimizer.target, model, state, inputs, targets)\n",
    "    new_optimizer = optimizer.apply_gradient(grad)\n",
    "    return new_optimizer, loss, state\n",
    "\n",
    "\n",
    "def epoch_step(model, optimizer, data, batch_size):\n",
    "    state = model.init_state()\n",
    "    total_loss = 0\n",
    "    for n, (inputs, targets) in enumerate(chunker(data, batch_size)):\n",
    "        optimizer, loss, state = batch_step(model, optimizer, state, inputs, targets)\n",
    "\n",
    "        total_loss += loss\n",
    "    return optimizer, total_loss / (n + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('jax-pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbeba54f39f0ad863615cd2814766ffd78084a8276e5c331aa23b4d5ff4f068c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
