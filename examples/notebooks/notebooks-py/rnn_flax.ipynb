{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beegass/.cache/pypoetry/virtualenvs/hippo-pkg-Uqb72G6k-py3.8/lib/python3.8/site-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "/home/beegass/.cache/pypoetry/virtualenvs/hippo-pkg-Uqb72G6k-py3.8/lib/python3.8/site-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnCell(nn.Module):\n",
    "    hidden_size: int\n",
    "    activation: str = \"tanh\"\n",
    "\n",
    "    def setup(self):\n",
    "        if self.activation not in [\"tanh\", \"relu\", \"sigmoid\"]:\n",
    "            raise ValueError(\n",
    "                \"Invalid nonlinearity selected for RNN. Please use tanh, relu, or sigmoid.\"\n",
    "            )\n",
    "\n",
    "        self.input2hidden = nn.Dense(self.hidden_size)\n",
    "        self.hidden2hidden = nn.Dense(self.hidden_size)\n",
    "\n",
    "    def __call__(self, inputs, hidden_state=None):\n",
    "        \"\"\"\n",
    "        Inputs: inputs (jax array) of shape [batchsize, input_size]\n",
    "                hidden state (jax array) of shape [batchsize, hidden_size]\n",
    "        Output: output (jax array) of shape [batchsize, hidden_size]\n",
    "        \"\"\"\n",
    "\n",
    "        # initialize hidden state at first iteration if None\n",
    "        if hidden_state is None:\n",
    "            hidden_state = jnp.zeros((inputs.shape[0], self.hidden_size))\n",
    "\n",
    "        # here the rnn magic happens, once we have a hidden state, it becomes the\n",
    "        # input for the next hidden state, that way we keep an internal memory\n",
    "        hidden_state = self.input2hidden(inputs) + self.hidden2hidden(hidden_state)\n",
    "\n",
    "        # apply activation function\n",
    "        if self.activation == \"tanh\":\n",
    "            output = nn.tanh(hidden_state)\n",
    "        elif self.activation == \"relu\":\n",
    "            output = nn.relu(hidden_state)\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            output = nn.sigmoid(hidden_state)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3F_uUENXHtLx"
   },
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    input_size: int\n",
    "    hidden_size: int\n",
    "    num_layers: int\n",
    "    output_size: int\n",
    "    activation: str = \"relu\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs, hidden_state=None):\n",
    "        \"\"\"\n",
    "        Inputs: inputs (jax array) of shape [batchsize, sequence length, inputsize]\n",
    "        Output: output (jax array) of shape [batchsize, outputsize]\n",
    "        \"\"\"\n",
    "\n",
    "        rnn_cell_list = []\n",
    "        if self.activation == \"tanh\":\n",
    "            rnn_cell_list.append(RnnCell(self.hidden_size, \"tanh\"))\n",
    "\n",
    "            for _ in range(1, self.num_layers):\n",
    "                rnn_cell_list.append(RnnCell(self.hidden_size, \"tanh\"))\n",
    "\n",
    "        elif self.activation == \"relu\":\n",
    "            rnn_cell_list.append(RnnCell(self.hidden_size, \"relu\"))\n",
    "\n",
    "            for _ in range(1, self.num_layers):\n",
    "                rnn_cell_list.append(RnnCell(self.hidden_size, \"relu\"))\n",
    "\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            rnn_cell_list.append(RnnCell(self.hidden_size, \"sigmoid\"))\n",
    "\n",
    "            for _ in range(1, self.num_layers):\n",
    "                rnn_cell_list.append(RnnCell(self.hidden_size, \"sigmoid\"))\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid activation. Please use tanh, relu, or sigmoid activation.\"\n",
    "            )\n",
    "\n",
    "        fc = nn.Dense(self.output_size)\n",
    "\n",
    "        # Initialize hidden state at the first timestep if None\n",
    "        if hidden_state is None:\n",
    "            hidden_state = jnp.zeros(\n",
    "                (inputs.shape[0], self.num_layers, self.hidden_size)\n",
    "            )\n",
    "\n",
    "        hidden = hidden_state\n",
    "\n",
    "        outs = []\n",
    "        for t in range(inputs.shape[1]):\n",
    "            for layer in range(self.num_layers):\n",
    "                if layer == 0:\n",
    "                    hidden_l = rnn_cell_list[layer](\n",
    "                        inputs[:, t, :], hidden[:, layer, :]\n",
    "                    )\n",
    "                else:\n",
    "                    hidden_l = rnn_cell_list[layer](\n",
    "                        hidden[:, layer - 1, :], hidden[:, layer, :]\n",
    "                    )\n",
    "                hidden = hidden.at[:, layer, :].set(hidden_l)\n",
    "\n",
    "            outs.append(hidden_l)\n",
    "\n",
    "        # Select the last timestep indexed at [-1]\n",
    "        out = outs[-1].squeeze()\n",
    "        out = fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rnn():\n",
    "    model = SimpleRNN(input_size=28 * 28, hidden_size=128, num_layers=3, output_size=10)\n",
    "    x = jax.random.normal(jax.random.PRNGKey(0), (64, 784, 1))\n",
    "    vals = jax.random.normal(jax.random.PRNGKey(1), (64, 784, 783))\n",
    "    x = jnp.concatenate([x, vals], axis=-1)\n",
    "    variables = model.init(jax.random.PRNGKey(0), x)\n",
    "    out = model.apply(variables, x)\n",
    "    xshape = out.shape\n",
    "    return x, xshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple RNN size test: passed.\n"
     ]
    }
   ],
   "source": [
    "testx, xdims = test_rnn()\n",
    "print(\"Simple RNN size test: passed.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
