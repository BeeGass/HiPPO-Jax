{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiPPO Matrices\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Loading In Necessary Packages](#load-packages)\n",
    "* [Instantiate The HiPPO Matrix](#instantiate-the-hippo-matrix)\n",
    "    * [Translated Legendre (LegT)](#translated-legendre-legt)\n",
    "        * [LegT](#legt)\n",
    "        * [LMU](#lmu)\n",
    "    * [Translated Laguerre (LagT)](#translated-laguerre-lagt)\n",
    "    * [Scaled Legendre (LegS)](#scaled-legendre-legs)\n",
    "    * [Fourier Basis](#fourier-basis)\n",
    "        * [Fourier Recurrent Unit (FRU)](#fourier-recurrent-unit-fru)\n",
    "        * [Truncated Fourier (FouT)](#truncated-fourier-fout)\n",
    "        * [Fourier With Decay (FourD)](#fourier-with-decay-fourd)\n",
    "* [Gu's Linear Time Invariant (LTI) HiPPO Operator](#gus-hippo-legt-operator)\n",
    "* [Gu's Scale invariant (LSI) HiPPO Operator](#gus-scale-invariant-hippo-legs-operator)\n",
    "* [Implementation Of General HiPPO Operator](#implementation-of-general-hippo-operator)\n",
    "* [Test Generalized Bilinear Transform and Zero Order Hold Matrices](#test-generalized-bilinear-transform-and-zero-order-hold-matrices)\n",
    "    * [Testing Forward Euler on GBT matrices](#testing-forward-euler-transform-for-lti-and-lsi)\n",
    "    * [Testing Backward Euler on GBT matrices](#testing-backward-euler-transform-for-lti-and-lsi-on-legs-matrices)\n",
    "    * [Testing Bidirectional on GBT matrices](#testing-lti-and-lsi-operators-with-bidirectional-transform)\n",
    "    * [Testing ZOH on GBT matrices](#testing-zoh-transform-for-lti-and-lsi-on-legs-matrices)\n",
    "* [Testing HiPPO Operators](#test-hippo-operators)\n",
    "    * [Testing Forward Euler on HiPPO Operators](#testing-lti-and-lsi-operators-with-forward-euler-transform)\n",
    "    * [Testing Backward Euler on HiPPO Operators](#testing-lti-and-lsi-operators-with-backward-euler-transform)\n",
    "    * [Testing Bidirectional on HiPPO Operators](#testing-lti-and-lsi-operators-with-bidirectional-transform)\n",
    "    * [Testing ZOH on HiPPO Operators](#testing-lti-and-lsi-operators-with-zoh-transform)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_path: /Users/beegass/Documents/Coding/s4mer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../../\"))\n",
    "print(f\"module_path: {module_path}\")\n",
    "if module_path not in sys.path:\n",
    "    print(f\"Adding {module_path} to sys.path\")\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "os.environ[\"TF_FORCE_UNIFIED_MEMORY\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import packages\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax._src.scipy.special import _gen_associated_legendre\n",
    "import einops\n",
    "from scipy import special as ss\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CpuDevice(id=0)]\n",
      "The Device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices())\n",
    "print(f\"The Device: {jax.lib.xla_bridge.get_backend().platform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS enabled: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"MPS enabled: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=150)\n",
    "np.set_printoptions(linewidth=150)\n",
    "jnp.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1701\n",
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_copies = 10\n",
    "subkeys = jax.random.split(key, num=num_copies)\n",
    "key = subkeys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs, tensor=False):\n",
    "#     \"\"\"\n",
    "#     Evaluate Legendre series at points x.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     x : array_like\n",
    "#         Points at which to evaluate the series.\n",
    "#     coeffs : array_like\n",
    "#         Coefficients of the Legendre series. The series is assumed to be of\n",
    "#         the form ``c[0]*P_0(x) + c[1]*P_1(x) + ... + c[N]*P_N(x)``.\n",
    "#     tensor : bool, optional\n",
    "#         If True, return a tensor. If False, return an array. Default is False.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     ndarray\n",
    "#         The value of the Legendre series at the points `x`.\n",
    "\n",
    "#     References\n",
    "#     ----------\n",
    "#     .. [1] Wikipedia, \"Legendre polynomials\",\n",
    "#            https://en.wikipedia.org/wiki/Legendre_polynomials\n",
    "\n",
    "#     \"\"\"\n",
    "#     x = jnp.asarray(x)\n",
    "#     if tensor:\n",
    "#         result = jnp.zeros(x.shape + coeffs.shape[0:1], dtype=coeffs.dtype)\n",
    "#     else:\n",
    "#         result = jnp.zeros(x.shape, dtype=coeffs.dtype)\n",
    "\n",
    "#     def body(i, val):\n",
    "#         # Recurrence relation for Legendre polynomials\n",
    "#         P0 = jnp.ones_like(x)\n",
    "#         P1 = x\n",
    "#         P = jax.lax.cond(i > 1, (2 * i - 1) * x * P1 - (i - 1) * P0 / i, P1)\n",
    "\n",
    "#         # Add current term to result\n",
    "#         val = val + coeffs[i] * P\n",
    "\n",
    "#         return i + 1, val\n",
    "\n",
    "#     _, result = jax.lax.scan(body, 0, result)\n",
    "\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs, tensor=None):\n",
    "#     \"\"\"\n",
    "#     Evaluate Legendre polynomials at points x using the provided coefficients.\n",
    "\n",
    "#     Args:\n",
    "#         x: Input points at which to evaluate the Legendre polynomials.\n",
    "#         coeffs: Coefficients of the Legendre polynomials.\n",
    "#         tensor: Optional tensor for use with JAX's JIT compilation.\n",
    "\n",
    "#     Returns:\n",
    "#         The value of the Legendre polynomials evaluated at the points x.\n",
    "#     \"\"\"\n",
    "#     if tensor is None:\n",
    "#         tensor = jnp.zeros_like(x)\n",
    "\n",
    "#     def body(i, val):\n",
    "#         true_fun = lambda i: (jnp.sqrt((2 * i - 1) / i), None)\n",
    "#         false_fun = lambda _: 0.0\n",
    "#         P1 = jax.lax.cond(i > 1, true_fun, false_fun)\n",
    "#         for j in range(2, jnp.floor(i) + 1):\n",
    "#             P0, P1 = P1, P\n",
    "#             P = ((2 * j - 1) * x * P1 - (j - 1) * P0) / j\n",
    "#         val = val + coeffs[i] * P\n",
    "#         return i + 1, val\n",
    "\n",
    "#     _, result = jax.lax.scan(body, 0, tensor)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs):\n",
    "#     n = coeffs.shape[0]\n",
    "#     tensor = jnp.stack([jnp.ones_like(x), x], axis=-1)\n",
    "#     for i in range(2, n):\n",
    "#         P0, P1 = tensor[..., i-1], tensor[..., i-2]\n",
    "#         true_fun = lambda i, val: (jnp.sqrt((2 * i - 1) / i), val)\n",
    "#         false_fun = lambda i, val: (0.0, val)\n",
    "#         P1 = jax.lax.cond(i > 1, (i, P1), true_fun, false_fun)[0]\n",
    "#         tensor = jnp.concatenate([tensor, ((x * P1 - ((i - 1) / i) * P0)[..., None])], axis=-1)\n",
    "#     val = jnp.zeros_like(x)\n",
    "#     body_fun = lambda val, p: (val + coeffs[p[0]] * p[1], (p[0]+1, p[2], p[3]))\n",
    "#     final_val = jax.lax.scan(body_fun, val, (jnp.arange(n), tensor[..., -1], x, P1))[0]\n",
    "#     return final_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs):\n",
    "#     # Initialize P0 and P1\n",
    "#     P0 = jnp.ones_like(x)\n",
    "#     P1 = x\n",
    "\n",
    "#     # Initialize tensor for storing intermediate results\n",
    "#     tensor = P0[..., None]\n",
    "\n",
    "#     # Loop through recursion relation and compute Legendre polynomials\n",
    "#     def body(i, val):\n",
    "#         true_fun = lambda i, P1: (jnp.sqrt((2 * i - 1) / i) * P1, val + coeffs[i] * P1)\n",
    "#         false_fun = lambda i, P1: (P1, val)\n",
    "#         P1, val = jax.lax.cond(i > 1, (i, P1), true_fun, false_fun)\n",
    "#         tensor = jnp.concatenate([tensor, ((x * P1 - ((i - 1) / i) * P0)[..., None])], axis=-1)\n",
    "#         P0 = P1\n",
    "#         return i + 1, val\n",
    "\n",
    "#     _, result = jax.lax.scan(body, 0, jnp.zeros_like(x))\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs):\n",
    "#     def body(i_val, x_val):\n",
    "#         i, val, P1, P0 = i_val\n",
    "#         true_fun = lambda i, P1: (jnp.sqrt((2 * i - 1) / i) * P1, val + coeffs[i] * P1)\n",
    "#         false_fun = lambda i, P1: (P1, val)\n",
    "#         P1, val = jax.lax.cond(i > 1, (i, P1), true_fun, false_fun)\n",
    "#         tensor = jnp.concatenate([x_val, ((x * P1 - ((i - 1) / i) * P0)[..., None])], axis=-1)\n",
    "#         P0 = P1\n",
    "#         return (i + 1, val, P1, P0), tensor\n",
    "\n",
    "#     _, result = jax.lax.scan(body, (0, jnp.zeros_like(x), jnp.zeros_like(x), jnp.zeros_like(x)), jnp.zeros_like(x))\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def eval_legendre(x, coeffs):\n",
    "#     def body(carry, i_val):\n",
    "#         i, val, P1, P0 = carry\n",
    "#         x_val = i_val[0]\n",
    "\n",
    "#         true_fun = lambda i_P1: (jnp.sqrt((2 * i - 1) / i) * i_P1, val + coeffs[i] * i_P1)\n",
    "#         false_fun = lambda i_P1: (i_P1, val)\n",
    "\n",
    "#         P1, val = jax.lax.cond(i > 1, P1, true_fun, false_fun)\n",
    "\n",
    "#         tensor = jnp.concatenate([i_val[1], ((x_val * P1 - ((i - 1) / i) * P0)[..., None])], axis=-1)\n",
    "#         P0 = P1\n",
    "\n",
    "#         return (i + 1, val, P1, P0), tensor\n",
    "\n",
    "#     _, result = jax.lax.scan(body, (0, jnp.zeros_like(x), jnp.zeros_like(x), jnp.zeros_like(x)), (x,))\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs):\n",
    "#     def body(carry, i_val):\n",
    "#         i, val, P1, P0 = carry\n",
    "#         x_val = i_val[0]\n",
    "#         true_fun = lambda i_P1: (jnp.sqrt((2 * i - 1) / i) * i_P1, val + coeffs[i] * i_P1)\n",
    "#         false_fun = lambda i_P1: (i_P1, val)\n",
    "#         P1, new_val = jax.lax.cond(i > 0, P1, true_fun, P0, false_fun)\n",
    "#         return (i + 1, new_val, P1, P0), P1\n",
    "\n",
    "#     _, result = jax.lax.scan(body, (jnp.array([0]), jnp.zeros_like(x), jnp.zeros_like(x), jnp.zeros_like(x)), x[:, None])\n",
    "#     return result.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs):\n",
    "#     def body(carry, i_val):\n",
    "#         i, P1, P0, val = carry\n",
    "#         true_fun = lambda i_P1: (jnp.sqrt((2 * i - 1) / i) * i_P1, val + coeffs[i] * i_P1)\n",
    "#         false_fun = lambda i_P1: (i_P1, val)\n",
    "#         P1, new_val = jax.lax.cond(i_val[0] > 0, P1, true_fun, P0, false_fun)\n",
    "#         return (i + 1, new_val, P1, P0), P1\n",
    "\n",
    "#     _, result = jax.lax.scan(body, (jnp.array([0]), jnp.zeros_like(x), jnp.zeros_like(x), jnp.zeros_like(x)), x[:, None])\n",
    "#     return result.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs):\n",
    "#     \"\"\"Evaluate Legendre polynomials with coefficients `coeffs` at points `x`.\"\"\"\n",
    "#     coeffs = jnp.flip(coeffs)\n",
    "\n",
    "#     def body(carry, i_val):\n",
    "#         i, val, P1, P0 = carry\n",
    "#         true_fun = lambda i_P1: (jnp.sqrt((2 * i - 1) / i) * i_P1, val + coeffs[i] * i_P1)\n",
    "#         false_fun = lambda i_P1: (i_P1, val)\n",
    "#         P1, new_val = jax.lax.cond(bool(i > 0), P1, lambda i_P1: (jnp.sqrt((2 * i[0] - 1) / i[0]) * i_P1, val + coeffs[i[0]] * i_P1), P0, lambda i_P1: (i_P1, val))\n",
    "#         return (i + 1, new_val, P1, P0), P1\n",
    "\n",
    "#     _, result = jax.lax.scan(body, (jnp.array([0]), jnp.zeros_like(x), jnp.zeros_like(x), jnp.zeros_like(x)), x[:, None])\n",
    "#     return result.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs):\n",
    "#     def body(carry, i_val):\n",
    "#         i, val, P1, P0 = carry\n",
    "#         P2 = jnp.where(jnp.less(i, 2), x, ((2 * i - 1) * x * P1 - (i - 1) * P0) / i)\n",
    "#         P1, new_val = jax.lax.cond(i > 0, (P1, val), lambda args: (jnp.sqrt((2 * i - 1) / i) * args[0], args[1] + coeffs[i] * args[0]), (P2, val), lambda args: (args[0], args[1]))\n",
    "#         return (i + 1, new_val, P1, P2), P1\n",
    "\n",
    "#     _, result = jax.lax.scan(body, (jnp.array([0]), jnp.zeros_like(x), jnp.zeros_like(x), jnp.zeros_like(x)), x[:, None])\n",
    "#     return result.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs):\n",
    "#     def body(carry, i_val):\n",
    "#         i, val, P1, P0 = carry\n",
    "#         P2 = jnp.where(jnp.less(i, 2), x, ((2 * i - 1) * x * P1 - (i - 1) * P0) / i)\n",
    "#         P1 = jax.lax.cond(i > 0, (P1, val), lambda args: (jnp.sqrt((2 * i - 1) / i) * args[0], args[1] + coeffs[i] * args[0]), (P2, val), lambda args: (args[0], args[1]))[0]\n",
    "#         new_val = P1\n",
    "#         return (i + 1, new_val, P1, P2), P1\n",
    "#     _, result = jax.lax.scan(body, (jnp.array([0]), jnp.zeros_like(x), jnp.zeros_like(x), jnp.zeros_like(x)), x[:, None])\n",
    "#     return result.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs):\n",
    "#     \"\"\"Evaluate Legendre polynomials with coefficients `coeffs` at `x`.\"\"\"\n",
    "#     def body(carry, i_val):\n",
    "#         i, val, P1, P0 = carry\n",
    "#         P2 = jnp.where(jnp.less(i, 2), x, ((2 * i - 1) * x * P1 - (i - 1) * P0) / i)\n",
    "#         P1 = jax.lax.cond(jnp.squeeze(i > 0), (P1, val), lambda args: (jnp.sqrt((2 * i - 1) / i) * args[0], args[1] + coeffs[i] * args[0]), (P2, val), lambda args: (args[0], args[1]))[0]\n",
    "#         new_val = P1\n",
    "#         return (i + 1, new_val, P1, P2), P1\n",
    "\n",
    "#     _, result = jax.lax.scan(body, (jnp.array([0]), jnp.zeros_like(x), jnp.zeros_like(x), jnp.zeros_like(x)), x[:, None])\n",
    "#     return result.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def eval_legendre(x, coeffs):\n",
    "#     \"\"\"\n",
    "#     Evaluate the Legendre polynomials with coefficients `coeffs` at the values in `x`.\n",
    "\n",
    "#     Args:\n",
    "#     x: a 1D array of input values\n",
    "#     coeffs: a 1D array of polynomial coefficients\n",
    "\n",
    "#     Returns:\n",
    "#     a 1D array of the same length as `x`, representing the polynomial values\n",
    "#     \"\"\"\n",
    "#     p0 = jnp.ones_like(x)\n",
    "#     p1 = x\n",
    "#     if coeffs.size == 0:\n",
    "#         return p0\n",
    "#     elif coeffs.size == 1:\n",
    "#         return coeffs[0] * p1\n",
    "#     else:\n",
    "#         for n in range(1, coeffs.size):\n",
    "#             pn = ((2 * n + 1) * x * p1 - n * p0) / (n + 1)\n",
    "#             p0 = p1\n",
    "#             p1 = pn\n",
    "#         return jnp.dot(jnp.vander(x, coeffs.size), coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def eval_legendre(x, coeffs):\n",
    "#     \"\"\"\n",
    "#     Evaluate the Legendre polynomials with coefficients `coeffs` at the values in `x`.\n",
    "\n",
    "#     Args:\n",
    "#     x: a 1D array of input values\n",
    "#     coeffs: a 1D array of polynomial coefficients\n",
    "\n",
    "#     Returns:\n",
    "#     a 1D array of the same length as `x`, representing the polynomial values\n",
    "#     \"\"\"\n",
    "#     n = coeffs.size\n",
    "#     p = jnp.zeros_like(x)\n",
    "#     for i in range(n):\n",
    "#         # Compute the ith Legendre polynomial using Rodrigues' formula\n",
    "#         dPdx = jax.grad(lambda x: jnp.power(x*x - 1, i))(x)\n",
    "#         p += coeffs[i] * dPdx / (2**i * jnp.math.factorial(i))\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs):\n",
    "#     n = coeffs.size\n",
    "#     p = jnp.zeros_like(x)\n",
    "#     for i in range(n):\n",
    "#         # Define a scalar function that takes x as input and returns the ith Legendre polynomial\n",
    "#         def legendre_scalar(xx):\n",
    "#             return jnp.power(xx*xx - 1, i)\n",
    "#         # Compute the gradient of the scalar function at x\n",
    "#         dPdx = jax.grad(legendre_scalar)(x)\n",
    "#         p += coeffs[i] * dPdx / (2**i * jnp.math.factorial(i))\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs, degree=None):\n",
    "#     # If degree is not specified, use the number of coefficients - 1\n",
    "#     degree = coeffs.size - 1 if degree is None else degree\n",
    "#     # Broadcast the inputs to the same shape\n",
    "#     x = jnp.broadcast_to(x, (degree+1, x.size))\n",
    "#     coeffs = jnp.broadcast_to(coeffs, (degree+1, coeffs.size))\n",
    "#     # Define the scalar function for the ith Legendre polynomial using Rodrigues' formula\n",
    "#     def legendre_scalar(i, xx):\n",
    "#         return jnp.power(xx*xx - 1, i)\n",
    "#     # Vectorize the scalar function and compute the gradients for all inputs at once\n",
    "#     dPdx = jax.vmap(jax.grad(legendre_scalar), in_axes=(0, None))(jnp.arange(degree+1), x)\n",
    "#     # Compute the polynomial as a linear combination of the gradients\n",
    "#     p = jnp.sum(coeffs * dPdx, axis=0) / 2**jnp.arange(degree+1) / jnp.array([jnp.math.factorial(i) for i in range(degree+1)])\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs, degree=None):\n",
    "#     if degree is None:\n",
    "#         degree = len(coeffs) - 1\n",
    "#     xx = jnp.asarray(x)\n",
    "#     p = jnp.zeros_like(xx)\n",
    "#     for i in range(degree+1):\n",
    "#         # Define a scalar function of a scalar variable\n",
    "#         def legendre_scalar(x_i):\n",
    "#             if i == 0:\n",
    "#                 return jnp.ones_like(x_i)\n",
    "#             elif i == 1:\n",
    "#                 return x_i\n",
    "#             else:\n",
    "#                 return ((2*i-1)*x_i*legendre_scalar(x_i) - (i-1)*legendre_scalar(x_i-1)) / i\n",
    "#         # Vectorize the scalar function and compute the gradients for all inputs at once\n",
    "#         dPdx = jax.vmap(jax.grad(legendre_scalar), in_axes=(0, None))(jnp.arange(degree+1).astype(float), xx)\n",
    "#         # Compute the polynomial as a linear combination of the gradients\n",
    "#         p += coeffs[i] * dPdx[i] / (2**i * jnp.math.factorial(i))\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs, degree=None):\n",
    "#     if degree is None:\n",
    "#         degree = len(coeffs) - 1\n",
    "#     xx = jnp.array(x).reshape((-1, 1))\n",
    "#     p = jnp.zeros_like(xx)\n",
    "#     for i in range(degree+1):\n",
    "#         def legendre_scalar(x_i):\n",
    "#             if i == 0:\n",
    "#                 return jnp.ones_like(x_i)\n",
    "#             elif i == 1:\n",
    "#                 return x_i\n",
    "#             else:\n",
    "#                 return ((2*i-1)*x_i*legendre_scalar(x_i) - (i-1)*legendre_scalar(x_i-1)) / i\n",
    "#         # Vectorize the scalar function and compute the gradients for all inputs at once\n",
    "#         dPdx = jax.vmap(jax.grad(legendre_scalar))(xx)\n",
    "#         # Compute the polynomial as a linear combination of the gradients\n",
    "#         p += coeffs[i] * dPdx[i] / (2**i * jnp.math.factorial(i))\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def legendre_scalar(x):\n",
    "#     if x < 2:\n",
    "#         return x\n",
    "#     p_i_minus_2 = 1\n",
    "#     p_i_minus_1 = x\n",
    "#     for i in range(2, x+1):\n",
    "#         p_i = ((2*i-1)*x*p_i_minus_1 - (i-1)*p_i_minus_2) / i\n",
    "#         p_i_minus_2 = p_i_minus_1\n",
    "#         p_i_minus_1 = p_i\n",
    "#     return p_i\n",
    "\n",
    "# def eval_legendre(x, coeffs, degree=None):\n",
    "#     if degree is None:\n",
    "#         degree = len(coeffs) - 1\n",
    "#     xx = jnp.array(x)\n",
    "#     p = jnp.zeros_like(xx)\n",
    "#     for i in range(degree+1):\n",
    "#         x_i = xx if i == 0 else ((2 * xx * x_i) - x_im1)\n",
    "#         x_im1 = xx if i == 1 else x_i\n",
    "#         # Compute the scalar function and its gradient\n",
    "#         scalar_val = legendre_scalar(x_i).item()\n",
    "#         dPdx_scalar = jax.grad(legendre_scalar)(x_i).item()\n",
    "#         # Compute the polynomial as a linear combination of the gradients\n",
    "#         p += coeffs[i] * dPdx_scalar / (2**i * jnp.math.factorial(i))\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs, degree=None):\n",
    "#     \"\"\"\n",
    "#     Evaluate a Legendre polynomial of a given degree at a given set of points.\n",
    "\n",
    "#     Parameters:\n",
    "#         x (float or ndarray): Points at which to evaluate the polynomial, shape (n_points,).\n",
    "#         coeffs (ndarray): Coefficients of the polynomial, shape (degree+1,).\n",
    "#         degree (int): Degree of the polynomial to evaluate (optional).\n",
    "#             If not provided, the degree is assumed to be len(coeffs) - 1.\n",
    "\n",
    "#     Returns:\n",
    "#         ndarray: Values of the Legendre polynomial at the given points, shape (n_points,).\n",
    "#     \"\"\"\n",
    "#     x = jnp.atleast_1d(x)\n",
    "#     degree = degree or len(coeffs) - 1\n",
    "\n",
    "#     # Define a function to compute the scalar value of the Legendre polynomial at a single point\n",
    "#     def legendre_scalar(x_i):\n",
    "#         p_i_minus_2 = 1\n",
    "#         p_i_minus_1 = x_i\n",
    "#         p_i = 0.5 * (3 * x_i**2 - 1)  # default value if degree is less than 2\n",
    "#         for i in range(2, degree + 1):\n",
    "#             p_i = ((2*i-1)*x_i*p_i_minus_1 - (i-1)*p_i_minus_2) / i\n",
    "#             p_i_minus_2 = p_i_minus_1\n",
    "#             p_i_minus_1 = p_i\n",
    "#         return p_i.item()\n",
    "\n",
    "#     # Evaluate the polynomial at each point in x\n",
    "#     p = jnp.zeros_like(x)\n",
    "#     for i in range(degree + 1):\n",
    "#         x_i = x if i == 0 else (2 * x * x_i - x_im1)\n",
    "#         x_im1 = x if i == 1 else x_i\n",
    "#         # Compute the scalar function and its gradient\n",
    "#         scalar_val = legendre_scalar(x_i)\n",
    "#         dPdx_scalar = jax.grad(legendre_scalar)(x_i).item()\n",
    "#         # Compute the polynomial as a linear combination of the gradients\n",
    "#         p += coeffs[i] * dPdx_scalar / (2**i * jnp.math.factorial(i))\n",
    "\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def legendre_scalar(x_i):\n",
    "#     p_i_minus_2 = 1.0\n",
    "#     p_i_minus_1 = x_i\n",
    "#     p_i = x_i\n",
    "#     for _ in range(degree - 1):\n",
    "#         p_i = ((2 * _ + 1) * x_i * p_i_minus_1 - _ * p_i_minus_2) / (_ + 1)\n",
    "#         p_i_minus_2 = p_i_minus_1\n",
    "#         p_i_minus_1 = p_i\n",
    "#     return p_i\n",
    "\n",
    "# @jax.jit\n",
    "# def eval_legendre(x, coeffs, degree):\n",
    "#     x = jnp.asarray(x)\n",
    "#     coeffs = jnp.asarray(coeffs)\n",
    "#     p = jnp.zeros_like(x)\n",
    "#     for i in range(degree):\n",
    "#         x_i = x ** i\n",
    "#         # Compute the scalar function and its gradient\n",
    "#         scalar_val = legendre_scalar(x_i)\n",
    "#         dPdx_scalar = jax.grad(legendre_scalar)(x_i)\n",
    "#         # Compute the polynomial as a linear combination of the gradients\n",
    "#         p += coeffs[i] * dPdx_scalar / (2**i * jnp.math.factorial(i))\n",
    "#     return p.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs, degree=None):\n",
    "#     x = jnp.asarray(x)\n",
    "#     coeffs = jnp.asarray(coeffs)\n",
    "#     degree = degree or len(coeffs) - 1\n",
    "#     p = jnp.zeros_like(x)\n",
    "#     for i in range(degree+1):\n",
    "#         x_i = x ** i\n",
    "#         # Compute the scalar function and its gradient\n",
    "#         p += coeffs[i] * x_i * (i % 2 + 1)\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs, degree):\n",
    "#     coeffs = jnp.asarray(coeffs)\n",
    "#     p = jnp.zeros_like(x)\n",
    "#     for i in range(degree+1):\n",
    "#         x_i = x ** i\n",
    "#         # Compute the scalar function and its gradient\n",
    "#         p_i, _ = jax.vmap(jax.value_and_grad(legendre))(i, x)\n",
    "#         p += coeffs[i] * p_i * x_i\n",
    "#     return p\n",
    "\n",
    "# def legendre(i, x):\n",
    "#     if i == 0:\n",
    "#         return jnp.ones_like(x)\n",
    "#     elif i == 1:\n",
    "#         return x\n",
    "#     else:\n",
    "#         return ((2 * i - 1) * x * legendre(i - 1, x) -\n",
    "#                 (i - 1) * legendre(i - 2, x)) / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def eval_legendre(x, coeffs, degree):\n",
    "#     coeffs = jnp.asarray(coeffs)\n",
    "#     p = jnp.zeros_like(x)\n",
    "#     for i in range(degree):\n",
    "#         x_i = x ** i\n",
    "#         # Compute the scalar function and its gradient\n",
    "#         p += coeffs[i] * x_i * (i + 0.5) / jnp.sqrt(1 - x ** 2)\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs, degree):\n",
    "#     \"\"\"\n",
    "#     Evaluate the Legendre series with given coefficients and degree at the points `x`.\n",
    "\n",
    "#     Args:\n",
    "#     x: array_like, shape (n_samples,), the input values to evaluate the Legendre series.\n",
    "#     coeffs: array_like, shape (degree+1,), the coefficients of the Legendre series.\n",
    "#     degree: int, the degree of the Legendre series.\n",
    "\n",
    "#     Returns:\n",
    "#     An array of shape (n_samples,) with the evaluation of the Legendre series at the points `x`.\n",
    "#     \"\"\"\n",
    "#     p = jnp.zeros((degree+1, len(x)))\n",
    "#     p = jnp.expand_dims(p[0], axis=0) + coeffs[1] * jnp.expand_dims(p[1], axis=0)\n",
    "#     for i in range(2, degree+1):\n",
    "#         p_next = ((2*i-1)/i)*coeffs[i]*p[-1] - ((i-1)/i)*p[-2]\n",
    "#         p = jnp.concatenate([p, jnp.expand_dims(p_next, axis=0)])\n",
    "#     return p[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def eval_legendre(x, coeffs, degree):\n",
    "#     n = degree\n",
    "#     p0 = jnp.ones_like(x)\n",
    "#     p1 = x\n",
    "#     if n == 0:\n",
    "#         return coeffs[0] * p0\n",
    "#     elif n == 1:\n",
    "#         return coeffs[:2] @ jnp.stack((p0, p1))\n",
    "#     else:\n",
    "#         coeffs = coeffs[:n+1]\n",
    "#         pn = 0\n",
    "#         pn_minus_1 = p1\n",
    "#         for k in range(1, n):\n",
    "#             pn = ((2 * k + 1) * x * pn_minus_1 - k * p0) / (k + 1)\n",
    "#             p0 = pn_minus_1\n",
    "#             pn_minus_1 = pn\n",
    "#         pn = ((2 * n + 1) * x * pn_minus_1 - n * p0) / (n + 1)\n",
    "#         return jnp.dot(coeffs, jnp.vstack([p0, pn_minus_1, pn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(x, coeffs, degree):\n",
    "#     \"\"\"Evaluate Legendre series with coefficients `coeffs` up to order `degree` at locations `x`.\"\"\"\n",
    "#     def legendre_poly(n):\n",
    "#         if n == 0:\n",
    "#             return jnp.ones_like(x)\n",
    "#         elif n == 1:\n",
    "#             return x\n",
    "#         else:\n",
    "#             return ((2 * n - 1) * x * legendre_poly(n - 1) - (n - 1) * legendre_poly(n - 2)) / n\n",
    "#     legendre_vec = jax.vmap(legendre_poly, (None,), 0)\n",
    "#     return jnp.sum(coeffs[:degree+1] * legendre_vec(jnp.arange(degree+1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(p, x):\n",
    "#     n = p.shape[0]\n",
    "#     x = x[..., None]\n",
    "#     ap = _gen_associated_legendre(p, p, x)\n",
    "#     bp = jax.lax.select(jax.numpy.mod(p, 2) == 0, 1.0, x)\n",
    "#     cp = jax.numpy.sqrt(jax.lax.select(x < -0.5, -1.0, 1.0))\n",
    "#     return ap[..., n-1] * cp * bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(p, x):\n",
    "#     p = jnp.asarray(p)\n",
    "#     n = p.shape[0]\n",
    "#     x = x[..., None]\n",
    "#     ap = _gen_associated_legendre(p, p, x)\n",
    "#     bp = jnp.where(jnp.mod(p, 2) == 0, 1.0, x)\n",
    "#     cp = jnp.sqrt(jnp.where(x < -0.5, -1.0, 1.0))\n",
    "#     return ap[..., n-1] * cp * bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(n, x):\n",
    "#     \"\"\"\n",
    "#     Evaluate Legendre polynomial of degree n at x using the SciPy implementation.\n",
    "\n",
    "#     Args:\n",
    "#     - n: integer degree of the polynomial\n",
    "#     - x: float point(s) at which to evaluate the polynomial\n",
    "\n",
    "#     Returns:\n",
    "#     - y: float the value(s) of the Legendre polynomial\n",
    "#     \"\"\"\n",
    "#     # ensure x is an array\n",
    "#     x = jnp.array(x)\n",
    "\n",
    "#     # set l_max equal to n\n",
    "#     l_max = n\n",
    "\n",
    "#     # evaluate the associated Legendre functions\n",
    "#     is_normalized = False\n",
    "#     Plm = _gen_associated_legendre(l_max, x, is_normalized)\n",
    "\n",
    "#     # extract the column corresponding to degree n\n",
    "#     Pn = Plm[n, :, jnp.newaxis]\n",
    "\n",
    "#     # scale the result by the normalization factor and remove the first\n",
    "#     # coefficient, which is zero\n",
    "#     Nn = jnp.sqrt((2 * n + 1) / 2)\n",
    "#     Pn = Nn * Pn[1:]\n",
    "\n",
    "#     return Pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_legendre_x(n, x):\n",
    "    \"\"\"\n",
    "    Evaluate Legendre polynomial of degree n at x using the SciPy implementation.\n",
    "\n",
    "    Args:\n",
    "    - n: integer degree of the polynomial\n",
    "    - x: float point(s) at which to evaluate the polynomial\n",
    "\n",
    "    Returns:\n",
    "    - y: float the value(s) of the Legendre polynomial\n",
    "    \"\"\"\n",
    "    # ensure x is an array\n",
    "    x = jnp.array(x)\n",
    "\n",
    "    # set l_max equal to n\n",
    "    l_max = n\n",
    "\n",
    "    # evaluate the associated Legendre functions\n",
    "    is_normalized = False\n",
    "    Plm = _gen_associated_legendre(l_max, x, is_normalized)\n",
    "\n",
    "    # extract the column corresponding to degree n\n",
    "    Pn = Plm[n, :]\n",
    "\n",
    "    # scale the result by the normalization factor and remove the first\n",
    "    # coefficient, which is zero\n",
    "    Nn = jnp.sqrt((2 * n + 1) / 2)\n",
    "    Pn = Nn * Pn[1:]\n",
    "\n",
    "    return Pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(n, x):\n",
    "#     \"\"\"\n",
    "#     Evaluate the Legendre polynomials up to order n at the points x.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     n : int\n",
    "#         The highest order of the Legendre polynomial to evaluate.\n",
    "#     x : numpy.ndarray, shape (m,)\n",
    "#         The points at which to evaluate the Legendre polynomials.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     y : numpy.ndarray, shape (n+1, m)\n",
    "#         The values of the Legendre polynomials up to order n at the points x.\n",
    "#     \"\"\"\n",
    "#     # Allocate space for output array\n",
    "#     y = np.zeros((n+1, len(x)))\n",
    "\n",
    "#     # Evaluate 0-th order Legendre polynomial\n",
    "#     y[0, :] = 1.0\n",
    "\n",
    "#     # Evaluate 1-st order Legendre polynomial\n",
    "#     if n >= 1:\n",
    "#         y[1, :] = x\n",
    "\n",
    "#     # Evaluate higher order Legendre polynomials using recurrence relation\n",
    "#     for i in range(2, n+1):\n",
    "#         y[i, :] = ((2*i - 1) * x * y[i-1, :] - (i - 1) * y[i-2, :]) / i\n",
    "\n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(n, x):\n",
    "#     if n == 0:\n",
    "#         return np.ones_like(x)\n",
    "#     elif n == 1:\n",
    "#         return np.array([np.ones_like(x), x])\n",
    "#     else:\n",
    "#         # recurrence relation\n",
    "#         L_n_minus_2 = np.ones_like(x)\n",
    "#         L_n_minus_1 = x\n",
    "#         L_n = 0.0\n",
    "#         for i in range(2, n+1):\n",
    "#             L_n = ((2*i-1)/i) * x * L_n_minus_1 - ((i-1)/i) * L_n_minus_2\n",
    "#             L_n_minus_2 = L_n_minus_1\n",
    "#             L_n_minus_1 = L_n\n",
    "#         return L_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_legendre_x(n, x):\n",
    "    if n == 0:\n",
    "        return jnp.ones_like(x)\n",
    "    elif n == 1:\n",
    "        return jnp.vstack((jnp.ones_like(x), x))\n",
    "    else:\n",
    "        L = jnp.zeros((n + 1, len(x)))\n",
    "        L = L.at[0].set(jnp.ones_like(x))\n",
    "        L = L.at[1].set(x)\n",
    "        for i in range(2, n + 1):\n",
    "            L = L.at[i].set(((2 * i - 1) * x * L[i - 1] - (i - 1) * L[i - 2]) / i)\n",
    "        return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypergeometric(a, b, c, z, eps=1e-10):\n",
    "    res = term = jnp.ones_like(z)\n",
    "    n = 0\n",
    "    while jnp.any(jnp.abs(term) > eps):\n",
    "        term *= (a + n) * (b + n) * z / ((c + n) * (n + 1))\n",
    "        res += term\n",
    "        n += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legendre_polynomial(n):\n",
    "    def inner(x):\n",
    "        return hypergeometric(-n, n + 1, 1, (1 - x) / 2)\n",
    "\n",
    "    return jax.vmap(inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(n, x):\n",
    "#     n = jnp.asarray(n)\n",
    "#     x = jnp.asarray(x)\n",
    "#     result = jnp.zeros((n.size, x.size))\n",
    "#     result = result.at[0].set(jnp.ones_like(x))\n",
    "#     if n.size > 1:\n",
    "#         result = result.at[1].set(x)\n",
    "#         for i in range(2, n.max() + 1):\n",
    "#             result = result.at[i].set(((2 * i - 1) * x * result[i - 1] - (i - 1) * result[i - 2]) / i)\n",
    "#     return result[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_legendre_x(n, x):\n",
    "    n = np.asarray(n)\n",
    "    x = np.asarray(x)\n",
    "    if np.isscalar(n):\n",
    "        n = np.array([n])\n",
    "    result = np.zeros((n.size, x.size))\n",
    "    for i, ni in enumerate(n):\n",
    "        if ni == 0:\n",
    "            result[i] = np.ones_like(x)\n",
    "        elif ni == 1:\n",
    "            result[i] = np.vstack((np.ones_like(x), x))\n",
    "        else:\n",
    "            L = np.zeros((ni + 1, len(x)))\n",
    "            L[0] = np.ones_like(x)\n",
    "            L[1] = x\n",
    "            for j in range(2, ni + 1):\n",
    "                L[j] = ((2 * j - 1) * x * L[j - 1] - (j - 1) * L[j - 2]) / j\n",
    "            result[i] = L[-1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(n, x):\n",
    "#     n = jnp.asarray(n)\n",
    "#     x = jnp.asarray(x)\n",
    "#     if jnp.isscalar(n):\n",
    "#         n = jnp.array([n])\n",
    "#     result = jnp.zeros((n.size, x.size))\n",
    "#     for i, ni in enumerate(n):\n",
    "#         if ni == 0:\n",
    "#             result = result.at[i].set(jnp.ones_like(x))\n",
    "#         elif ni == 1:\n",
    "#             result = result.at[i].set(jnp.vstack((jnp.ones_like(x), x)))\n",
    "#         else:\n",
    "#             L = jnp.zeros((ni + 1, len(x)))\n",
    "#             L = jax.ops.index_update(L, 0, jnp.ones_like(x))\n",
    "#             L = jax.ops.index_update(L, 1, x)\n",
    "#             for j in range(2, ni + 1):\n",
    "#                 L = jax.ops.index_update(L, j, ((2 * j - 1) * x * L[j - 1] - (j - 1) * L[j - 2]) / j)\n",
    "#             result = jax.ops.index_update(result, i, L[-1])\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(n, x):\n",
    "#     result = jnp.zeros((len(n), len(x)))\n",
    "#     print(f\"result {result}\")\n",
    "#     print(f\"result.shape {result.shape}\")\n",
    "\n",
    "#     for i, ni in enumerate(n):\n",
    "#         ni_val = int(ni)\n",
    "#         print(f\"ni_val {ni_val}\")\n",
    "#         if ni_val == 0:\n",
    "#             result = result.at[i].set(jnp.ones_like(x))\n",
    "#             print(f\"when ni_val == 0, result {result}\")\n",
    "#             print(f\"when ni_val == 0, result.shape {result.shape}\")\n",
    "#         elif ni_val == 1:\n",
    "#             ones = jnp.ones_like(x)[jnp.newaxis, :]\n",
    "#             print(f\"when ni_val == 0, ones {ones}\")\n",
    "#             print(f\"when ni_val == 0, ones.shape {ones.shape}\")\n",
    "#             xs = x.reshape((1, -1))\n",
    "#             print(f\"when ni_val == 0, xs {xs}\")\n",
    "#             print(f\"when ni_val == 0, xs.shape {xs.shape}\")\n",
    "#             result = result.at[i].set(jnp.vstack([ones, xs]))\n",
    "#             print(f\"when ni_val == 1, result {result}\")\n",
    "#             print(f\"when ni_val == 1, result.shape {result.shape}\")\n",
    "#         else:\n",
    "#             L = jnp.zeros((ni_val + 1, len(x)))\n",
    "#             L = L.at[0].set(jnp.ones_like(x))\n",
    "#             L = L.at[1].set(x)\n",
    "#             print(f\"else, before for-loop, L {L}\")\n",
    "#             print(f\"else, before for-loop, L shape {L.shape}\")\n",
    "#             for j in range(1, ni_val):\n",
    "#                 L = L.at[j + 1].set(((2*j + 1) * x * L[j] - j * L[j-1]) / (j+1))\n",
    "#                 print(f\"else, inside for-loop, L {L}\")\n",
    "#                 print(f\"else, inside for-loop, L shape {L.shape}\")\n",
    "#             result = result.at[i].set(L[ni_val])\n",
    "#             print(f\"else, result {result}\")\n",
    "#             print(f\"else, result.shape {result.shape}\")\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(n, x):\n",
    "#     result = jnp.zeros((len(n), len(x)))\n",
    "#     print(f\"result {result}\")\n",
    "#     print(f\"result.shape {result.shape}\")\n",
    "\n",
    "#     for i, ni in enumerate(n):\n",
    "#         ni_val = int(ni)\n",
    "#         print(f\"ni_val {ni_val}\")\n",
    "#         if ni_val == 0:\n",
    "#             result = result.at[i].set(jnp.ones_like(x))\n",
    "#             print(f\"when ni_val == 0, result {result}\")\n",
    "#             print(f\"when ni_val == 0, result.shape {result.shape}\")\n",
    "#         elif ni_val == 1:\n",
    "#             ones = jnp.ones_like(x)[jnp.newaxis, :]\n",
    "#             print(f\"when ni_val == 1, ones {ones}\")\n",
    "#             print(f\"when ni_val == 1, ones.shape {ones.shape}\")\n",
    "#             xs = x.reshape((1, -1))\n",
    "#             print(f\"when ni_val == 1, xs {xs}\")\n",
    "#             print(f\"when ni_val == 1, xs.shape {xs.shape}\")\n",
    "#             result = result.at[i].set(jnp.vstack([ones, xs]))\n",
    "#             print(f\"when ni_val == 1, result {result}\")\n",
    "#             print(f\"when ni_val == 1, result.shape {result.shape}\")\n",
    "#         else:\n",
    "#             L = jnp.zeros((ni_val + 1, len(x)))\n",
    "#             L = L.at[0].set(jnp.ones_like(x))\n",
    "#             L = L.at[1].set(x)\n",
    "#             print(f\"else, before for-loop, L {L}\")\n",
    "#             print(f\"else, before for-loop, L shape {L.shape}\")\n",
    "#             for j in range(1, ni_val):\n",
    "#                 L = L.at[j + 1].set(((2 * j + 1) * x * L[j] - j * L[j - 1]) / (j + 1))\n",
    "#                 print(f\"else, inside for-loop, L {L}\")\n",
    "#                 print(f\"else, inside for-loop, L shape {L.shape}\")\n",
    "#             result = result.at[i].set(jnp.expand_dims(L[ni_val], axis=0))\n",
    "#             print(f\"else, result {result}\")\n",
    "#             print(f\"else, result.shape {result.shape}\")\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_legendre(n, x):\n",
    "#     L0 = jnp.ones_like(x)\n",
    "#     L1 = x\n",
    "#     L = jnp.where(n==0, L0, L1)\n",
    "#     L = jnp.where(n==1, jnp.vstack((L0, L1)), L)\n",
    "\n",
    "#     for i in range(2, n+1):\n",
    "#         L = jnp.where(i==n, ((2*i-1)*x*L - (i-1)*L[:-2]) / i, L)\n",
    "\n",
    "#     return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     # Define test inputs\n",
    "#     coeffs = jnp.array([1, 2, 3], dtype=jnp.float64)\n",
    "#     x = jnp.linspace(-1, 1, 11, dtype=jnp.float64)\n",
    "\n",
    "#     # Compute outputs using JAX\n",
    "#     jax_result = eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compute expected outputs using SciPy\n",
    "#     scipy_result = ss.eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compare results\n",
    "#     assert jnp.allclose(jax_result, scipy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     coeffs = jnp.array([1, 2, 3], dtype=jnp.float64)\n",
    "#     x = jnp.linspace(-1, 1, 11, dtype=jnp.float64)\n",
    "\n",
    "#     # Compute outputs using JAX\n",
    "#     jax_result = eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compute expected outputs using SciPy\n",
    "#     scipy_result = ss.eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compare results\n",
    "#     assert jnp.allclose(jax_result, scipy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the function\n",
    "# def test_eval_legendre():\n",
    "#     coeffs = jnp.array([1, 0, -1], dtype=jnp.float64)\n",
    "#     x = jnp.linspace(-1, 1, 11, dtype=jnp.float64)\n",
    "\n",
    "#     # Compute outputs using JAX\n",
    "#     jax_result = eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compute expected outputs using SciPy\n",
    "#     scipy_result = ss.eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compare results\n",
    "#     assert jnp.allclose(jax_result, scipy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     # Generate input values\n",
    "#     x = jnp.linspace(-1, 1, 11, dtype=jnp.float32)\n",
    "\n",
    "#     # Generate random Legendre polynomial coefficients\n",
    "#     coeffs = jax.random.normal(subkeys[1], shape=(len(x),))\n",
    "\n",
    "#     # Compute outputs using JAX\n",
    "#     jax_result = eval_legendre(x, coeffs)\n",
    "#     # Compute expected outputs using SciPy\n",
    "#     scipy_result = ss.eval_legendre(x, coeffs)\n",
    "#     # Compare JAX and SciPy results\n",
    "#     assert jnp.allclose(jax_result, scipy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "\n",
    "#     # Generate random number of Legendre polynomial coefficients and input values\n",
    "#     num_coeffs = jax.random.randint(subkeys[1], shape=(), minval=1, maxval=10)\n",
    "#     num_vals = jax.random.randint(subkeys[2], shape=(), minval=1, maxval=20)\n",
    "\n",
    "#     # Generate random Legendre polynomial coefficients\n",
    "#     coeffs = jax.random.normal(subkeys[3], shape=(num_coeffs,))\n",
    "\n",
    "#     # Generate input values\n",
    "#     x = jnp.linspace(-1, 1, num_vals, dtype=jnp.float64)\n",
    "\n",
    "#     # Compute JAX outputs\n",
    "#     jax_result = eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compute expected outputs using SciPy\n",
    "#     scipy_result = ss.eval_legendre(jnp.arange(num_coeffs), x) @ coeffs\n",
    "\n",
    "#     print(jax_result.shape, scipy_result.shape)\n",
    "\n",
    "#     # Compare JAX and SciPy results\n",
    "#     assert jnp.allclose(jax_result, scipy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     key = jax.random.PRNGKey(0)\n",
    "\n",
    "#     # Generate random number of Legendre polynomial coefficients and input values\n",
    "#     num_coeffs = jax.random.randint(key, shape=(), minval=1, maxval=10)\n",
    "#     num_vals = jax.random.randint(key, shape=(), minval=1, maxval=20)\n",
    "\n",
    "#     # Generate random Legendre polynomial coefficients\n",
    "#     coeffs = jax.random.normal(key, shape=(num_coeffs,))\n",
    "\n",
    "#     # Generate input values\n",
    "#     x = jnp.linspace(-1, 1, num_vals, dtype=jnp.float64)\n",
    "\n",
    "#     # Compute expected outputs using NumPy/SciPy\n",
    "#     expected_result = ss.eval_legendre(jnp.arange(num_coeffs), x) @ coeffs\n",
    "\n",
    "#     # Compute actual outputs using your function\n",
    "#     actual_result = eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compare expected and actual results using allclose with a tolerance of 1e-12\n",
    "#     assert jnp.allclose(actual_result, expected_result, rtol=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "\n",
    "#     # Generate random maximum degree of the polynomial and number of input values\n",
    "#     degree = jax.random.randint(subkeys[1], shape=(), minval=1, maxval=10)\n",
    "#     num_vals = jax.random.randint(subkeys[2], shape=(), minval=1, maxval=20)\n",
    "\n",
    "#     # Generate random Legendre polynomial coefficients\n",
    "#     coeffs = jax.random.normal(subkeys[3], shape=(degree+1,))\n",
    "\n",
    "#     # Generate input values\n",
    "#     x = jnp.linspace(-1, 1, num_vals, dtype=jnp.float64)\n",
    "\n",
    "#     # Compute expected outputs using NumPy/SciPy\n",
    "#     expected_result = ss.eval_legendre(jnp.arange(degree+1), x) @ coeffs\n",
    "\n",
    "#     # Compute actual outputs using your function\n",
    "#     actual_result = eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compare actual and expected results\n",
    "#     assert jnp.allclose(actual_result, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "\n",
    "#     # Generate random maximum degree of the polynomial and number of input values\n",
    "#     degree = jax.random.randint(subkeys[1], shape=(), minval=1, maxval=10)\n",
    "#     num_vals = jax.random.randint(subkeys[2], shape=(), minval=1, maxval=20)\n",
    "\n",
    "#     # Generate random Legendre polynomial coefficients\n",
    "#     coeffs = jax.random.normal(subkeys[3], shape=(degree+1,))\n",
    "\n",
    "#     # Generate input values\n",
    "#     x = jnp.linspace(-1, 1, num_vals, dtype=jnp.float64)\n",
    "\n",
    "#     # Compute expected outputs using NumPy/SciPy\n",
    "#     expected_result = jnp.zeros_like(x)\n",
    "#     for i in range(x.size):\n",
    "#         p = ss.eval_legendre(jnp.arange(coeffs.size), x[i])\n",
    "#         expected_result[i] = jnp.dot(p, coeffs)\n",
    "\n",
    "#     # Compute actual outputs using your function\n",
    "#     actual_result = eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compare actual and expected results\n",
    "#     assert jnp.allclose(actual_result, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "\n",
    "#     # Generate random maximum degree of the polynomial and number of input values\n",
    "#     degree = jax.random.randint(subkeys[1], shape=(), minval=1, maxval=10)\n",
    "#     num_vals = jax.random.randint(subkeys[2], shape=(), minval=1, maxval=20)\n",
    "\n",
    "#     # Generate random Legendre polynomial coefficients\n",
    "#     coeffs = jax.random.normal(subkeys[3], shape=(degree+1,))\n",
    "\n",
    "#     # Generate input values\n",
    "#     x = jnp.linspace(-1, 1, num_vals, dtype=jnp.float64)\n",
    "\n",
    "#     # Compute expected outputs using NumPy/SciPy\n",
    "#     expected_result = jnp.zeros(num_vals)\n",
    "#     for i in range(x.size):\n",
    "#         p = ss.eval_legendre(jnp.arange(coeffs.size), x[i])\n",
    "#         expected_result = expected_result.at[i].set(jnp.dot(p, coeffs))\n",
    "\n",
    "#     # Compute actual outputs using your function\n",
    "#     actual_result = eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compare actual and expected results\n",
    "#     assert jnp.allclose(actual_result, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "\n",
    "#     # Generate random maximum degree of the polynomial and number of input values\n",
    "#     degree = jax.random.randint(subkeys[1], shape=(), minval=1, maxval=10)\n",
    "#     num_vals = jax.random.randint(subkeys[2], shape=(), minval=1, maxval=20)\n",
    "\n",
    "#     # Generate random Legendre polynomial coefficients\n",
    "#     coeffs = jax.random.normal(subkeys[3], shape=(degree+1,))\n",
    "\n",
    "#     # Generate input values\n",
    "#     x = jnp.linspace(-1, 1, num_vals, dtype=jnp.float64)\n",
    "\n",
    "#     # Compute expected outputs using NumPy/SciPy\n",
    "#     expected_result = ss.eval_legendre(jnp.arange(degree+1), x) @ coeffs\n",
    "\n",
    "#     # Compute actual outputs using your function\n",
    "#     actual_result = eval_legendre(x, coeffs)\n",
    "\n",
    "#     # Compare actual and expected results\n",
    "#     assert jnp.allclose(actual_result, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     x = jnp.array([-0.5, 0.0, 0.5, 1.0])\n",
    "#     degree = 3\n",
    "#     coeffs = jnp.array([1.0, 0.0, -0.5, 0.0])\n",
    "\n",
    "#     expected_result = ss.eval_legendre(jnp.arange(degree+1), x) @ coeffs\n",
    "\n",
    "#     actual_result = eval_legendre(x, coeffs, degree)\n",
    "\n",
    "#     assert jnp.allclose(actual_result, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     degree = 3\n",
    "#     x = jnp.linspace(-1, 1, 100)\n",
    "#     coeffs = jnp.array([1.0, 0.0, -0.5, 0.0])\n",
    "#     expected_result = ss.eval_legendre(jnp.arange(degree+1), x).T @ coeffs\n",
    "#     actual_result = eval_legendre(x, coeffs, degree)\n",
    "#     assert jnp.allclose(actual_result, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     x = jnp.linspace(-1, 1, 100)\n",
    "#     degree = 3\n",
    "#     coeffs = jnp.array([1.0, 0.0, -0.5, 0.0])\n",
    "#     expected_result = ss.eval_legendre(jnp.arange(degree+1), x) @ coeffs.T\n",
    "#     actual_result = eval_legendre(x, coeffs, degree)\n",
    "#     assert jnp.allclose(actual_result, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     degree = 3\n",
    "#     x = jnp.linspace(-1, 1, 100)\n",
    "#     coeffs = jnp.array([1.0, 0.0, -0.5, 0.0])\n",
    "#     expected_result = ss.eval_legendre(jnp.arange(degree+1), x) @ coeffs\n",
    "#     actual_result = eval_legendre(x, coeffs, degree)\n",
    "#     assert jnp.allclose(actual_result, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     degree = 3\n",
    "#     x = jnp.linspace(-1, 1, 100)\n",
    "#     coeffs = jnp.array([1.0, 0.0, -0.5, 0.0])\n",
    "#     expected_result = ss.eval_legendre(jnp.arange(degree+1), x).T @ coeffs[:degree+1]\n",
    "#     actual_result = eval_legendre(x, coeffs, degree)\n",
    "#     assert jnp.allclose(actual_result, expected_result)\n",
    "#     print(\"Test passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     x = jnp.linspace(-1, 1, 100)\n",
    "#     degree = 3\n",
    "#     coeffs = jnp.array([1.0, 0.0, -0.5, 0.0])\n",
    "#     expected_result = ss.eval_legendre(jnp.arange(degree+1), x)\n",
    "#     actual_result = eval_legendre(x, coeffs, degree)\n",
    "#     assert jnp.allclose(actual_result, expected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     # Test case\n",
    "#     p = np.array([0, 1, 2, 3])\n",
    "#     x = np.array([-1, -0.5, 0, 0.5, 1])\n",
    "#     actual_output = eval_legendre(p, x)\n",
    "#     expected_output = ss.eval_legendre(p, x)\n",
    "#     assert np.allclose(expected_output, actual_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     # Test case\n",
    "#     x = np.linspace(-1, 1, 10)\n",
    "#     for n in range(5):\n",
    "#         y_pred = eval_legendre(n, x)\n",
    "#         y = ss.eval_legendre(n, x)\n",
    "#         print(f\"n = {n},\\ny_pred = {y_pred},\\ny = {y}\")\n",
    "#         assert np.allclose(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     # Test case\n",
    "#     x = np.linspace(-1, 1, 10)\n",
    "#     for n in range(5):\n",
    "#         y_pred = eval_legendre(n, x)\n",
    "#         y = ss.eval_legendre(n, x)\n",
    "#         print(f\"n = {n},\\ny_pred = {y_pred},\\ny = {y}\")\n",
    "#         assert np.allclose(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     x = np.linspace(-1, 1, 10)\n",
    "#     for n in range(5):\n",
    "#         y = jnp.array(ss.eval_legendre(n, x))\n",
    "#         y_pred = eval_legendre(n, jnp.array(x))[n]\n",
    "#         print(f\"n = {n}\")\n",
    "#         print(f\"y_pred = {y_pred}\")\n",
    "#         print(f\"y_pred shape = {y_pred.shape}\")\n",
    "#         print(f\"y = {y}\")\n",
    "#         print(f\"y shape = {y.shape}\")\n",
    "#         assert jnp.allclose(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     x = jax.random.uniform(subkeys[1], shape=(10,))\n",
    "#     n = jax.random.randint(subkeys[2], minval=0, maxval=10, shape=(10,))\n",
    "#     y = ss.eval_legendre(n, x)\n",
    "#     y_pred = eval_legendre(n, x)\n",
    "\n",
    "#     print(f\"y_pred = {y_pred}\")\n",
    "#     print(f\"y_pred shape = {y_pred.shape}\")\n",
    "#     print(f\"y = {y}\")\n",
    "#     print(f\"y shape = {y.shape}\")\n",
    "\n",
    "#     assert jnp.allclose(y_pred, y, rtol=1e-4, atol=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     subkeys = jax.random.split(jax.random.PRNGKey(0), 3)\n",
    "#     x = jax.random.uniform(subkeys[1], shape=(10,))\n",
    "#     n = jax.random.randint(subkeys[2], minval=0, maxval=10, shape=(10,))\n",
    "#     y = ss.eval_legendre(n, x)\n",
    "#     y_pred = eval_legendre(n, x)\n",
    "#     print(f\"y_pred = {y_pred}\")\n",
    "#     print(f\"y_pred shape = {y_pred.shape}\")\n",
    "#     print(f\"y = {y}\")\n",
    "#     print(f\"y shape = {y.shape}\")\n",
    "#     assert jnp.allclose(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_legendre_real(n, x):\n",
    "    jax.debug.print(\"n: {x1}\", x1=n)\n",
    "    jax.debug.print(\"x: {x2}\", x2=x)\n",
    "\n",
    "    def cond_one(x):\n",
    "        return jnp.ones_like(x)\n",
    "\n",
    "    def cond_two(x):\n",
    "        return jnp.vstack((jnp.ones_like(x), x))\n",
    "\n",
    "    def cond_three(n, x):\n",
    "        L = jnp.zeros((n + 1, len(x)))\n",
    "        L = L.at[0].set(jnp.ones_like(x))\n",
    "        L = L.at[1].set(x)\n",
    "        for i in range(2, n + 1):\n",
    "            L = L.at[i].set(((2 * i - 1) * x * L[i - 1] - (i - 1) * L[i - 2]) / i)\n",
    "        return L\n",
    "\n",
    "    return jax.lax.cond(\n",
    "        n == 0,\n",
    "        cond_one,\n",
    "        jax.lax.cond(n == 1, cond_two, cond_three, operand=(n, x)),\n",
    "        operand=x,\n",
    "    )\n",
    "    # val = None\n",
    "    # if n == 0:\n",
    "    #     val = jnp.ones_like(x)\n",
    "    # elif n == 1:\n",
    "    #     val = jnp.vstack((jnp.ones_like(x), x))\n",
    "    # else:\n",
    "    #     L = jnp.zeros((n + 1, len(x)))\n",
    "    #     L = L.at[0].set(jnp.ones_like(x))\n",
    "    #     L = L.at[1].set(x)\n",
    "    #     for i in range(2, n + 1):\n",
    "    #         L = L.at[i].set(((2 * i - 1) * x * L[i - 1] - (i - 1) * L[i - 2]) / i)\n",
    "    #     val = L\n",
    "    # return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval_legendre():\n",
    "    n = np.array([0, 1, 2, 3])\n",
    "    x = np.linspace(-1, 1, n.shape[0])\n",
    "\n",
    "    print(f\"x = {x}\")\n",
    "    print(f\"x shape = {x.shape}\")\n",
    "    print(f\"n = {n}\")\n",
    "    print(f\"n shape = {n.shape}\")\n",
    "\n",
    "    y = ss.eval_legendre(n, x)\n",
    "\n",
    "    print(f\"y = {y}\")\n",
    "    print(f\"y shape = {y.shape}\")\n",
    "\n",
    "    y_pred = jax.vmap(eval_legendre_real, in_axes=(0, None))(n, x)\n",
    "\n",
    "    print(f\"y_pred = {y_pred}\")\n",
    "    print(f\"y_pred shape = {y_pred.shape}\")\n",
    "\n",
    "    assert np.allclose(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_eval_legendre():\n",
    "#     x = np.linspace(-1, 1, 10)\n",
    "#     for n in range(5):\n",
    "#         y = ss.eval_legendre(n, x)\n",
    "#         y_pred = eval_legendre(n, x)\n",
    "#         print(f\"n = {n}\")\n",
    "#         print(f\"y_pred = {y_pred}\")\n",
    "#         print(f\"y_pred shape = {y_pred.shape}\")\n",
    "#         print(f\"y = {y}\")\n",
    "#         print(f\"y shape = {y.shape}\")\n",
    "#         assert np.allclose(y_pred, y.reshape((-1, y_pred.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [-1.         -0.33333333  0.33333333  1.        ]\n",
      "x shape = (4,)\n",
      "n = [0 1 2 3]\n",
      "n shape = (4,)\n",
      "y = [ 1.         -0.33333333 -0.33333333  1.        ]\n",
      "y shape = (4,)\n",
      "n: 0\n",
      "n: 1\n",
      "n: 2\n",
      "n: 3\n",
      "x: [-1.         -0.33333333  0.33333333  1.        ]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "lax.cond: true_fun and false_fun arguments should be callable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_eval_legendre\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[76], line 15\u001b[0m, in \u001b[0;36mtest_eval_legendre\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my shape = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_legendre_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred shape = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[75], line 22\u001b[0m, in \u001b[0;36meval_legendre_real\u001b[0;34m(n, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         L \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mat[i]\u001b[38;5;241m.\u001b[39mset(((\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m*\u001b[39m L[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m (i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m L[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m/\u001b[39m i)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m L\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mcond(\n\u001b[1;32m     20\u001b[0m     n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     21\u001b[0m     cond_one,\n\u001b[0;32m---> 22\u001b[0m     \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_two\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond_three\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     23\u001b[0m     operand\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m     24\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/s4mer-pkg-rmt3vFtN-py3.8/lib/python3.8/site-packages/jax/_src/lax/control_flow/conditionals.py:193\u001b[0m, in \u001b[0;36m_cond\u001b[0;34m(pred, true_fun, false_fun, operand, linear, *operands)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Conditionally apply ``true_fun`` or ``false_fun``.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[39mWraps XLA's `Conditional\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39m  pytree (nested Python tuple/list/dict) thereof.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (callable(true_fun) \u001b[39mand\u001b[39;00m callable(false_fun)):\n\u001b[0;32m--> 193\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlax.cond: true_fun and false_fun arguments should be callable.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m operand \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _no_operand_sentinel:\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m operands:\n",
      "\u001b[0;31mTypeError\u001b[0m: lax.cond: true_fun and false_fun arguments should be callable."
     ]
    }
   ],
   "source": [
    "test_eval_legendre()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('s4mer-pkg-rmt3vFtN-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "616abfd6b1e11a599364f0d5228ada514baf1d2a8611f9274dc002b78190c46b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
