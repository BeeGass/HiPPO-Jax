{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiPPO Operator Minimal Test\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_path: /home/beegass/Documents/Coding/HiPPO-Jax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../../\"))\n",
    "print(f\"module_path: {module_path}\")\n",
    "if module_path not in sys.path:\n",
    "    print(f\"Adding {module_path} to sys.path\")\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"False\"\n",
    "os.environ[\"TF_FORCE_UNIFIED_MEMORY\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beegass/.cache/pypoetry/virtualenvs/hippo-pkg-Uqb72G6k-py3.8/lib/python3.8/site-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
      "/home/beegass/.cache/pypoetry/virtualenvs/hippo-pkg-Uqb72G6k-py3.8/lib/python3.8/site-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(data_clz, keypaths)\n"
     ]
    }
   ],
   "source": [
    "## import packages\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import einops\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from jax import random\n",
    "import flax.linen as nn\n",
    "from jaxtyping import Array, Float\n",
    "from scipy import special as ss\n",
    "from typing import Any, Callable, List, Optional, Tuple, Union\n",
    "\n",
    "KeyArray = random.KeyArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n",
      "The Device: gpu\n"
     ]
    }
   ],
   "source": [
    "print(jax.devices())\n",
    "print(f\"The Device: {jax.lib.xla_bridge.get_backend().platform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS enabled: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"MPS enabled: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=150)\n",
    "np.set_printoptions(linewidth=150)\n",
    "jnp.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1701\n",
    "key = jax.random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_copies = 10\n",
    "subkeys = jax.random.split(key, num=num_copies)\n",
    "key = subkeys[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitesignal(key, period, dt, freq, rms=0.5, batch_shape=()):\n",
    "    \"\"\"\n",
    "    Produces output signal of length period / dt, band-limited to frequency freq\n",
    "    Output shape (*batch_shape, period/dt)\n",
    "    Adapted from the nengo library\n",
    "    \"\"\"\n",
    "\n",
    "    if freq is not None and freq < 1.0 / period:\n",
    "        raise ValueError(\n",
    "            f\"Make ``{freq=} >= 1. / {period=}`` to produce a non-zero signal\",\n",
    "        )\n",
    "\n",
    "    nyquist_cutoff = 0.5 / dt\n",
    "    if freq > nyquist_cutoff:\n",
    "        raise ValueError(\n",
    "            f\"{freq} must not exceed the Nyquist frequency for the given dt ({nyquist_cutoff:0.3f})\"\n",
    "        )\n",
    "\n",
    "    n_coefficients = int(jnp.ceil(period / dt / 2.0))\n",
    "    shape = batch_shape + (n_coefficients + 1,)\n",
    "    sigma = rms * jnp.sqrt(0.5)\n",
    "    coefficients = 1j * jax.random.normal(key, shape) * sigma\n",
    "    coefficients = jnp.array(coefficients)\n",
    "    coefficients = coefficients.at[..., -1].set(0.0)\n",
    "    coefficients += jax.random.normal(key, shape) * sigma\n",
    "    coefficients = jnp.array(coefficients)\n",
    "    coefficients = coefficients.at[..., 0].set(0.0)\n",
    "\n",
    "    set_to_zero = jnp.fft.rfftfreq(2 * n_coefficients, d=dt) > freq\n",
    "    coefficients *= 1 - set_to_zero\n",
    "    power_correction = jnp.sqrt(\n",
    "        1.0 - jnp.sum(set_to_zero, dtype=jnp.float32) / n_coefficients\n",
    "    )\n",
    "    if power_correction > 0.0:\n",
    "        coefficients /= power_correction\n",
    "    coefficients *= jnp.sqrt(2 * n_coefficients)\n",
    "    signal = jnp.fft.irfft(coefficients, axis=-1)\n",
    "    signal = signal - signal[..., :1]  # Start from 0\n",
    "    return signal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HiPPO Intializers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPOInitializer(jax.nn.initializers.Initializer):\n",
    "    \"\"\"Base class for HiPPO initializers.\"\"\"\n",
    "\n",
    "    def __call__(self, key: jnp.ndarray, shape: tuple, dtype: Any = jnp.float32):\n",
    "        raise NotImplementedError(\"HiPPOInitializer must implement __call__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegSInitializer(HiPPOInitializer):\n",
    "    \"\"\"Initializer for the Scaled Legendre basis.\"\"\"\n",
    "\n",
    "    def __name__(self) -> str:\n",
    "        return \"legs\"\n",
    "\n",
    "    def __call__(\n",
    "        self, key: KeyArray, shape: tuple, dtype: Any = jnp.float32\n",
    "    ) -> Tuple[Float[Array, \"N N\"], Float[Array, \"N 1\"]]:\n",
    "        assert (\n",
    "            shape[0] == shape[1] or shape[1] == 1\n",
    "        ), \"LegSInitializer: shape mismatch for square matrix. Got {shape}\"\n",
    "\n",
    "        N = shape[0]\n",
    "        q = jnp.arange(N, dtype=dtype)\n",
    "        k, n = jnp.meshgrid(q, q)\n",
    "        pre_D = jnp.sqrt(jnp.diag(2 * q + 1))\n",
    "        B = D = jnp.diag(pre_D)[:, None]\n",
    "\n",
    "        A_base = jnp.sqrt(2 * n + 1) * jnp.sqrt(2 * k + 1)\n",
    "\n",
    "        A = jnp.where(n > k, A_base, jnp.where(n == k, n + 1, 0.0))\n",
    "\n",
    "        if shape[0] >= 1 and shape[0] == shape[1]:\n",
    "            return -A.astype(dtype)\n",
    "        elif shape[1] == 1:\n",
    "            return B.astype(dtype)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"LegSInitializer: shape mismatch for square matrix. Got {shape}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legs_initializer() -> Callable:\n",
    "    return LegSInitializer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HiPPO Shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPOCell(nn.Module):\n",
    "    @staticmethod\n",
    "    def initialize_state(\n",
    "        rng,\n",
    "        batch_size: int,\n",
    "        hidden_size: int,\n",
    "        init_fn: Callable,\n",
    "    ):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPO(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    Examples:\n",
    "            The matrix_args in the format of:\n",
    "                {N: int,\n",
    "                 measure: str,\n",
    "                 lambda_n: Optional[float],\n",
    "                 alpha: Optional[float], # rotation for lagt\n",
    "                 beta: Optional[float], # rotation for lagt\n",
    "                 dtype: Optional[jnp.dtype]\n",
    "                }\n",
    "\n",
    "            >>> {N:64, measure:\"legs\", lambda_n:1.0, dtype:jnp.float16}\n",
    "            >>> {N:64, measure:\"legt\", lambda_n:2.0, dtype:jnp.float32} # produces LMU\n",
    "            >>> {N:64, measure:\"legt\", lambda_n:1.0, dtype:jnp.float32} # produces LegT\n",
    "            >>> {N:64, measure:\"lagt\", alpha:0.0, beta:1.0, dtype:jnp.float6} # produces LagT\n",
    "            >>> {N:64, measure:\"lagt\", alpha:0.7, beta:1.4, dtype:jnp.float64} # produces a version of a slightly \"rotated\" LagT\n",
    "\n",
    "\n",
    "            HiPPOLSICell, in the format of:\n",
    "                (max_length: int\n",
    "                 alpha: Optional[float], # alpha value for discretization\n",
    "                 measure: Optional[str],\n",
    "                 recon: Optional[bool],\n",
    "                 dtype: Optional[jnp.dtype]\n",
    "                )\n",
    "            >>> {max_length=1024, alpha=0.0, measure=\"legs\", recon=True, dtype=jnp.float16} # produces HiPPOLSICell w/ forward euler discretization, and reconstruction\n",
    "            >>> {max_length=512, alpha=1.0, measure=\"legt\", recon=False, dtype=jnp.float32} # produces HiPPOLSICell w/ backward euler discretization, and no reconstruction\n",
    "            >>> {max_length=256, alpha=0.5, measure=\"fru\", recon=True, dtype=jnp.float32} # produces HiPPOLSICell w/ bilinear transform discretization, and reconstruction\n",
    "            >>> {max_length=512, alpha=2.0, measure=\"fout\", recon=True, dtype=jnp.float32} # produces HiPPOLSICell w/ zero-order hold discretization, and reconstruction\n",
    "\n",
    "            HiPPOLTICell, in the format of:\n",
    "                (step_size: float, # 1 / sequence length\n",
    "                 basis_size: float, # The intended maximum value of the basis function for the coefficients to be projected onto\n",
    "                 alpha: Optional[float], # alpha value for discretization\n",
    "                 recon: Optional[bool],\n",
    "                 measure: Optional[str],\n",
    "                 dtype: Optional[jnp.dtype]\n",
    "                )\n",
    "            >>> {step_size:1e-3, basis_size:1.0, alpha:0.0, recon:True, measure:\"legs\", dtype:jnp.float16} # produces HiPPOLTICell w/ forward euler discretization, and reconstruction, discretized every 1/1000 assuming a sequence length is 1000\n",
    "            >>> {step_size:1e-4, basis_size:1.0, alpha:1.0, recon:True, measure:\"lagt\", dtype:jnp.float32} # produces HiPPOLTICell w/ backward euler discretization, and reconstruction, discretized every 1/10000 assuming a sequence length is 10000\n",
    "            >>> {step_size:1e-2, basis_size:1.0, alpha:2.0, recon:True, measure:\"foud\", dtype:jnp.float64} # produces HiPPOLTICell w/ zero-order hold discretization, and reconstruction, discretized every 1/10000 assuming a sequence length is 100\n",
    "            >>> {step_size:1e-2, basis_size:1.0, alpha:0.5, recon:True, measure:\"fru\", dtype:jnp.float16} # produces HiPPOLTICell w/ bilinear transform discretization, and reconstruction, discretized every 1/10000 assuming a sequence length is 100\n",
    "\n",
    "\n",
    "\n",
    "    Args:\n",
    "        features (int):\n",
    "            The size of the hidden state of the HiPPO model\n",
    "\n",
    "        hippo_cell (HiPPOCell):\n",
    "            The HiPPOCell class to be used for the HiPPO model\n",
    "\n",
    "        hippo_args (dict):\n",
    "            The dict associated with the input parameters into the HiPPOCell class.\n",
    "\n",
    "        matrix_args (dict):\n",
    "            The dict associated with the input parameters into the TransMatrix class.\n",
    "\n",
    "        unroll (bool):\n",
    "            Determines if you wanted the full history (all time steps) of coefficients, and potentially reconstructions. Defaults to False\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Enforces that the inputted cell is a HiPPOCell\n",
    "    \"\"\"\n",
    "\n",
    "    features: int\n",
    "    hippo_cell: HiPPOCell\n",
    "    hippo_args: dict\n",
    "    init_t: int = 0\n",
    "    unroll: bool = False\n",
    "\n",
    "    def setup(self) -> None:\n",
    "\n",
    "        self._hippo = self.hippo_cell(\n",
    "            features=self.features, init_t=self.init_t, **self.hippo_args\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        f: Float[Array, \"#batch seq_len input_size\"],\n",
    "        c_t_1: Float[Array, \"#batch input_size N\"],\n",
    "    ) -> Tuple[\n",
    "        Union[\n",
    "            Float[Array, \"#batch seq_len input_size N\"],\n",
    "            Float[Array, \"#batch input_size N\"],\n",
    "        ],\n",
    "        Union[\n",
    "            Float[Array, \"#batch input_size N\"],\n",
    "            Float[Array, \"#batch seq_len input_size N\"],\n",
    "        ],\n",
    "    ]:\n",
    "\n",
    "        if isinstance(self._hippo, HiPPOLTICell):\n",
    "\n",
    "            def lti_scan_fn(carry, i):\n",
    "                c_tm1, y_t_1 = carry\n",
    "                c_t, y = jax.vmap(self._hippo, in_axes=(0, 0, None))(f, c_tm1, i)\n",
    "                return (c_t, y), (c_t, y)\n",
    "\n",
    "            (c_n, y_n), (c_s, y_s) = jax.lax.scan(\n",
    "                f=lti_scan_fn,\n",
    "                init=(c_t_1, jnp.ones(f.shape)),\n",
    "                xs=(jnp.arange(f.shape[1] - self.init_t) + 1),\n",
    "            )\n",
    "\n",
    "            if self.unroll:\n",
    "                return c_s, y_s\n",
    "\n",
    "            else:\n",
    "                return c_n, y_n\n",
    "\n",
    "        # elif isinstance(self._hippo, HiPPOLSICell):\n",
    "\n",
    "        #     def lsi_scan_fn(carry, i):\n",
    "        #         c_tm1, y_t_1 = carry\n",
    "        #         c_t, y = jax.vmap(self._hippo, in_axes=(0, 0, None))(f, c_tm1, i)\n",
    "        #         return (c_t, y), (c_t, y)\n",
    "\n",
    "        #     (c_n, y_n), (c_s, y_s) = jax.lax.scan(\n",
    "        #         f=lsi_scan_fn,\n",
    "        #         init=(c_t_1, jnp.ones(f.shape)),\n",
    "        #         xs=(jnp.arange(f.shape[1] - self.init_t) + 1),\n",
    "        #     )\n",
    "\n",
    "        #     if self.unroll:\n",
    "        #         return c_s, y_s\n",
    "\n",
    "        #     else:\n",
    "        #         return c_n, y_n\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"hippo must be of type HiPPOLSICell or HiPPOLTICell\")\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_state(\n",
    "        rng,\n",
    "        batch_size: int,\n",
    "        hidden_size: int,\n",
    "        init_fn=nn.initializers.zeros,\n",
    "    ):\n",
    "        mem_shape = (batch_size, hidden_size)\n",
    "        return init_fn(rng, mem_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HiPPOLTI Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiPPOLTICell(HiPPOCell):\n",
    "\n",
    "    features: int\n",
    "    step_size: float\n",
    "    basis_size: float\n",
    "    alpha: float = 0.5\n",
    "    init_t: int = 0\n",
    "    recon: bool = True\n",
    "    measure: str = \"legs\"\n",
    "    A_init_fn: Callable = legs_initializer()\n",
    "    B_init_fn: Callable = legs_initializer()\n",
    "    dtype: Any = jnp.float32\n",
    "\n",
    "    def setup(self) -> None:\n",
    "        A = self.param(\n",
    "            \"A\",\n",
    "            self.A_init_fn,\n",
    "            (jax.random.PRNGKey(0), (self.features, self.features)),\n",
    "        )\n",
    "        B = self.param(\"B\", self.B_init_fn, (jax.random.PRNGKey(0), (self.features, 1)))\n",
    "\n",
    "        A_d_, B_d_ = jax.lax.stop_gradient(\n",
    "            self.discretize(\n",
    "                A=A,\n",
    "                B=B,\n",
    "                step=self.step_size,\n",
    "                alpha=self.alpha,\n",
    "                dtype=self.dtype,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.A_d = A_d_\n",
    "        self.B_d = B_d_\n",
    "\n",
    "        if self.measure in [\"legs\", \"legt\", \"lmu\", \"lagt\", \"fout\"] and self.recon:\n",
    "            self.vals = jnp.arange(0.0, self.basis_size, self.step_size)\n",
    "            self.eval_matrix = self.basis(\n",
    "                method=self.measure,\n",
    "                N=self.A_d.shape[0],\n",
    "                vals=self.vals,\n",
    "                c=0.0,\n",
    "                dtype=self.dtype,\n",
    "            )  # (T/dt, N)\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        f: Float[Array, \"#batch seq_len input_size\"],\n",
    "        c_t_1: Float[Array, \"#batch input_size N\"],\n",
    "        t_step: int,\n",
    "    ) -> Tuple[\n",
    "        Float[Array, \"#batch input_size N\"], Float[Array, \"#batch input_size N\"]\n",
    "    ]:\n",
    "        t = t_step - 1 + self.init_t\n",
    "        c_t = (jnp.dot(c_t_1, (self.A_d).T) + ((self.B_d).T * f[t, :])).astype(\n",
    "            self.dtype\n",
    "        )\n",
    "\n",
    "        if self.measure in [\"legs\", \"legt\", \"lmu\", \"lagt\", \"fout\"] and self.recon:\n",
    "            y = self.reconstruct(c_t).astype(self.dtype)\n",
    "            return (c_t, y), (c_t, y)\n",
    "        else:\n",
    "            return (c_t, c_t), (c_t, c_t)\n",
    "\n",
    "    def discretize(\n",
    "        self,\n",
    "        A: Float[Array, \"N N\"],\n",
    "        B: Float[Array, \"N input_size\"],\n",
    "        step: float,\n",
    "        alpha: Union[float, str] = 0.5,\n",
    "        dtype: Any = jnp.float32,\n",
    "    ) -> Tuple[Float[Array, \"N N\"], Float[Array, \"N input_size\"]]:\n",
    "        \"\"\"\n",
    "        Function used for discretizing the HiPPO A and B matrices\n",
    "\n",
    "        Args:\n",
    "            A (jnp.ndarray):\n",
    "                shape: (N, N)\n",
    "                matrix to be discretized\n",
    "\n",
    "            B (jnp.ndarray):\n",
    "                shape: (N, 1)\n",
    "                matrix to be discretized\n",
    "\n",
    "            step (float):\n",
    "                step size used for discretization\n",
    "\n",
    "            alpha (float, optional):\n",
    "                used for determining which generalized bilinear transformation to use\n",
    "                - forward Euler corresponds to α = 0,\n",
    "                - backward Euler corresponds to α = 1,\n",
    "                - bilinear corresponds to α = 0.5,\n",
    "                - Zero-order Hold corresponds to α > 1\n",
    "\n",
    "            dtype (jnp.float):\n",
    "                type of float precision to be used\n",
    "\n",
    "        Returns:\n",
    "            GBT_A (jnp.ndarray):\n",
    "                shape: (N, N)\n",
    "                discretized A matrix based on the given step size and alpha value\n",
    "\n",
    "            GBT_B (jnp.ndarray):\n",
    "                shape: (N, 1)\n",
    "                discretized B matrix based on the given step size and alpha value\n",
    "        \"\"\"\n",
    "        if alpha <= 1:\n",
    "            assert alpha in [0, 0.5, 1], \"alpha must be 0, 0.5, or 1\"\n",
    "        else:\n",
    "            assert (\n",
    "                alpha > 1 or type(alpha) == str\n",
    "            ), \"alpha must be greater than 1 for zero-order hold\"\n",
    "            if type(alpha) == str:\n",
    "                assert (\n",
    "                    alpha == \"zoh\"\n",
    "                ), \"if alpha is a string, it must be defined as 'zoh' for zero-order hold\"\n",
    "\n",
    "        I = jnp.eye(A.shape[0])\n",
    "\n",
    "        if alpha <= 1:  # Generalized Bilinear Transformation\n",
    "            step_size = step\n",
    "            part1 = I - (step_size * alpha * A)\n",
    "            part2 = I + (step_size * (1 - alpha) * A)\n",
    "\n",
    "            GBT_A = jnp.linalg.lstsq(part1, part2, rcond=None)[0]\n",
    "            GBT_B = jnp.linalg.lstsq(part1, (step_size * B), rcond=None)[0]\n",
    "\n",
    "        else:  # Zero-order Hold\n",
    "            # refer to this for why this works\n",
    "            # https://en.wikipedia.org/wiki/Discretization#:~:text=A%20clever%20trick%20to%20compute%20Ad%20and%20Bd%20in%20one%20step%20is%20by%20utilizing%20the%20following%20property\n",
    "\n",
    "            n = A.shape[0]\n",
    "            b_n = B.shape[1]\n",
    "            A_B_square = jnp.block(\n",
    "                [[A, B], [jnp.zeros((b_n, n)), jnp.zeros((b_n, b_n))]]\n",
    "            )\n",
    "            A_B = jax.scipy.linalg.expm(A_B_square * self.step_size)\n",
    "\n",
    "            GBT_A = A_B[0:n, 0:n]\n",
    "            GBT_B = A_B[0:-b_n, -b_n:]\n",
    "\n",
    "        return GBT_A.astype(dtype), GBT_B.astype(dtype)\n",
    "\n",
    "    def measure_fn(self, method: str, c: float = 0.0) -> Callable:\n",
    "        \"\"\"\n",
    "        Returns a function that is used to measure the distance between the input sequence and the estimated coefficients\n",
    "\n",
    "        Args:\n",
    "            method (str):\n",
    "                The method used to measure the distance between the input sequence and the estimated coefficients\n",
    "\n",
    "            c (float):\n",
    "                The tilt of the function used to measure the distance between the input sequence and the estimated coefficients\n",
    "\n",
    "        Returns:\n",
    "            fn_tilted (Callable):\n",
    "                The function used to measure the distance between the input sequence and the estimated coefficients\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if method == \"legs\":\n",
    "            fn = lambda x: jnp.heaviside(x, 1.0) * jnp.exp(-x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        fn_tilted = lambda x: jnp.exp(c * x) * fn(x)\n",
    "\n",
    "        return fn_tilted\n",
    "\n",
    "    def basis(\n",
    "        self,\n",
    "        method: str,\n",
    "        N: int,\n",
    "        vals: Float[Array, \"1\"],\n",
    "        c: float = 0.0,\n",
    "        truncate_measure: bool = True,\n",
    "        dtype: Any = jnp.float32,\n",
    "    ) -> Float[Array, \"seq_len N\"]:\n",
    "        \"\"\"\n",
    "        Creates the basis matrix (eval matrix) for the appropriate HiPPO method.\n",
    "\n",
    "        Args:\n",
    "            B (jnp.ndarray):\n",
    "                shape: (N, 1)\n",
    "                The HiPPO B matrix\n",
    "\n",
    "            method (str):\n",
    "                The HiPPO method to use\n",
    "\n",
    "            N (int):\n",
    "                The number of basis functions to use\n",
    "\n",
    "            vals (jnp.ndarray):\n",
    "                shape: (seq_len, )\n",
    "                The values to evaluate the basis functions at\n",
    "\n",
    "            c (float):\n",
    "                The constant to use for the tilted measure\n",
    "\n",
    "            truncate_measure (bool):\n",
    "                Whether or not to truncate the measure to the interval [0, 1]\n",
    "\n",
    "            dtype (Any):\n",
    "                The dtype to use for the basis matrix\n",
    "\n",
    "        Returns:\n",
    "            eval_matrix (jnp.ndarray):\n",
    "                shape: (seq_len, N)\n",
    "                The basis matrix\n",
    "        \"\"\"\n",
    "\n",
    "        if method == \"legs\":\n",
    "            _vals = jnp.exp(-vals)\n",
    "            base = (2 * jnp.arange(N) + 1) ** 0.5 * (-1) ** jnp.arange(\n",
    "                N\n",
    "            )  # unscaled, untranslated legendre polynomial matrix\n",
    "            base = einops.rearrange(base, \"N -> N 1\")\n",
    "            eval_matrix = (\n",
    "                jax.lax.stop_gradient(\n",
    "                    ss.eval_legendre(jnp.expand_dims(jnp.arange(N), -1), 1 - 2 * _vals)\n",
    "                )\n",
    "                * base\n",
    "            ).T  # (L, N)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"method {method} not implemented\")\n",
    "\n",
    "        if truncate_measure:\n",
    "            tilting_fn = self.measure_fn(method, c=c)\n",
    "            val = tilting_fn(vals)\n",
    "            eval_matrix = eval_matrix.at[val == 0.0].set(0.0)\n",
    "\n",
    "        p = eval_matrix * jnp.exp(-c * vals)[:, None]  # [::-1, None]\n",
    "\n",
    "        return p.astype(dtype)\n",
    "\n",
    "    def reconstruct(\n",
    "        self, c: Float[Array, \"#batch input_size N\"], evals=None\n",
    "    ) -> Float[Array, \"#batch seq_len input_size\"]:\n",
    "        \"\"\"reconstructs the input sequence from the estimated coefficients and the evaluation matrix\n",
    "\n",
    "        Args:\n",
    "            c (jnp.ndarray):\n",
    "                shape: (batch size, input length, N)\n",
    "                Vector of the estimated coefficients, given the history of the function/sequence\n",
    "\n",
    "            evals (jnp.ndarray, optional):\n",
    "                shape: ()\n",
    "                Vector of the evaluation points. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            y (jnp.ndarray):\n",
    "                shape: (batch size, input length, input size)\n",
    "                The reconstructed input sequence\n",
    "        \"\"\"\n",
    "        if evals is not None:\n",
    "            eval_matrix = self.basis(method=self.measure, N=self.N, vals=evals)\n",
    "        else:\n",
    "            eval_matrix = self.eval_matrix\n",
    "\n",
    "        y = None\n",
    "        if len(c.shape) == 3:\n",
    "            c = einops.rearrange(c, \"batch input_size N -> batch N input_size\")\n",
    "            y = jax.vmap(jnp.dot, in_axes=(None, 0))(eval_matrix, c)\n",
    "            y = einops.rearrange(y, \"batch seq_len 1 -> batch seq_len\")\n",
    "            y = jax.vmap(jnp.flip, in_axes=(0, None))(y, 0)\n",
    "        elif len(c.shape) == 4:\n",
    "            c = einops.rearrange(\n",
    "                c, \"batch seq_len input_size N -> batch seq_len N input_size\"\n",
    "            )\n",
    "            time_dot = jax.vmap(jnp.dot, in_axes=(None, 0))\n",
    "            batch_time_dot = jax.vmap(time_dot, in_axes=(None, 0))\n",
    "            y = batch_time_dot(eval_matrix, c)\n",
    "            y = einops.rearrange(\n",
    "                y, \"batch seq_len 1 seq_len2 -> batch seq_len seq_len2\"\n",
    "            )\n",
    "            y = jax.vmap(jax.vmap(jnp.flip, in_axes=(0, None)), in_axes=(0, None))(y, 0)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"c must be of shape (batch size, input length, N) or (batch seq_len input_size N)\"\n",
    "            )\n",
    "\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_state(\n",
    "        rng,\n",
    "        batch_size: int,\n",
    "        hidden_size: int,\n",
    "        init_fn=nn.initializers.zeros,\n",
    "    ):\n",
    "        mem_shape = (batch_size, hidden_size)\n",
    "        return init_fn(rng, mem_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test HiPPO Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hippo_operator(key, hippo, random_input, hidden_size, batch_size):\n",
    "    x_jnp = jnp.asarray(random_input, dtype=jnp.float32)\n",
    "    x_jnp = einops.rearrange(x_jnp, \"batch seq_len -> batch seq_len 1\")\n",
    "\n",
    "    c_t_1 = hippo.initialize_state(\n",
    "        subkeys[7], batch_size=batch_size, hidden_size=hidden_size\n",
    "    )\n",
    "    params = hippo.init(key, f=x_jnp, c_t_1=c_t_1)\n",
    "\n",
    "    start = time.time()\n",
    "    c, y = hippo.apply(params, f=x_jnp)\n",
    "    end = time.time()\n",
    "\n",
    "    duration = end - start\n",
    "    print(f\"Duration: {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_operators(the_measure=\"legs\", alpha=0.5):\n",
    "    T = 1\n",
    "    freq = 1\n",
    "    step = 1e-3\n",
    "    L = int(T / step)\n",
    "\n",
    "    batch_size = 1\n",
    "    data_size = L\n",
    "    input_size = 1\n",
    "\n",
    "    N = 64\n",
    "\n",
    "    u = whitesignal(subkeys[4], T, step, freq, batch_shape=(batch_size,))\n",
    "    x_np = np.asarray(u)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ------------------------------ Instantiate My HiPPOs -----------------------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    print(f\"Creating HiPPO-{the_measure} LTI model with {alpha} transform\")\n",
    "    hippo_lti_cell = HiPPOLTICell\n",
    "    h_args = {\n",
    "        \"step_size\": step,\n",
    "        \"basis_size\": T,\n",
    "        \"alpha\": alpha,\n",
    "        \"recon\": True,\n",
    "        \"A_init_fn\": legs_initializer(),\n",
    "        \"B_init_fn\": legs_initializer(),\n",
    "        \"measure\": the_measure,\n",
    "    }\n",
    "    hippo_lti = HiPPO(\n",
    "        features=N,\n",
    "        hippo_cell=hippo_lti_cell,\n",
    "        hippo_args=h_args,\n",
    "        init_t=0,\n",
    "        unroll=False,\n",
    "    )\n",
    "\n",
    "    print(f\"Testing Coeffiecients for {alpha} LTI HiPPO-{the_measure}\")\n",
    "\n",
    "    test_hippo_operator(\n",
    "        key=subkeys[5],\n",
    "        hippo=hippo_lti,\n",
    "        random_input=x_np,\n",
    "        hidden_size=N,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    print(f\"end of test for HiPPO-{the_measure} model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LegS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HiPPO-legs LTI model with 0.0 transform\n",
      "Testing Coeffiecients for 0.0 LTI HiPPO-legs\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "\"HiPPOLTICell\" object has no attribute \"A_d\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_operators(the_measure\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlegs\u001b[39;49m\u001b[39m\"\u001b[39;49m, alpha\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[17], line 40\u001b[0m, in \u001b[0;36mtest_operators\u001b[0;34m(the_measure, alpha)\u001b[0m\n\u001b[1;32m     30\u001b[0m hippo_lti \u001b[39m=\u001b[39m HiPPO(\n\u001b[1;32m     31\u001b[0m     features\u001b[39m=\u001b[39mN,\n\u001b[1;32m     32\u001b[0m     hippo_cell\u001b[39m=\u001b[39mhippo_lti_cell,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     unroll\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTesting Coeffiecients for \u001b[39m\u001b[39m{\u001b[39;00malpha\u001b[39m}\u001b[39;00m\u001b[39m LTI HiPPO-\u001b[39m\u001b[39m{\u001b[39;00mthe_measure\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m test_hippo_operator(\n\u001b[1;32m     41\u001b[0m     key\u001b[39m=\u001b[39;49msubkeys[\u001b[39m5\u001b[39;49m],\n\u001b[1;32m     42\u001b[0m     hippo\u001b[39m=\u001b[39;49mhippo_lti,\n\u001b[1;32m     43\u001b[0m     random_input\u001b[39m=\u001b[39;49mx_np,\n\u001b[1;32m     44\u001b[0m     hidden_size\u001b[39m=\u001b[39;49mN,\n\u001b[1;32m     45\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend of test for HiPPO-\u001b[39m\u001b[39m{\u001b[39;00mthe_measure\u001b[39m}\u001b[39;00m\u001b[39m model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m, in \u001b[0;36mtest_hippo_operator\u001b[0;34m(key, hippo, random_input, hidden_size, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m x_jnp \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(x_jnp, \u001b[39m\"\u001b[39m\u001b[39mbatch seq_len -> batch seq_len 1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m c_t_1 \u001b[39m=\u001b[39m hippo\u001b[39m.\u001b[39minitialize_state(\n\u001b[1;32m      6\u001b[0m     subkeys[\u001b[39m7\u001b[39m], batch_size\u001b[39m=\u001b[39mbatch_size, hidden_size\u001b[39m=\u001b[39mhidden_size\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m params \u001b[39m=\u001b[39m hippo\u001b[39m.\u001b[39;49minit(key, f\u001b[39m=\u001b[39;49mx_jnp, c_t_1\u001b[39m=\u001b[39;49mc_t_1)\n\u001b[1;32m     10\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     11\u001b[0m c, y \u001b[39m=\u001b[39m hippo\u001b[39m.\u001b[39mapply(params, f\u001b[39m=\u001b[39mx_jnp)\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[14], line 102\u001b[0m, in \u001b[0;36mHiPPO.__call__\u001b[0;34m(self, f, c_t_1)\u001b[0m\n\u001b[1;32m     99\u001b[0m     c_t, y \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mvmap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hippo, in_axes\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39mNone\u001b[39;00m))(f, c_tm1, i)\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m (c_t, y), (c_t, y)\n\u001b[0;32m--> 102\u001b[0m (c_n, y_n), (c_s, y_s) \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mlax\u001b[39m.\u001b[39;49mscan(\n\u001b[1;32m    103\u001b[0m     f\u001b[39m=\u001b[39;49mlti_scan_fn,\n\u001b[1;32m    104\u001b[0m     init\u001b[39m=\u001b[39;49m(c_t_1, jnp\u001b[39m.\u001b[39;49mones(f\u001b[39m.\u001b[39;49mshape)),\n\u001b[1;32m    105\u001b[0m     xs\u001b[39m=\u001b[39;49m(jnp\u001b[39m.\u001b[39;49marange(f\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_t) \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m),\n\u001b[1;32m    106\u001b[0m )\n\u001b[1;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munroll:\n\u001b[1;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m c_s, y_s\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[14], line 99\u001b[0m, in \u001b[0;36mHiPPO.__call__.<locals>.lti_scan_fn\u001b[0;34m(carry, i)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlti_scan_fn\u001b[39m(carry, i):\n\u001b[1;32m     98\u001b[0m     c_tm1, y_t_1 \u001b[39m=\u001b[39m carry\n\u001b[0;32m---> 99\u001b[0m     c_t, y \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvmap(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hippo, in_axes\u001b[39m=\u001b[39;49m(\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m))(f, c_tm1, i)\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m (c_t, y), (c_t, y)\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[15], line 54\u001b[0m, in \u001b[0;36mHiPPOLTICell.__call__\u001b[0;34m(self, f, c_t_1, t_step)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m     46\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     47\u001b[0m     f: Float[Array, \u001b[39m\"\u001b[39m\u001b[39m#batch seq_len input_size\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     Float[Array, \u001b[39m\"\u001b[39m\u001b[39m#batch input_size N\u001b[39m\u001b[39m\"\u001b[39m], Float[Array, \u001b[39m\"\u001b[39m\u001b[39m#batch input_size N\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     52\u001b[0m ]:\n\u001b[1;32m     53\u001b[0m     t \u001b[39m=\u001b[39m t_step \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_t\n\u001b[0;32m---> 54\u001b[0m     c_t \u001b[39m=\u001b[39m (jnp\u001b[39m.\u001b[39mdot(c_t_1, (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mA_d)\u001b[39m.\u001b[39mT) \u001b[39m+\u001b[39m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB_d)\u001b[39m.\u001b[39mT \u001b[39m*\u001b[39m f[t, :]))\u001b[39m.\u001b[39mastype(\n\u001b[1;32m     55\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\n\u001b[1;32m     56\u001b[0m     )\n\u001b[1;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasure \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mlegs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlegt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlmu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlagt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecon:\n\u001b[1;32m     59\u001b[0m         y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreconstruct(c_t)\u001b[39m.\u001b[39mastype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/hippo-pkg-Uqb72G6k-py3.8/lib/python3.8/site-packages/flax/linen/module.py:718\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    716\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[name]\n\u001b[1;32m    717\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    719\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: \"HiPPOLTICell\" object has no attribute \"A_d\""
     ]
    }
   ],
   "source": [
    "test_operators(the_measure=\"legs\", alpha=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s4mer-pkg-jZnBSgjq-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a81e05d1d7f7eae781698b7c1b81c0d771335201ebad1d81045cb177cef974b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
