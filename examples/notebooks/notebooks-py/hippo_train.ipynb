{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiPPO Matrices\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Loading In Necessary Packages](#load-packages)\n",
    "* [Instantiate The HiPPO Matrix](#instantiate-the-hippo-matrix)\n",
    "    * [Translated Legendre (LegT)](#translated-legendre-legt)\n",
    "        * [LegT](#legt)\n",
    "        * [LMU](#lmu)\n",
    "    * [Translated Laguerre (LagT)](#translated-laguerre-lagt)\n",
    "    * [Scaled Legendre (LegS)](#scaled-legendre-legs)\n",
    "    * [Fourier Basis](#fourier-basis)\n",
    "        * [Fourier Recurrent Unit (FRU)](#fourier-recurrent-unit-fru)\n",
    "        * [Truncated Fourier (FouT)](#truncated-fourier-fout)\n",
    "        * [Fourier With Decay (FourD)](#fourier-with-decay-fourd)\n",
    "* [Gu's Linear Time Invariant (LTI) HiPPO Operator](#gus-hippo-legt-operator)\n",
    "* [Gu's Scale invariant (LSI) HiPPO Operator](#gus-scale-invariant-hippo-legs-operator)\n",
    "* [Implementation Of General HiPPO Operator](#implementation-of-general-hippo-operator)\n",
    "* [Test Generalized Bilinear Transform and Zero Order Hold Matrices](#test-generalized-bilinear-transform-and-zero-order-hold-matrices)\n",
    "    * [Testing Forward Euler on GBT matrices](#testing-forward-euler-transform-for-lti-and-lsi)\n",
    "    * [Testing Backward Euler on GBT matrices](#testing-backward-euler-transform-for-lti-and-lsi-on-legs-matrices)\n",
    "    * [Testing Bidirectional on GBT matrices](#testing-lti-and-lsi-operators-with-bidirectional-transform)\n",
    "    * [Testing ZOH on GBT matrices](#testing-zoh-transform-for-lti-and-lsi-on-legs-matrices)\n",
    "* [Testing HiPPO Operators](#test-hippo-operators)\n",
    "    * [Testing Forward Euler on HiPPO Operators](#testing-lti-and-lsi-operators-with-forward-euler-transform)\n",
    "    * [Testing Backward Euler on HiPPO Operators](#testing-lti-and-lsi-operators-with-backward-euler-transform)\n",
    "    * [Testing Bidirectional on HiPPO Operators](#testing-lti-and-lsi-operators-with-bidirectional-transform)\n",
    "    * [Testing ZOH on HiPPO Operators](#testing-lti-and-lsi-operators-with-zoh-transform)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_path: /home/beegass/Documents/Coding/s4mer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../../../\"))\n",
    "print(f\"module_path: {module_path}\")\n",
    "if module_path not in sys.path:\n",
    "    print(f\"Adding {module_path} to sys.path\")\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n",
      "The Device: gpu\n"
     ]
    }
   ],
   "source": [
    "## import packages\n",
    "import math\n",
    "import time\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "\n",
    "import optax\n",
    "\n",
    "import wandb\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import requests\n",
    "\n",
    "from jaxtyping import Array, Float, Float16, Float32, Float64\n",
    "from typing import Callable, List, Optional, Tuple, Any, Union\n",
    "\n",
    "from src.data.process import moving_window, rolling_window\n",
    "\n",
    "# import modules\n",
    "from src.models.hippo.hippo import HiPPOLTI, HiPPOLSI\n",
    "from src.models.hippo.transition import TransMatrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jax.devices())\n",
    "print(f\"The Device: {jax.lib.xla_bridge.get_backend().platform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MPS enabled: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(linewidth=150)\n",
    "np.set_printoptions(linewidth=150)\n",
    "jnp.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_16_input(key_generator, batch_size=16, data_size=784, input_size=28):\n",
    "    # x = jax.random.randint(key_generator, (batch_size, data_size), 0, 255)\n",
    "    x = jax.random.uniform(key_generator, (batch_size, data_size))\n",
    "    return np.asarray(jax.vmap(moving_window, in_axes=(0, None))(x, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(cfg):\n",
    "    # download and transform train dataset\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(\n",
    "            \"../../datasets/mnist_data\",\n",
    "            download=True,\n",
    "            train=True,\n",
    "            transform=transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),  # first, convert image to PyTorch tensor\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        batch_size=cfg.training.params.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    # download and transform test dataset\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(\n",
    "            \"../../datasets/mnist_data\",\n",
    "            download=True,\n",
    "            train=False,\n",
    "            transform=transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),  # first, convert image to PyTorch tensor\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        batch_size=cfg.training.params.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(cfg, data):\n",
    "    # preprocess data\n",
    "    x = None\n",
    "    if cfg.data.dataset.preprocess_data == \"flatten\":\n",
    "        x = data.cpu().detach().numpy()\n",
    "        x = jnp.asarray(data, dtype=jnp.float32)\n",
    "        x = jnp.squeeze(x, axis=1)\n",
    "        x = vmap(jnp.ravel, in_axes=0)(x)\n",
    "        x = vmap(moving_window, in_axes=(0, None))(x, cfg[\"training\"][\"input_length\"])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(cfg, labels):\n",
    "    # preprocess data\n",
    "    y = None\n",
    "    if cfg.data.dataset.preprocess_labels == \"one hot\":\n",
    "        y = labels.cpu().detach().numpy()\n",
    "        y = jnp.asarray(y, dtype=jnp.float32)\n",
    "        # y = jax.nn.one_hot(y, 10, dtype=jnp.float32)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_optim(cfg, model, params):\n",
    "\n",
    "    tx = None\n",
    "    if cfg.training.params.optim == \"adam\":\n",
    "        tx = optax.adamw(\n",
    "            learning_rate=cfg.training.params.lr,\n",
    "            weight_decay=cfg.training.params.weight_decay,\n",
    "        )\n",
    "    elif cfg.training.params.optim == \"sgd\":\n",
    "        tx = optax.sgd(learning_rate=cfg.training.params.lr)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown optimizer\")\n",
    "\n",
    "    # tx_state = tx.init(params)\n",
    "    # print(f\"tx_state: {tx_state}\")\n",
    "\n",
    "    return train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "    # , opt_state=tx_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def apply_model(state, carry, data, labels):\n",
    "    \"\"\"Computes gradients, loss and accuracy for a single batch.\"\"\"\n",
    "\n",
    "    def loss_fn(params):\n",
    "        # jax.debug.print(\"params:\\n{params}\", params=params)\n",
    "\n",
    "        logits = state.apply_fn({\"params\": params}, carry=carry, input=data)\n",
    "\n",
    "        one_hot = jax.nn.one_hot(labels, 10, dtype=jnp.float32)\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n",
    "\n",
    "        # jax.debug.print(\"logits:\\n{logits}\", logits=logits)\n",
    "        # jax.debug.print(\"labels:\\n{labels}\", labels=labels)\n",
    "        # jax.debug.print(\"one_hot:\\n{one_hot}\", one_hot=one_hot)\n",
    "        # jax.debug.print(\"loss:\\n{loss}\", loss=loss)\n",
    "\n",
    "        return loss, logits\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "\n",
    "    return grads, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def update_model(state, grads):\n",
    "    return state.apply_gradients(grads=grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hydra.main(config_path=\"../../config\", config_name=\"config\")\n",
    "def recurrent_train(\n",
    "    cfg: DictConfig,\n",
    ") -> None:  # num_epochs, opt_state, net_type=\"RNN\", train_key=None):\n",
    "    \"\"\"\n",
    "    Implements a learning loop over epochs.\n",
    "\n",
    "    Args:\n",
    "        cfg: Hydra config\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    with wandb.init(\n",
    "        project=\"BeeGass-HiPPOs\", entity=\"beegass\", config=cfg\n",
    "    ):  # initialize wandb project for logging\n",
    "\n",
    "        # get keys for parameters\n",
    "        seed = cfg.training.seed\n",
    "        key = jax.random.PRNGKey(seed)\n",
    "\n",
    "        \n",
    "        num_copies = cfg.training.key_num\n",
    "        subkeys = jax.random.split(key, num=num_copies)\n",
    "\n",
    "        # get train and test datasets\n",
    "        train_loader, test_loader = get_datasets(cfg)\n",
    "        print(f\"got dataset\")\n",
    "\n",
    "        # pick a model\n",
    "        model, params, carry = pick_model(a_key, cfg)\n",
    "        print(f\"got model and params\")\n",
    "\n",
    "        # pick an optimizer\n",
    "        state = pick_optim(cfg, model, params)\n",
    "        print(f\"got optimizer state\")\n",
    "\n",
    "        # pick a scheduler\n",
    "        # TODO: implement choice of scheduler\n",
    "\n",
    "        # pick a loss function\n",
    "        # TODO: implement choice of loss function\n",
    "\n",
    "        epoch_loss = []\n",
    "        epoch_accuracy = []\n",
    "\n",
    "        print(f\"starting training loop\")\n",
    "        # Loop over the training epochs\n",
    "        for epoch in range(cfg.training.params.num_epochs):\n",
    "            start_time = time.time()\n",
    "            for batch_id, (train_data, train_labels) in enumerate(train_loader):\n",
    "                data = preprocess_data(cfg, train_data)\n",
    "                labels = preprocess_labels(cfg, train_labels)\n",
    "                # carry = model.initialize_carry(\n",
    "                #     rng=subkey,\n",
    "                #     batch_size=(cfg[\"training\"][\"batch_size\"],),\n",
    "                #     hidden_size=cfg[\"models\"][\"deep_rnn\"][\"hidden_size\"],\n",
    "                # )\n",
    "                # grads, loss, accuracy = apply_model(\n",
    "                #     state=state, carry=None, data=data, labels=labels\n",
    "                # )\n",
    "                grads, loss, accuracy = apply_model(\n",
    "                    state=state,\n",
    "                    carry=carry,\n",
    "                    data=data,\n",
    "                    labels=labels,\n",
    "                )\n",
    "                state = update_model(state, grads)\n",
    "                epoch_loss.append(loss)\n",
    "                epoch_accuracy.append(accuracy)\n",
    "\n",
    "            # train loss and accuracy for current epoch\n",
    "            train_loss = jnp.mean(jnp.array(epoch_loss))\n",
    "            train_accuracy = jnp.mean(jnp.array(epoch_accuracy))\n",
    "            wandb.log(\n",
    "                {\"train_loss\": train_loss, \"train_accuracy\": train_accuracy}, step=epoch\n",
    "            )\n",
    "\n",
    "            epoch_test_loss = []\n",
    "            epoch_test_accuracy = []\n",
    "\n",
    "            for data, target in test_loader:\n",
    "                data = preprocess_data(cfg, train_data)\n",
    "                target = preprocess_labels(cfg, target)\n",
    "\n",
    "                # test loss for current epoch\n",
    "                # _, test_loss, test_accuracy = apply_model(\n",
    "                #     state=state, carry=None, data=data, labels=target\n",
    "                # )\n",
    "                _, test_loss, test_accuracy = apply_model(\n",
    "                    state=state,\n",
    "                    carry=carry,\n",
    "                    data=data,\n",
    "                    labels=target,\n",
    "                )\n",
    "                epoch_test_loss.append(test_loss)\n",
    "                epoch_test_accuracy.append(test_accuracy)\n",
    "\n",
    "            test_epoch_loss = jnp.mean(jnp.array(epoch_test_loss))\n",
    "            test_epoch_accuracy = jnp.mean(jnp.array(epoch_test_accuracy))\n",
    "            wandb.log(\n",
    "                {\"test_loss\": test_epoch_loss, \"test_accuracy\": test_epoch_accuracy},\n",
    "                step=epoch,\n",
    "            )\n",
    "\n",
    "            epoch_time = time.time() - start_time\n",
    "            print(f\"Epoch {epoch + 1} in {epoch_time:.2f} sec\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "            print(\n",
    "                f\"Test Loss: {test_epoch_loss:.4f}, Test Accuracy: {test_epoch_accuracy:.4f}\"\n",
    "            )\n",
    "\n",
    "        return state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test HiPPO Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hippo_reconstruction(\n",
    "    hippo, gu_hippo, random_input, key, s_or_t=\"lti\", print_all=False\n",
    "):\n",
    "    x_tensor = torch.tensor(random_input, dtype=torch.float32)\n",
    "    x_jnp = jnp.asarray(x_tensor, dtype=jnp.float32)  # convert torch array to jax array\n",
    "\n",
    "    # My Implementation\n",
    "    if print_all:\n",
    "        print(\n",
    "            f\"------------------------------------------------------------------------------------------\"\n",
    "        )\n",
    "        print(\n",
    "            f\"----------------------------My {s_or_t} Implementation Outputs----------------------------\"\n",
    "        )\n",
    "        print(\n",
    "            f\"------------------------------------------------------------------------------------------\"\n",
    "        )\n",
    "    params = hippo.init(key, f=x_jnp)\n",
    "    hippo = hippo.bind(params)\n",
    "    c = hippo.__call__(f=x_jnp)\n",
    "    y = hippo.reconstruct(c)\n",
    "\n",
    "    if s_or_t == \"lsi\":\n",
    "        c = jnp.moveaxis(c, 0, 1)\n",
    "        # y = jnp.moveaxis(y, 0, 1)\n",
    "\n",
    "    mse = lambda y_hat, y: jnp.mean((y_hat - y) ** 2)\n",
    "    batch_mse = jax.vmap(mse, in_axes=(0, 0))\n",
    "    print(f\"The Loss:\\n {batch_mse(y, x_jnp)}\\n\\n\\n\")\n",
    "\n",
    "    # Gu's HiPPO LegS\n",
    "    if print_all:\n",
    "        print(\n",
    "            f\"------------------------------------------------------------------------------------------\"\n",
    "        )\n",
    "        print(\n",
    "            f\"---------------------------Gu's {s_or_t} Implementation Outputs---------------------------\"\n",
    "        )\n",
    "        print(\n",
    "            f\"------------------------------------------------------------------------------------------\"\n",
    "        )\n",
    "    x_tensor = torch.moveaxis(x_tensor, 0, 1)\n",
    "    GU_c_s, GU_c_k = gu_hippo(x_tensor, fast=False)\n",
    "    # print(f\"GU_c_k shape:\\n{GU_c_k.shape}\")\n",
    "\n",
    "    gu_y = None\n",
    "    if s_or_t == \"lsi\":\n",
    "        gu_y = gu_hippo.reconstruct(GU_c_k)\n",
    "    elif s_or_t == \"lti\":\n",
    "        gu_y = gu_hippo.reconstruct(GU_c_k)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"s_or_t must be either 'lsi' or 'lti'. s_or_t is currently set to: {s_or_t}\"\n",
    "        )\n",
    "\n",
    "    gu_c = jnp.asarray(GU_c_k, dtype=jnp.float32)  # convert torch array to jax array\n",
    "    gu_y = jnp.asarray(gu_y, dtype=jnp.float32)  # convert torch array to jax array\n",
    "\n",
    "    # gu_c = jnp.moveaxis(gu_c, 0, 1)\n",
    "    # gu_y = jnp.moveaxis(gu_y, 0, 1)\n",
    "\n",
    "    # print(f\"gu_y shape:\\n {gu_y.shape}\")\n",
    "\n",
    "    x_tensor = jnp.asarray(\n",
    "        x_tensor, dtype=jnp.float32\n",
    "    )  # convert torch array to jax array\n",
    "    x_tensor = jnp.moveaxis(x_tensor, 0, 1)\n",
    "\n",
    "    print(f\"The Loss:\\n {batch_mse(gu_y, x_tensor)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reconstruction(\n",
    "    the_measure=\"legs\", lambda_n=1.0, alpha=0.5, discretization=0.5, print_all=False\n",
    "):\n",
    "    # N = 256\n",
    "    # L = 128\n",
    "\n",
    "    batch_size = 16\n",
    "    data_size = 256\n",
    "    input_size = 1\n",
    "\n",
    "    N = 50\n",
    "    L = data_size\n",
    "\n",
    "    x_jnp = random_16_input(\n",
    "        key_generator=subkeys[4],\n",
    "        batch_size=batch_size,\n",
    "        data_size=data_size,\n",
    "        input_size=input_size,\n",
    "    )\n",
    "    x_np = np.asarray(x_jnp)\n",
    "\n",
    "    x = torch.tensor(x_np, dtype=torch.float32)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ------------------------------ Instantiate Gu's HiPPOs ---------------------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "\n",
    "    print(f\"Creating Gu's HiPPO-{the_measure} LTI model with {alpha} transform\")\n",
    "    gu_hippo_lti = gu_HiPPO_LTI(\n",
    "        N=N,\n",
    "        method=the_measure,\n",
    "        dt=1.0,\n",
    "        T=L,\n",
    "        discretization=discretization,\n",
    "        lambda_n=lambda_n,\n",
    "        alpha=0.0,\n",
    "        beta=1.0,\n",
    "        c=0.0,\n",
    "    )  # The Gu's\n",
    "\n",
    "    if the_measure == \"legs\":\n",
    "        print(f\"Creating Gu's HiPPO-{the_measure} LSI model with {alpha} transform\")\n",
    "        gu_hippo_lsi = gu_HiPPO_LSI(\n",
    "            N=N,\n",
    "            method=the_measure,\n",
    "            max_length=L,\n",
    "            discretization=discretization,\n",
    "            lambda_n=lambda_n,\n",
    "            alpha=0.0,\n",
    "            beta=1.0,\n",
    "        )  # The Gu's\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ------------------------------ Instantiate My HiPPOs -----------------------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    print(f\"\\nTesting BRYANS HiPPO-{the_measure} model\")\n",
    "\n",
    "    matrices = TransMatrix(\n",
    "        N=N,\n",
    "        measure=the_measure,\n",
    "        lambda_n=lambda_n,\n",
    "        alpha=0.0,\n",
    "        beta=1.0,\n",
    "        dtype=jnp.float32,\n",
    "    )\n",
    "\n",
    "    A = matrices.A\n",
    "    B = matrices.B\n",
    "\n",
    "    print(f\"Creating HiPPO-{the_measure} LTI model with {alpha} transform\")\n",
    "    hippo_lti = HiPPOLTI(\n",
    "        N=N,\n",
    "        step_size=1.0,\n",
    "        lambda_n=lambda_n,\n",
    "        alpha=0.0,\n",
    "        beta=1.0,\n",
    "        GBT_alpha=alpha,\n",
    "        measure=the_measure,\n",
    "        basis_size=L,\n",
    "        dtype=jnp.float32,\n",
    "        unroll=False,\n",
    "    )  # Bryan's\n",
    "\n",
    "    # hippo_lti = HiPPO(\n",
    "    #     max_length=L,\n",
    "    #     step_size=1.0,\n",
    "    #     N=N,\n",
    "    #     lambda_n=lambda_n,\n",
    "    #     alpha=0.0,\n",
    "    #     beta=1.0,\n",
    "    #     GBT_alpha=alpha,\n",
    "    #     measure=the_measure,\n",
    "    #     s_t=\"lti\",\n",
    "    #     dtype=jnp.float32,\n",
    "    #     unroll=False,\n",
    "    # )  # Bryan's\n",
    "\n",
    "    if the_measure == \"legs\":\n",
    "        print(f\"Creating HiPPO-{the_measure} LSI model with {alpha} transform\")\n",
    "        hippo_lsi = HiPPOLSI(\n",
    "            N=N,\n",
    "            max_length=L,\n",
    "            step_size=1.0,\n",
    "            lambda_n=lambda_n,\n",
    "            alpha=0.0,\n",
    "            beta=1.0,\n",
    "            GBT_alpha=alpha,\n",
    "            measure=the_measure,\n",
    "            dtype=jnp.float32,\n",
    "            unroll=False,\n",
    "        )  # Bryan's\n",
    "        # hippo_lsi = HiPPO(\n",
    "        #     max_length=L,\n",
    "        #     step_size=1.0,\n",
    "        #     N=N,\n",
    "        #     lambda_n=lambda_n,\n",
    "        #     alpha=0.0,\n",
    "        #     beta=1.0,\n",
    "        #     GBT_alpha=alpha,\n",
    "        #     measure=the_measure,\n",
    "        #     s_t=\"lsi\",\n",
    "        #     dtype=jnp.float32,\n",
    "        #     unroll=False,\n",
    "        # )  # Bryan's\n",
    "\n",
    "    # ----------------------------------------------------------------------------------\n",
    "    # ------------------------------ Test HiPPO Operators ------------------------------\n",
    "    # ----------------------------------------------------------------------------------\n",
    "\n",
    "    print(f\"Bryan's Coeffiecients for {alpha} LTI HiPPO-{the_measure}\")\n",
    "\n",
    "    test_hippo_reconstruction(\n",
    "        hippo=hippo_lti,\n",
    "        gu_hippo=gu_hippo_lti,\n",
    "        random_input=x_np,\n",
    "        key=subkeys[5],\n",
    "        s_or_t=\"lti\",\n",
    "        print_all=print_all,\n",
    "    )\n",
    "\n",
    "    if the_measure == \"legs\":\n",
    "        print(f\"\\n\\nBryan's Coeffiecients for {alpha} LSI HiPPO-{the_measure}\")\n",
    "\n",
    "        test_hippo_reconstruction(\n",
    "            hippo=hippo_lsi,\n",
    "            gu_hippo=gu_hippo_lsi,\n",
    "            random_input=x_np,\n",
    "            key=subkeys[6],\n",
    "            s_or_t=\"lsi\",\n",
    "            print_all=print_all,\n",
    "        )\n",
    "\n",
    "    print(f\"end of test for HiPPO-{the_measure} model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigation To Table Of Contents\n",
    "---\n",
    "* [Table Of Contents](#table-of-contents)\n",
    "* [Loading In Necessary Packages](#load-packages)\n",
    "* [Instantiate The HiPPO Matrix](#instantiate-the-hippo-matrix)\n",
    "* [Gu's Linear Time Invariant (LTI) HiPPO Operator](#gus-hippo-legt-operator)\n",
    "* [Gu's Scale invariant (LSI) HiPPO Operator](#gus-scale-invariant-hippo-legs-operator)\n",
    "* [Implementation Of General HiPPO Operator](#implementation-of-general-hippo-operator)\n",
    "* [Test Generalized Bilinear Transform and Zero Order Hold Matrices](#test-generalized-bilinear-transform-and-zero-order-hold-matrices)\n",
    "* [Testing HiPPO Operators](#test-hippo-operators)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing (LTI and LSI) Operators With Forward Euler Transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LegS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-legs LTI model with 0.0 transform\n",
      "gu's vals: (256,)\n",
      "gu's vals: (256,)\n",
      "Creating Gu's HiPPO-legs LSI model with 0.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-legs model\n",
      "Creating HiPPO-legs LTI model with 0.0 transform\n",
      "Creating HiPPO-legs LSI model with 0.0 transform\n",
      "Bryan's Coeffiecients for 0.0 LTI HiPPO-legs\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n",
      "\n",
      "Bryan's Coeffiecients for 0.0 LSI HiPPO-legs\n",
      "The Loss:\n",
      " [41.367485  18.531097  14.098469  30.345993  10.6641865  7.9826894  9.042797  63.674404  29.575207  22.450172   4.7379494 25.612314  15.653051\n",
      "  8.503983  27.31075   44.781677 ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [40.91818   17.95709   13.634292  29.817364  10.300377   7.7191753  8.815974  63.2482    28.771494  22.10402    4.4629774 25.125237  14.982275\n",
      "  8.256765  26.396832  43.420464 ]\n",
      "\n",
      "end of test for HiPPO-legs model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"legs\", lambda_n=1.0, alpha=0.0, discretization=0.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LegT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-legt LTI model with 0.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-legt model\n",
      "Creating HiPPO-legt LTI model with 0.0 transform\n",
      "Bryan's Coeffiecients for 0.0 LTI HiPPO-legt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beegass/.cache/pypoetry/virtualenvs/s4mer-pkg-jZnBSgjq-py3.8/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:4970: RuntimeWarning: overflow encountered in cast\n",
      "  return binary_op(*args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "end of test for HiPPO-legt model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"legt\", lambda_n=1.0, alpha=0.0, discretization=0.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-lmu LTI model with 0.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-lmu model\n",
      "Creating HiPPO-lmu LTI model with 0.0 transform\n",
      "Bryan's Coeffiecients for 0.0 LTI HiPPO-lmu\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "end of test for HiPPO-lmu model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"lmu\", lambda_n=2.0, alpha=0.0, discretization=0.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LagT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-lagt LTI model with 0.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-lagt model\n",
      "Creating HiPPO-lagt LTI model with 0.0 transform\n",
      "Bryan's Coeffiecients for 0.0 LTI HiPPO-lagt\n",
      "The Loss:\n",
      " [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [2.7180708e+23 2.2506286e+26 4.5019242e+25 3.6529218e+25 1.0892659e+26 5.1358761e+25 2.0433805e+26 1.0698097e+24 2.2920454e+24 2.7865366e+24\n",
      " 2.1316504e+25 9.0141790e+24 6.8558258e+24 3.8399939e+24 2.2452325e+25 1.1329689e+25]\n",
      "\n",
      "end of test for HiPPO-lagt model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"lagt\", lambda_n=1.0, alpha=0.0, discretization=0.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-fru LTI model with 0.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-fru model\n",
      "Creating HiPPO-fru LTI model with 0.0 transform\n",
      "Bryan's Coeffiecients for 0.0 LTI HiPPO-fru\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "end of test for HiPPO-fru model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"fru\", lambda_n=1.0, alpha=0.0, discretization=0.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FouT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-fout LTI model with 0.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-fout model\n",
      "Creating HiPPO-fout LTI model with 0.0 transform\n",
      "Bryan's Coeffiecients for 0.0 LTI HiPPO-fout\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "end of test for HiPPO-fout model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"fout\", lambda_n=1.0, alpha=0.0, discretization=0.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FouD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-foud LTI model with 0.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-foud model\n",
      "Creating HiPPO-foud LTI model with 0.0 transform\n",
      "Bryan's Coeffiecients for 0.0 LTI HiPPO-foud\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "\n",
      "end of test for HiPPO-foud model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"foud\", lambda_n=1.0, alpha=0.0, discretization=0.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing (LTI and LSI) Operators With Backward Euler Transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LegS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-legs LTI model with 1.0 transform\n",
      "gu's vals: (256,)\n",
      "gu's vals: (256,)\n",
      "Creating Gu's HiPPO-legs LSI model with 1.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-legs model\n",
      "Creating HiPPO-legs LTI model with 1.0 transform\n",
      "Creating HiPPO-legs LSI model with 1.0 transform\n",
      "Bryan's Coeffiecients for 1.0 LTI HiPPO-legs\n",
      "The Loss:\n",
      " [0.24920948 0.26120606 0.2225034  0.2562787  0.22515053 0.21028472 0.24650134 0.27222782 0.22471839 0.27827442 0.27449894 0.3005273  0.28741568\n",
      " 0.24308945 0.31829214 0.28291494]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.10874012 0.08415962 0.0876613  0.09463326 0.08717994 0.08624279 0.12696809 0.09238221 0.08174874 0.08340041 0.08126472 0.09182876 0.09582479\n",
      " 0.09089237 0.09624433 0.08324574]\n",
      "\n",
      "\n",
      "\n",
      "Bryan's Coeffiecients for 1.0 LSI HiPPO-legs\n",
      "The Loss:\n",
      " [0.09170212 0.08274928 0.08844691 0.0866254  0.09163544 0.08870362 0.09487514 0.09269952 0.07820393 0.08769968 0.08195163 0.081138   0.097323\n",
      " 0.09436389 0.10034208 0.09119291]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.07773688 0.07255538 0.07355011 0.08291766 0.07646185 0.07711822 0.08256438 0.08390449 0.06928975 0.07830015 0.06854879 0.07528481 0.08563745\n",
      " 0.0773788  0.08420778 0.07432349]\n",
      "\n",
      "end of test for HiPPO-legs model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"legs\", lambda_n=1.0, alpha=1.0, discretization=1.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LegT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-legt LTI model with 1.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-legt model\n",
      "Creating HiPPO-legt LTI model with 1.0 transform\n",
      "Bryan's Coeffiecients for 1.0 LTI HiPPO-legt\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "end of test for HiPPO-legt model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"legt\", lambda_n=1.0, alpha=1.0, discretization=1.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-lmu LTI model with 1.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-lmu model\n",
      "Creating HiPPO-lmu LTI model with 1.0 transform\n",
      "Bryan's Coeffiecients for 1.0 LTI HiPPO-lmu\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "end of test for HiPPO-lmu model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"lmu\", lambda_n=2.0, alpha=1.0, discretization=1.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LagT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-lagt LTI model with 1.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-lagt model\n",
      "Creating HiPPO-lagt LTI model with 1.0 transform\n",
      "Bryan's Coeffiecients for 1.0 LTI HiPPO-lagt\n",
      "The Loss:\n",
      " [2.97866306e+27 7.69596023e+26 2.34778854e+27 2.34798733e+27 1.69587412e+27 1.89873532e+27 3.40461727e+27 7.15103529e+26 4.11259534e+26\n",
      " 1.05265504e+27 1.34903733e+26 1.87793130e+26 7.50029257e+25 3.75032490e+27 4.09923281e+27 3.00623784e+27]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.34614652 0.3436889  0.32018572 0.37510973 0.31538126 0.29790556 0.34649736 0.34762293 0.31610107 0.35278565 0.32734016 0.31865036 0.3183095\n",
      " 0.35929114 0.33028978 0.3190096 ]\n",
      "\n",
      "end of test for HiPPO-lagt model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"lagt\", lambda_n=1.0, alpha=1.0, discretization=1.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-fru LTI model with 1.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-fru model\n",
      "Creating HiPPO-fru LTI model with 1.0 transform\n",
      "Bryan's Coeffiecients for 1.0 LTI HiPPO-fru\n",
      "The Loss:\n",
      " [0.35103828 0.3443796  0.3208844  0.37567043 0.31828076 0.29978725 0.35313404 0.3464237  0.31523266 0.35390437 0.32718375 0.32085764 0.31820312\n",
      " 0.36389875 0.3335151  0.32449648]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35103828 0.3443796  0.3208844  0.37567043 0.31828076 0.29978725 0.35313404 0.3464237  0.31523266 0.35390437 0.32718375 0.32085764 0.31820312\n",
      " 0.36389875 0.3335151  0.3244965 ]\n",
      "\n",
      "end of test for HiPPO-fru model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"fru\", lambda_n=1.0, alpha=1.0, discretization=1.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FouT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-fout LTI model with 1.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-fout model\n",
      "Creating HiPPO-fout LTI model with 1.0 transform\n",
      "Bryan's Coeffiecients for 1.0 LTI HiPPO-fout\n",
      "The Loss:\n",
      " [0.35106996 0.344378   0.32087767 0.37567848 0.31823134 0.29978877 0.3531564  0.34632966 0.31542528 0.35397243 0.3271905  0.32091826 0.31893167\n",
      " 0.36397302 0.33368683 0.32445395]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35106996 0.344378   0.3208777  0.37567848 0.31823134 0.29978877 0.3531564  0.34632966 0.31542528 0.35397243 0.3271905  0.32091826 0.31893167\n",
      " 0.36397302 0.3336868  0.32445395]\n",
      "\n",
      "end of test for HiPPO-fout model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"fout\", lambda_n=1.0, alpha=1.0, discretization=1.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FouD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-foud LTI model with 1.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-foud model\n",
      "Creating HiPPO-foud LTI model with 1.0 transform\n",
      "Bryan's Coeffiecients for 1.0 LTI HiPPO-foud\n",
      "The Loss:\n",
      " [0.3510547  0.34435478 0.3209077  0.37571317 0.3182457  0.29978248 0.35311943 0.34622428 0.31510615 0.35376358 0.32711208 0.32100677 0.3177272\n",
      " 0.36386395 0.3333422  0.32429516]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.3510547  0.34435478 0.3209077  0.37571317 0.3182457  0.29978248 0.35311943 0.34622425 0.31510615 0.35376355 0.32711208 0.32100677 0.3177272\n",
      " 0.36386395 0.3333422  0.32429516]\n",
      "\n",
      "end of test for HiPPO-foud model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"foud\", lambda_n=1.0, alpha=1.0, discretization=1.0, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing (LTI and LSI) Operators With Bidirectional Transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LegS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-legs LTI model with 0.5 transform\n",
      "gu's vals: (256,)\n",
      "gu's vals: (256,)\n",
      "Creating Gu's HiPPO-legs LSI model with 0.5 transform\n",
      "\n",
      "Testing BRYANS HiPPO-legs model\n",
      "Creating HiPPO-legs LTI model with 0.5 transform\n",
      "Creating HiPPO-legs LSI model with 0.5 transform\n",
      "Bryan's Coeffiecients for 0.5 LTI HiPPO-legs\n",
      "The Loss:\n",
      " [ 40.985847    0.5634093   2.8889482   5.893869   12.014208   48.11052    36.70481    26.736866    2.832956   96.23154     0.7655915  77.20819\n",
      "   2.3401718  34.16419   103.69086     9.367006 ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [1.0503573  1.2949177  0.14021397 0.3582669  1.0865629  0.64516515 0.50587565 0.39670065 0.8277695  2.0997803  0.21040663 2.4856312  0.22027926\n",
      " 2.7459843  1.2234805  0.25088328]\n",
      "\n",
      "\n",
      "\n",
      "Bryan's Coeffiecients for 0.5 LSI HiPPO-legs\n",
      "The Loss:\n",
      " [0.10447852 0.09750983 0.1006453  0.09969212 0.10920918 0.09401403 0.10654827 0.09686814 0.09675886 0.11329925 0.08927324 0.09767537 0.11696188\n",
      " 0.10941317 0.1298894  0.12789543]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.07221566 0.06683332 0.06898078 0.07441905 0.06896985 0.07259226 0.07693301 0.07542108 0.06581502 0.08418398 0.06745987 0.0705431  0.08039401\n",
      " 0.07383187 0.08552738 0.07164612]\n",
      "\n",
      "end of test for HiPPO-legs model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"legs\", lambda_n=1.0, alpha=0.5, discretization=0.5, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LegT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-legt LTI model with 0.5 transform\n",
      "\n",
      "Testing BRYANS HiPPO-legt model\n",
      "Creating HiPPO-legt LTI model with 0.5 transform\n",
      "Bryan's Coeffiecients for 0.5 LTI HiPPO-legt\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "end of test for HiPPO-legt model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"legt\", lambda_n=1.0, alpha=0.5, discretization=0.5, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-lmu LTI model with 0.5 transform\n",
      "\n",
      "Testing BRYANS HiPPO-lmu model\n",
      "Creating HiPPO-lmu LTI model with 0.5 transform\n",
      "Bryan's Coeffiecients for 0.5 LTI HiPPO-lmu\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "end of test for HiPPO-lmu model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"lmu\", lambda_n=2.0, alpha=0.5, discretization=0.5, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LagT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-lagt LTI model with 0.5 transform\n",
      "\n",
      "Testing BRYANS HiPPO-lagt model\n",
      "Creating HiPPO-lagt LTI model with 0.5 transform\n",
      "Bryan's Coeffiecients for 0.5 LTI HiPPO-lagt\n",
      "The Loss:\n",
      " [          inf           inf           inf 5.0527295e+34 4.5679888e+34           inf           inf           inf 4.5509465e+35 3.0879517e+35\n",
      " 3.5372083e+35           inf           inf           inf           inf           inf]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.3595016  0.3442213  0.37153238 0.3943251  0.33519942 0.30110395 0.44138414 0.35445568 0.37508082 0.35947025 0.34108108 0.31860203 0.32243496\n",
      " 0.362264   0.3312602  0.31949446]\n",
      "\n",
      "end of test for HiPPO-lagt model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"lagt\", lambda_n=1.0, alpha=0.5, discretization=0.5, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-fru LTI model with 0.5 transform\n",
      "\n",
      "Testing BRYANS HiPPO-fru model\n",
      "Creating HiPPO-fru LTI model with 0.5 transform\n",
      "Bryan's Coeffiecients for 0.5 LTI HiPPO-fru\n",
      "The Loss:\n",
      " [0.35118264 0.38082975 0.32966015 0.37876427 0.32509214 0.31076282 0.35634804 0.3444245  0.32797927 0.35355532 0.3306821  0.3208621  0.3228538\n",
      " 0.3640939  0.3412339  0.34140104]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.3511826  0.3808303  0.32966012 0.3787643  0.32509232 0.31076315 0.35634816 0.3444245  0.32797945 0.35355532 0.33068204 0.3208621  0.32285362\n",
      " 0.36409396 0.34123397 0.34140077]\n",
      "\n",
      "end of test for HiPPO-fru model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"fru\", lambda_n=1.0, alpha=0.5, discretization=0.5, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FouT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-fout LTI model with 0.5 transform\n",
      "\n",
      "Testing BRYANS HiPPO-fout model\n",
      "Creating HiPPO-fout LTI model with 0.5 transform\n",
      "Bryan's Coeffiecients for 0.5 LTI HiPPO-fout\n",
      "The Loss:\n",
      " [0.3535667  0.35146195 0.35392866 0.37577248 0.32537478 0.342341   0.35267413 0.34554935 0.33443934 0.35393754 0.3432759  0.32086352 0.34556466\n",
      " 0.39044106 0.35431844 0.35615224]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35356656 0.35146213 0.35392857 0.37577245 0.3253752  0.34234062 0.3526743  0.34554917 0.33443916 0.3539375  0.3432762  0.32086352 0.3455655\n",
      " 0.39044186 0.35431787 0.35615334]\n",
      "\n",
      "end of test for HiPPO-fout model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"fout\", lambda_n=1.0, alpha=0.5, discretization=0.5, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FouD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-foud LTI model with 0.5 transform\n",
      "\n",
      "Testing BRYANS HiPPO-foud model\n",
      "Creating HiPPO-foud LTI model with 0.5 transform\n",
      "Bryan's Coeffiecients for 0.5 LTI HiPPO-foud\n",
      "The Loss:\n",
      " [0.35069418 0.35698712 0.32436812 0.3781004  0.31943154 0.30363774 0.35764936 0.34441382 0.3172199  0.3541609  0.32780588 0.32111537 0.3175849\n",
      " 0.3674386  0.33515513 0.33352256]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35069418 0.356987   0.32436806 0.37810043 0.31943154 0.30363765 0.35764927 0.34441385 0.31722    0.35416102 0.32780588 0.3211154  0.31758484\n",
      " 0.36743852 0.3351551  0.33352235]\n",
      "\n",
      "end of test for HiPPO-foud model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"foud\", lambda_n=1.0, alpha=0.5, discretization=0.5, print_all=print_all\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing (LTI and LSI) Operators With ZOH Transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LegS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-legs LTI model with 2.0 transform\n",
      "gu's vals: (256,)\n",
      "gu's vals: (256,)\n",
      "Creating Gu's HiPPO-legs LSI model with 2.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-legs model\n",
      "Creating HiPPO-legs LTI model with 2.0 transform\n",
      "Creating HiPPO-legs LSI model with 2.0 transform\n",
      "Bryan's Coeffiecients for 2.0 LTI HiPPO-legs\n",
      "The Loss:\n",
      " [0.24887547 0.26386017 0.22381255 0.2577321  0.23089343 0.2123164  0.24520826 0.27531803 0.21867877 0.29000908 0.274537   0.2946152  0.28397858\n",
      " 0.2402501  0.34515768 0.29902413]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.2927326  0.12845896 0.165967   0.10037367 0.21014486 0.278264   0.3281554  0.09506361 0.12716429 0.08225903 0.11849605 0.090541   0.10785306\n",
      " 0.17675102 0.12504598 0.09001569]\n",
      "\n",
      "\n",
      "\n",
      "Bryan's Coeffiecients for 2.0 LSI HiPPO-legs\n",
      "The Loss:\n",
      " [0.10172817 0.09642398 0.09994817 0.0996581  0.10897219 0.09424824 0.1072233  0.09650478 0.092353   0.09804132 0.08860762 0.09561859 0.11546683\n",
      " 0.10787295 0.11346029 0.11233236]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.06824626 0.06779923 0.0704189  0.07547039 0.07031    0.07307882 0.07713184 0.07610603 0.06447862 0.07406408 0.0672615  0.07002634 0.07961836\n",
      " 0.07299153 0.08096497 0.0683699 ]\n",
      "\n",
      "end of test for HiPPO-legs model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"legs\",\n",
    "    lambda_n=1.0,\n",
    "    alpha=2.0,\n",
    "    discretization=\"zoh\",\n",
    "    print_all=print_all,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LegT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-legt LTI model with 2.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-legt model\n",
      "Creating HiPPO-legt LTI model with 2.0 transform\n",
      "Bryan's Coeffiecients for 2.0 LTI HiPPO-legt\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "end of test for HiPPO-legt model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"legt\",\n",
    "    lambda_n=1.0,\n",
    "    alpha=2.0,\n",
    "    discretization=\"zoh\",\n",
    "    print_all=print_all,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-lmu LTI model with 2.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-lmu model\n",
      "Creating HiPPO-lmu LTI model with 2.0 transform\n",
      "Bryan's Coeffiecients for 2.0 LTI HiPPO-lmu\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35142815 0.3455534  0.3226121  0.37903214 0.31867814 0.30122083 0.3527272  0.34916523 0.31786817 0.35646066 0.3277972  0.3211748  0.3205662\n",
      " 0.36499843 0.33480752 0.3240801 ]\n",
      "\n",
      "end of test for HiPPO-lmu model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"lmu\",\n",
    "    lambda_n=2.0,\n",
    "    alpha=2.0,\n",
    "    discretization=\"zoh\",\n",
    "    print_all=print_all,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LagT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-lagt LTI model with 2.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-lagt model\n",
      "Creating HiPPO-lagt LTI model with 2.0 transform\n",
      "Bryan's Coeffiecients for 2.0 LTI HiPPO-lagt\n",
      "The Loss:\n",
      " [9.1217859e+34 5.7362997e+33 1.0018595e+35 2.5804589e+35 2.4022569e+35 1.4176100e+34 7.2374545e+34 4.2535694e+34 6.4100862e+34 6.5418139e+34\n",
      " 5.6368510e+33 9.4797193e+32 2.7605731e+34 2.0170646e+35 5.3546453e+34 2.1092401e+35]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.34603003 0.3435721  0.32015926 0.37499648 0.3152003  0.2978233  0.3463508  0.3474422  0.31605712 0.35251835 0.32731292 0.31842488 0.31799686\n",
      " 0.3592921  0.3303862  0.31895453]\n",
      "\n",
      "end of test for HiPPO-lagt model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"lagt\",\n",
    "    lambda_n=1.0,\n",
    "    alpha=2.0,\n",
    "    discretization=\"zoh\",\n",
    "    print_all=print_all,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-fru LTI model with 2.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-fru model\n",
      "Creating HiPPO-fru LTI model with 2.0 transform\n",
      "Bryan's Coeffiecients for 2.0 LTI HiPPO-fru\n",
      "The Loss:\n",
      " [0.35110626 0.34437096 0.32087862 0.3758601  0.31798816 0.299774   0.35316494 0.3458764  0.3154822  0.35367787 0.32720894 0.32093203 0.31910044\n",
      " 0.36382112 0.3333275  0.323862  ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35110626 0.34437096 0.3208786  0.3758601  0.31798816 0.299774   0.3531649  0.3458764  0.3154822  0.35367787 0.32720894 0.32093203 0.31910044\n",
      " 0.36382112 0.3333275  0.323862  ]\n",
      "\n",
      "end of test for HiPPO-fru model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"fru\",\n",
    "    lambda_n=1.0,\n",
    "    alpha=2.0,\n",
    "    discretization=\"zoh\",\n",
    "    print_all=print_all,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FouT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-fout LTI model with 2.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-fout model\n",
      "Creating HiPPO-fout LTI model with 2.0 transform\n",
      "Bryan's Coeffiecients for 2.0 LTI HiPPO-fout\n",
      "The Loss:\n",
      " [0.35099867 0.34436995 0.3208948  0.375654   0.31843498 0.29979926 0.35301557 0.34657085 0.3154192  0.3542355  0.32717574 0.32098946 0.31938225\n",
      " 0.36411223 0.33431405 0.3247923 ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35099867 0.34436995 0.3208948  0.375654   0.31843498 0.29979926 0.35301557 0.34657085 0.3154192  0.3542355  0.32717574 0.32098946 0.31938225\n",
      " 0.36411223 0.33431405 0.3247923 ]\n",
      "\n",
      "end of test for HiPPO-fout model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"fout\",\n",
    "    lambda_n=1.0,\n",
    "    alpha=2.0,\n",
    "    discretization=\"zoh\",\n",
    "    print_all=print_all,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FouD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Gu's HiPPO-foud LTI model with 2.0 transform\n",
      "\n",
      "Testing BRYANS HiPPO-foud model\n",
      "Creating HiPPO-foud LTI model with 2.0 transform\n",
      "Bryan's Coeffiecients for 2.0 LTI HiPPO-foud\n",
      "The Loss:\n",
      " [0.35119998 0.34435833 0.32090923 0.375829   0.31804895 0.2997815  0.35316664 0.34592736 0.31527933 0.35360616 0.32716495 0.32088467 0.31803918\n",
      " 0.36382782 0.33322173 0.3239077 ]\n",
      "\n",
      "\n",
      "\n",
      "The Loss:\n",
      " [0.35119998 0.34435833 0.32090923 0.375829   0.31804898 0.2997815  0.35316664 0.34592736 0.31527933 0.35360616 0.32716495 0.32088467 0.31803915\n",
      " 0.36382782 0.33322173 0.32390773]\n",
      "\n",
      "end of test for HiPPO-foud model\n"
     ]
    }
   ],
   "source": [
    "test_reconstruction(\n",
    "    the_measure=\"foud\",\n",
    "    lambda_n=1.0,\n",
    "    alpha=2.0,\n",
    "    discretization=\"zoh\",\n",
    "    print_all=print_all,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s4mer-pkg-jZnBSgjq-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a81e05d1d7f7eae781698b7c1b81c0d771335201ebad1d81045cb177cef974b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
